{
  "abstract": {
    "en": "Accurately forecasting the impact of macroeconomic events is critical for investors and policymakers. Salient events like monetary policy decisions and employment reports often trigger market movements by shaping expectations of economic growth and risk, thereby establishing causal relationships between events and market behavior. Existing forecasting methods typically focus either on textual analysis or time-series modeling, but fail to capture the multi-modal nature of financial markets and the causal relationship between events and price movements. To address these gaps, we propose CAMEF (Causal-Augmented Multi-Modality Event-Driven Financial Forecasting), a multi-modality framework that effectively integrates textual and time-series data with a causal learning mechanism and an LLM-based counterfactual event augmentation technique for causal-enhanced financial forecasting. Our contributions include: (1) a multi-modal framework that captures causal relationships between policy texts and historical price data; (2) a new financial dataset with six types of macroeconomic releases from 2008 to April 2024, and high-frequency real trading data for five key U.S. financial assets; and (3) an LLM-based counterfactual event augmentation strategy. We compare CAMEF to state-of-the-art transformer-based time-series and multi-modal baselines, and perform ablation studies to validate the effectiveness of the causal learning mechanism and event types.",
    "zh": "精准预测宏观经济事件的影响对投资者和政策制定者至关重要。货币政策决议与非农就业报告等重大事件常通过塑造经济增长预期与风险认知引发市场波动，从而建立事件与市场行为间的因果关系。现有预测方法通常仅聚焦文本分析或时间序列建模，未能捕捉金融市场的多模态特性及事件与价格变动间的因果关联。为弥补这些不足，我们提出CAMEF（因果增强多模态事件驱动金融预测框架），该多模态框架通过因果学习机制与基于大语言模型的反事实事件增强技术，有效融合文本与时序数据以实现因果增强的金融预测。我们的贡献包括：（1）构建能捕捉政策文本与历史价格数据因果关系的多模态框架；（2）发布涵盖2008年至2024年4月六类宏观经济数据及五种美国关键金融资产高频实盘交易的新金融数据集；（3）提出基于大语言模型的反事实事件增强策略。通过将CAMEF与基于Transformer的先进时序模型及多模态基线对比，并进行消融实验，验证了因果学习机制与事件分类的有效性。"
  },
  "keywords": [
    "Multimodal learning",
    "Causal Learning",
    "Financial dataset",
    "Timeseries Forecasting"
  ],
  "sections": [
    {
      "id": "section-d5e1b1c8-4f1d-4153-bfa9-1097f5ddf323",
      "title": {
        "en": "Introduction",
        "zh": "引言"
      },
      "content": [
        {
          "id": "paragraph-f02db66f-6e03-49ca-84b6-a1c9e8879407",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "The prices of financial assets reflect all available information, according to Fama's Efficient Market Theory "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-15",
                  "ref-16"
                ],
                "displayText": "[15, 16]"
              },
              {
                "type": "text",
                "content": ". Major financial releases from government sectors often trigger market movements by shaping investors' expectations and evaluations of economic conditions, asset growth potential, and associated risks. For example, during the FOMC meeting on March 16, 2020, the Fed's emergency rate cut to "
              },
              {
                "type": "inline-math",
                "latex": "0 - 0.25\\%"
              },
              {
                "type": "text",
                "content": " sharply altered investors' economic outlook, resulting in a massive sell-off. Major indices, including the S&P 500, NASDAQ, and Dow Jones, dropped by over "
              },
              {
                "type": "inline-math",
                "latex": "10\\%"
              },
              {
                "type": "text",
                "content": ", marking the steepest single-day decline since 1987 "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-13"
                ],
                "displayText": "[13]"
              },
              {
                "type": "text",
                "content": ". These salient macroeconomic events cause reactions in financial assets, establishing causal relationships between events and financial assets. "
              },
              {
                "type": "figure-ref",
                "figureId": "fig-1",
                "displayText": "Figure 1"
              },
              {
                "type": "text",
                "content": " illustrates multiple types of events that cause financial market reactions. Therefore, accurately forecasting the causal consequences of the salient macroeconomic releases on financial market is essential, not only to help investors manage risks and maximize returns, but also to provide policymakers with valuable insights for evaluating and refining future policies."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "根据法玛的有效市场理论"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-15",
                  "ref-16"
                ],
                "displayText": "[15, 16]"
              },
              {
                "type": "text",
                "content": "，金融资产价格反映了所有可用信息。政府部门的重大金融发布通过塑造投资者对经济状况、资产增长潜力和相关风险的预期和评估，常常触发市场变动。例如，在2020年3月16日的FOMC会议期间，美联储紧急降息至"
              },
              {
                "type": "inline-math",
                "latex": "0 - 0.25\\%"
              },
              {
                "type": "text",
                "content": "急剧改变了投资者的经济前景，导致大规模抛售。包括标普500、纳斯达克和道琼斯在内的主要指数下跌超过"
              },
              {
                "type": "inline-math",
                "latex": "10\\%"
              },
              {
                "type": "text",
                "content": "，创下自1987年以来最大的单日跌幅"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-13"
                ],
                "displayText": "[13]"
              },
              {
                "type": "text",
                "content": "。这些显著的宏观经济事件引起金融资产的反应，建立事件与金融资产之间的因果关系。图1展示了引起金融市场反应的多种事件类型。因此，准确预测显著宏观经济发布对金融市场的因果后果至关重要，不仅帮助投资者管理风险和最大化回报，还为政策制定者提供评估和完善未来政策的宝贵见解。"
              }
            ]
          }
        },
        {
          "id": "figure-9ab00828-c58c-4bc0-ac26-1014657883e6",
          "type": "figure",
          "src": "/uploads/images/5f6810f9-e873-442a-9010-512a38761b5c/figure-9ab00828-c58c-4bc0-ac26-1014657883e6.jpg",
          "alt": "FOMC Release Event",
          "caption": {
            "en": [
              {
                "type": "text",
                "content": "Event: FOMC Release"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "事件：FOMC发布"
              }
            ]
          },
          "description": {},
          "uploadedFilename": "figure-9ab00828-c58c-4bc0-ac26-1014657883e6.jpg"
        },
        {
          "id": "figure-3fbc5a90-c849-4c60-a7b9-ec245a917ddb",
          "type": "figure",
          "src": "/uploads/images/5f6810f9-e873-442a-9010-512a38761b5c/figure-3fbc5a90-c849-4c60-a7b9-ec245a917ddb.jpg",
          "alt": "FOMC Release Event",
          "caption": {
            "en": [
              {
                "type": "text",
                "content": "Event: FOMC Release"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "事件：FOMC发布"
              }
            ]
          },
          "description": {},
          "uploadedFilename": "figure-3fbc5a90-c849-4c60-a7b9-ec245a917ddb.jpg"
        },
        {
          "id": "figure-2b26d0ef-3fdb-46ad-b91e-68ee8f588f9a",
          "type": "figure",
          "src": "/uploads/images/5f6810f9-e873-442a-9010-512a38761b5c/figure-2b26d0ef-3fdb-46ad-b91e-68ee8f588f9a.jpg",
          "alt": "CPI Release Event",
          "caption": {
            "en": [
              {
                "type": "text",
                "content": "New Event: CPI Release"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "新事件：CPI发布"
              }
            ]
          },
          "description": {},
          "uploadedFilename": "figure-2b26d0ef-3fdb-46ad-b91e-68ee8f588f9a.jpg"
        },
        {
          "id": "figure-87bf57d5-3264-47e8-a90b-fd63e573775a",
          "type": "figure",
          "src": "/uploads/images/5f6810f9-e873-442a-9010-512a38761b5c/figure-87bf57d5-3264-47e8-a90b-fd63e573775a.jpg",
          "alt": "Event-Driven Forecasting Examples",
          "caption": {
            "en": [
              {
                "type": "figure-ref",
                "figureId": "fig-1",
                "displayText": "Figure 1"
              },
              {
                "type": "text",
                "content": ": Event-Driven Forecasting Examples: (a) Market reaction to employment insurance release; (b) Market reaction during FOMC meeting; (c) Forecasting market reactions to future events."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "图1：事件驱动预测示例：（a）市场对就业保险发布的反应；（b）FOMC会议期间的市场反应；（c）预测未来事件的市场反应。"
              }
            ]
          },
          "description": {},
          "uploadedFilename": "figure-87bf57d5-3264-47e8-a90b-fd63e573775a.jpg"
        },
        {
          "id": "figure-16b2b73c-1135-4366-acd8-b68fb8038445",
          "type": "figure",
          "src": "/uploads/images/5f6810f9-e873-442a-9010-512a38761b5c/figure-16b2b73c-1135-4366-acd8-b68fb8038445.jpg",
          "caption": {},
          "description": {},
          "uploadedFilename": "figure-16b2b73c-1135-4366-acd8-b68fb8038445.jpg"
        },
        {
          "id": "figure-8e8f937d-ccfd-4393-9d57-0c63c0740b2e",
          "type": "figure",
          "src": "/uploads/images/5f6810f9-e873-442a-9010-512a38761b5c/figure-8e8f937d-ccfd-4393-9d57-0c63c0740b2e.jpg",
          "caption": {},
          "description": {},
          "uploadedFilename": "figure-8e8f937d-ccfd-4393-9d57-0c63c0740b2e.jpg"
        },
        {
          "id": "paragraph-f5e82539-ff56-42b0-bcff-1b6a4f57cfd3",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Previous studies on event-driven forecasting have primarily adopted three lines of methodologies. The first line of approaches utilizes text feature-based models, where language models, ranging from self-crafted RNN-based architectures "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-11",
                  "ref-22",
                  "ref-29",
                  "ref-57"
                ],
                "displayText": "[11, 22, 29, 57]"
              },
              {
                "type": "text",
                "content": " to pre-trained transformers "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-49",
                  "ref-62"
                ],
                "displayText": "[49, 62]"
              },
              {
                "type": "text",
                "content": ", embed sentiment information into text vectors, and then stock movements are predicted as a binary classification task (e.g., hawkish vs. dovish). The second line of methodology focuses on historical time-series data, treating stock price movements as a regression problem "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-7",
                  "ref-54"
                ],
                "displayText": "[7, 54]"
              },
              {
                "type": "text",
                "content": ". Recently, transformer-based architectures have been applied for time-series prediction, including Informer "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-60"
                ],
                "displayText": "[60]"
              },
              {
                "type": "text",
                "content": ", FedFormer "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-61"
                ],
                "displayText": "[61]"
              },
              {
                "type": "text",
                "content": ", and AutoFormer "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-8"
                ],
                "displayText": "[8]"
              },
              {
                "type": "text",
                "content": ", etc. However, both of these directions typically focus on a single modality, neglecting multi-dimensional information. The third line of research adopts a multi-modality approach, leveraging multiple types of data sources to enhance forecasting performance. For instance, studies like "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-35",
                  "ref-37"
                ],
                "displayText": "[35, 37]"
              },
              {
                "type": "text",
                "content": " incorporate textual, video, and audio data from FOMC meetings alongside corresponding market movements. While these approaches show promise for event-driven financial forecasts, they face three major limitations:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "先前关于事件驱动预测的研究主要采用三种方法论路线。第一种方法利用基于文本特征的模型，其中语言模型从自制的基于RNN的架构"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-11",
                  "ref-22",
                  "ref-29",
                  "ref-57"
                ],
                "displayText": "[11, 22, 29, 57]"
              },
              {
                "type": "text",
                "content": "到预训练的Transformer"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-49",
                  "ref-62"
                ],
                "displayText": "[49, 62]"
              },
              {
                "type": "text",
                "content": "，将情感信息嵌入文本向量，然后将股票变动预测为二元分类任务（例如，鹰派与鸽派）。第二种方法侧重于历史时间序列数据，将股价变动视为回归问题"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-7",
                  "ref-54"
                ],
                "displayText": "[7, 54]"
              },
              {
                "type": "text",
                "content": "。最近，基于Transformer的架构已应用于时间序列预测，包括Informer"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-60"
                ],
                "displayText": "[60]"
              },
              {
                "type": "text",
                "content": "、FedFormer"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-61"
                ],
                "displayText": "[61]"
              },
              {
                "type": "text",
                "content": "和AutoFormer"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-8"
                ],
                "displayText": "[8]"
              },
              {
                "type": "text",
                "content": "等。然而，这两个方向通常侧重于单一模态，忽略了多维信息。第三种研究采用多模态方法，利用多种类型的数据源来增强预测性能。例如，像"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-35",
                  "ref-37"
                ],
                "displayText": "[35, 37]"
              },
              {
                "type": "text",
                "content": "这样的研究结合了FOMC会议的文本、视频和音频数据以及相应的市场变动。虽然这些方法在事件驱动金融预测方面显示出前景，但它们面临三个主要限制："
              }
            ]
          }
        },
        {
          "id": "unordered-list-0de24eca-2e55-49a1-b2b6-f580a9f1962e",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Data Limitation: Existing approaches predominantly focus on a single type of event, such as FOMC meetings "
                  },
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-35",
                      "ref-37",
                      "ref-49"
                    ],
                    "displayText": "[35, 37, 49]"
                  },
                  {
                    "type": "text",
                    "content": ", while neglecting other crucial macroeconomic events like unemployment insurance releases, CPI, PPI, and GDP advance reports. Additionally, many studies rely on daily-based time-series data for financial assets "
                  },
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-7",
                      "ref-8",
                      "ref-35",
                      "ref-37",
                      "ref-49",
                      "ref-54",
                      "ref-60",
                      "ref-61"
                    ],
                    "displayText": "[7, 8, 35, 37, 49, 54, 60, 61]"
                  },
                  {
                    "type": "text",
                    "content": ", which limits their applicability and precision in real-time trading scenarios where high-frequency data is mostly adopted."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "数据限制：现有方法主要侧重于单一类型的事件，如FOMC会议"
                  },
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-35",
                      "ref-37",
                      "ref-49"
                    ],
                    "displayText": "[35, 37, 49]"
                  },
                  {
                    "type": "text",
                    "content": "，而忽略了其他关键的宏观经济事件，如失业保险发布、CPI、PPI和GDP初步报告。此外，许多研究依赖金融资产的基于日的时间序列数据"
                  },
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-7",
                      "ref-8",
                      "ref-35",
                      "ref-37",
                      "ref-49",
                      "ref-54",
                      "ref-60",
                      "ref-61"
                    ],
                    "displayText": "[7, 8, 35, 37, 49, 54, 60, 61]"
                  },
                  {
                    "type": "text",
                    "content": "，这限制了它们在主要采用高频数据的实时交易场景中的适用性和精确性。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "paragraph-7fbdf0b2-02a9-46cf-867e-f7975b5343c3",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Most prior studies rely on single-modality analysis, using either textual models "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-11",
                  "ref-22",
                  "ref-29",
                  "ref-49",
                  "ref-57",
                  "ref-62"
                ],
                "displayText": "[11, 22, 29, 49, 57, 62]"
              },
              {
                "type": "text",
                "content": " or time-series models "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-7",
                  "ref-8",
                  "ref-54",
                  "ref-60",
                  "ref-61"
                ],
                "displayText": "[7, 8, 54, 60, 61]"
              },
              {
                "type": "text",
                "content": ", which fail to integrate the complementary strengths of both modalities. While some multi-modality approaches have been proposed "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-35",
                  "ref-37"
                ],
                "displayText": "[35, 37]"
              },
              {
                "type": "text",
                "content": ", they often lack advanced mechanisms for feature fusion, effective decoding strategies, and causal learning, which are critical for understanding the complex interplay between event texts and market dynamics."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "大多数先前研究依赖于单模态分析，使用文本模型"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-11",
                  "ref-22",
                  "ref-29",
                  "ref-49",
                  "ref-57",
                  "ref-62"
                ],
                "displayText": "[11, 22, 29, 49, 57, 62]"
              },
              {
                "type": "text",
                "content": "或时间序列模型"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-7",
                  "ref-8",
                  "ref-54",
                  "ref-60",
                  "ref-61"
                ],
                "displayText": "[7, 8, 54, 60, 61]"
              },
              {
                "type": "text",
                "content": "，未能整合两种模态的互补优势。虽然已提出一些多模态方法"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-35",
                  "ref-37"
                ],
                "displayText": "[35, 37]"
              },
              {
                "type": "text",
                "content": "，但它们通常缺乏高级的特征融合机制、有效的解码策略和因果学习，这些对于理解事件文本与市场动态之间的复杂相互作用至关重要。"
              }
            ]
          }
        },
        {
          "id": "paragraph-24d32787-e7d6-4e74-bf15-5ebdb20deb5e",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Existing methods "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-35",
                  "ref-37"
                ],
                "displayText": "[35, 37]"
              },
              {
                "type": "text",
                "content": " fail to incorporate causal reasoning frameworks, overlooking the causal relationships between events and market reactions. Without explicitly modeling these relationships, such approaches cannot fully capture the drivers of financial market behavior, limiting their predictive robustness."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "现有方法"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-35",
                  "ref-37"
                ],
                "displayText": "[35, 37]"
              },
              {
                "type": "text",
                "content": "未能整合因果推理框架，忽略了事件与市场反应之间的因果关系。若不明确建模这些关系，此类方法无法完全捕捉金融市场行为的驱动因素，限制了其预测鲁棒性。"
              }
            ]
          }
        },
        {
          "id": "paragraph-692acb4c-ae1c-4db2-b603-8727acf93146",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "To address the limitations of previous studies, we propose a novel multi-modality framework, CAMEF<sup>1</sup> (causal-Augmented Multi-Modality Event-Driven Financial Forecasting). CAMEF integrates time-series and textual features through specially designed multi-feature fusion techniques, time-series decoding mechanisms, and causal learning strategies. By conducting a thorough review of financial literature, we identify six types of salient macroeconomic events for the forecasting analysis. Furthermore, the framework employs causal data augmentation powered by Large Language Models (LLMs) and a causal contrastive learning approach to enhance the causal understanding and forecast accuracy of CAMEF."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "为解决先前研究的局限性，我们提出了一种新颖的多模态框架CAMEF<sup>1</sup>（因果增强多模态事件驱动金融预测）。CAMEF通过专门设计的多特征融合技术、时间序列解码机制和因果学习策略整合时间序列和文本特征。通过对金融文献的全面回顾，我们确定了六种显著的宏观经济事件用于预测分析。此外，该框架采用由大型语言模型（LLMs）驱动的因果数据增强和因果对比学习方法，以增强CAMEF的因果理解和预测准确性。"
              }
            ]
          }
        },
        {
          "id": "unordered-list-cf641844-f46e-497b-9e4e-3bd13c8b99d8",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Novel Dataset: We introduce a novel open-source synthetic dataset comprising 6 types of macroeconomic event scripts (ref to Tab. 1 for details) from 2008 to April 2024 through reviewing from financial literature [3, 10, 17-20, 26, 33, 34, 38, 42-44, 52], alongside intra-day high-frequency financial data at 5-minute intervals from key U.S. stock indexes and Treasury bonds. To support causal learning, the dataset also includes counterfactual event scripts generated using our LLM-based causal argumentation prompting, making it the first to integrate policy texts, high-frequency trading data, and causally augmented content."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "新颖数据集：我们引入了一个新颖的开源合成数据集，包含通过金融文献[3, 10, 17-20, 26, 33, 34, 38, 42-44, 52]回顾的2008年至2024年4月的6种宏观经济事件脚本（详见表格1），以及来自美国主要股票指数和国债的日内5分钟间隔高频金融数据。为支持因果学习，该数据集还包括使用我们基于LLM的因果论证提示生成的反事实事件脚本，使其成为首个整合政策文本、高频交易数据和因果增强内容的数据集。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "unordered-list-62c47452-538f-4207-b34c-f75783c4b7fa",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Novel Multi-Modality Model: We propose a novel multimodality approach, CAMEF, that integrates time-series and textual features, incorporating specifically designed multi-feature fusion and time-series decoding networks, which have been demonstrated to be effective for forecasting. Additionally, the model includes a causal learning mechanism to enhance forecasting capability by capturing the causal relationships between events and market reactions."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "新颖多模态模型：我们提出了一种新颖的多模态方法CAMEF，整合时间序列和文本特征，包含专门设计的多特征融合和时间序列解码网络，这些已被证明对预测有效。此外，该模型包括一个因果学习机制，通过捕捉事件与市场反应之间的因果关系来增强预测能力。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "unordered-list-3dd1a234-1b9d-4bab-928e-72c2a2fa8659",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Counterfactual Generation and Learning: We introduce a counterfactual data augmentation strategy to generate counterfactual event scripts based on collected macroeconomic releases. This approach leverages LLMs to create scripts with varying sentiment levels by modifying key numerical values and sentiment-relevant phrases, while preserving the original format, writing style, and neutral words of the factual reports. Counterfactual events enable CAMEF to better understand the causal relationships between events and market reactions by learning from hypothetical scenarios, thereby improving its forecasting ability."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "反事实生成与学习：我们引入了一种反事实数据增强策略，基于收集的宏观经济发布生成反事实事件脚本。该方法利用LLMs通过修改关键数值和情感相关短语来创建具有不同情感水平的脚本，同时保留事实报告的原始格式、写作风格和中性词。反事实事件使CAMEF能够通过从假设场景中学习来更好地理解事件与市场反应之间的因果关系，从而提高其预测能力。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "paragraph-f272fd45-bf28-4a4f-9141-54f189f058b4",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Event-driven financial forecasting "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-2"
                ],
                "displayText": "[2]"
              },
              {
                "type": "text",
                "content": " focuses on predicting asset prices "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-18",
                  "ref-20"
                ],
                "displayText": "[18, 20]"
              },
              {
                "type": "text",
                "content": " and market volatility "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-10",
                  "ref-33"
                ],
                "displayText": "[10, 33]"
              },
              {
                "type": "text",
                "content": " based on events like macroeconomic releases "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-18"
                ],
                "displayText": "[18]"
              },
              {
                "type": "text",
                "content": ", news "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-29"
                ],
                "displayText": "[29]"
              },
              {
                "type": "text",
                "content": ", corporate announcements "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-62"
                ],
                "displayText": "[62]"
              },
              {
                "type": "text",
                "content": ", and social media activity "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-57"
                ],
                "displayText": "[57]"
              },
              {
                "type": "text",
                "content": ". Three main approaches exist in this area."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "事件驱动金融预测"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-2"
                ],
                "displayText": "[2]"
              },
              {
                "type": "text",
                "content": "侧重于基于宏观经济发布"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-18"
                ],
                "displayText": "[18]"
              },
              {
                "type": "text",
                "content": "、新闻"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-29"
                ],
                "displayText": "[29]"
              },
              {
                "type": "text",
                "content": "、公司公告"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-62"
                ],
                "displayText": "[62]"
              },
              {
                "type": "text",
                "content": "和社交媒体活动"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-57"
                ],
                "displayText": "[57]"
              },
              {
                "type": "text",
                "content": "等事件预测资产价格"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-18",
                  "ref-20"
                ],
                "displayText": "[18, 20]"
              },
              {
                "type": "text",
                "content": "和市场波动性"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-10",
                  "ref-33"
                ],
                "displayText": "[10, 33]"
              },
              {
                "type": "text",
                "content": "。该领域存在三种主要方法。"
              }
            ]
          }
        },
        {
          "id": "paragraph-24ebb10e-216b-4726-92da-1c2598b7d6d0",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "The first leverages text analysis to predict asset responses based on event-related text. Early works utilized TF-IDF "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-28",
                  "ref-39"
                ],
                "displayText": "[28, 39]"
              },
              {
                "type": "text",
                "content": " and topic models "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-36",
                  "ref-50"
                ],
                "displayText": "[36, 50]"
              },
              {
                "type": "text",
                "content": ", progressing to RNN-based models "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-22",
                  "ref-29"
                ],
                "displayText": "[22, 29]"
              },
              {
                "type": "text",
                "content": " and pre-trained transformers "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-49",
                  "ref-62"
                ],
                "displayText": "[49, 62]"
              },
              {
                "type": "text",
                "content": ", which capture nuanced semantics. Although these models excel at semantic extraction, they often lack integration with historical price data, crucial for holistic forecasting."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "第一种利用文本分析基于事件相关文本预测资产响应。早期工作使用TF-IDF"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-28",
                  "ref-39"
                ],
                "displayText": "[28, 39]"
              },
              {
                "type": "text",
                "content": "和主题模型"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-36",
                  "ref-50"
                ],
                "displayText": "[36, 50]"
              },
              {
                "type": "text",
                "content": "，发展到基于RNN的模型"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-22",
                  "ref-29"
                ],
                "displayText": "[22, 29]"
              },
              {
                "type": "text",
                "content": "和预训练变换器"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-49",
                  "ref-62"
                ],
                "displayText": "[49, 62]"
              },
              {
                "type": "text",
                "content": "，这些模型捕捉了细微语义。尽管这些模型在语义提取方面表现出色，但它们通常缺乏与历史价格数据的整合，这对整体预测至关重要。"
              }
            ]
          }
        },
        {
          "id": "paragraph-edba01a2-b07c-4553-9276-186ff99f92b1",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "The second line of approaches uses statistical and sequential models on numerical data, such as linear regression "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-5"
                ],
                "displayText": "[5]"
              },
              {
                "type": "text",
                "content": ", ARIMA "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-1"
                ],
                "displayText": "[1]"
              },
              {
                "type": "text",
                "content": ", and GARCH "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-23"
                ],
                "displayText": "[23]"
              },
              {
                "type": "text",
                "content": ". Later, deep learning methods like RNNs "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-29"
                ],
                "displayText": "[29]"
              },
              {
                "type": "text",
                "content": " and CNNs "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-14",
                  "ref-48"
                ],
                "displayText": "[14, 48]"
              },
              {
                "type": "text",
                "content": " enhanced nonlinear modeling capabilities. More recently, transformer-based models, such as Informer "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-60"
                ],
                "displayText": "[60]"
              },
              {
                "type": "text",
                "content": " and FedFormer "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-61"
                ],
                "displayText": "[61]"
              },
              {
                "type": "text",
                "content": ", improved long-range dependency modeling for time series data. However, these models tend to be \"case-specific,\" requiring task-specific training. In contrast, the latest pre-trained models for time-series data, like MOMENT "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-21"
                ],
                "displayText": "[21]"
              },
              {
                "type": "text",
                "content": ", Timer "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-32"
                ],
                "displayText": "[32]"
              },
              {
                "type": "text",
                "content": ", and TOKEN "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-53"
                ],
                "displayText": "[53]"
              },
              {
                "type": "text",
                "content": ", offer more generalized and adaptable solutions for time-series tasks."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "第二种方法在数值数据上使用统计和序列模型，如线性回归"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-5"
                ],
                "displayText": "[5]"
              },
              {
                "type": "text",
                "content": "、ARIMA"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-1"
                ],
                "displayText": "[1]"
              },
              {
                "type": "text",
                "content": "和GARCH"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-23"
                ],
                "displayText": "[23]"
              },
              {
                "type": "text",
                "content": "。后来，深度学习方法如RNNs"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-29"
                ],
                "displayText": "[29]"
              },
              {
                "type": "text",
                "content": "和CNNs"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-14",
                  "ref-48"
                ],
                "displayText": "[14, 48]"
              },
              {
                "type": "text",
                "content": "增强了非线性建模能力。最近，基于变换器的模型，如Informer"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-60"
                ],
                "displayText": "[60]"
              },
              {
                "type": "text",
                "content": "和FedFormer"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-61"
                ],
                "displayText": "[61]"
              },
              {
                "type": "text",
                "content": "，改进了时间序列数据的长程依赖建模。然而，这些模型往往是\"特定案例的\"，需要任务特定训练。相比之下，最新的时间序列预训练模型，如MOMENT"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-21"
                ],
                "displayText": "[21]"
              },
              {
                "type": "text",
                "content": "、Timer"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-32"
                ],
                "displayText": "[32]"
              },
              {
                "type": "text",
                "content": "和TOKEN"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-53"
                ],
                "displayText": "[53]"
              },
              {
                "type": "text",
                "content": "，为时间序列任务提供了更通用和适应性强的解决方案。"
              }
            ]
          }
        },
        {
          "id": "paragraph-663f4823-bf5d-4bbd-b03b-ec00c5dad795",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "The third line of research adopts multi-modality approaches, combining diverse data types to improve forecasting accuracy. Some studies incorporate text and audio "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-40",
                  "ref-58"
                ],
                "displayText": "[40, 58]"
              },
              {
                "type": "text",
                "content": " but often overlook time-series dependencies. Recent work has integrated time-series and textual data; for example, "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-46",
                  "ref-47"
                ],
                "displayText": "[46, 47]"
              },
              {
                "type": "text",
                "content": " employed SVM and GRU models to capture time-series features. However, these models are relatively shallow for extracting complex patterns. More recent studies "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-24",
                  "ref-27"
                ],
                "displayText": "[24, 27]"
              },
              {
                "type": "text",
                "content": " leverage transformer-based models for time-series analysis, better capturing deeper temporal structures. Building on these advancements, this paper aims to utilize state-of-the-art pre-trained models with enhanced feature fusion and causal learning for multimodality forecasting."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "第三种研究采用多模态方法，结合多样数据类型以提高预测准确性。一些研究整合文本和音频"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-40",
                  "ref-58"
                ],
                "displayText": "[40, 58]"
              },
              {
                "type": "text",
                "content": "但常忽略时间序列依赖。近期工作整合了时间序列和文本数据；例如，"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-46",
                  "ref-47"
                ],
                "displayText": "[46, 47]"
              },
              {
                "type": "text",
                "content": "使用SVM和GRU模型捕捉时间序列特征。然而，这些模型在提取复杂模式方面相对浅层。更近期的研究"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-24",
                  "ref-27"
                ],
                "displayText": "[24, 27]"
              },
              {
                "type": "text",
                "content": "利用基于变换器的模型进行时间序列分析，更好地捕捉深层时间结构。基于这些进展，本文旨在利用最先进的预训练模型，结合增强的特征融合和因果学习进行多模态预测。"
              }
            ]
          }
        },
        {
          "id": "paragraph-d0ab7dfc-e8c8-4ff1-bc9c-3e7bfdcba81b",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Which macroeconomic announcements have a greater impact on financial markets than others? This question has been widely studied in the financial literature, with Central Bank Communications standing out as the most-researched factor [10, 17, 33, 34, 42-44, 52]."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "哪些宏观经济公告对金融市场的影响比其他更大？这个问题在金融文献中被广泛研究，其中中央银行沟通作为研究最多的因素脱颖而出[10, 17, 33, 34, 42-44, 52]。"
              }
            ]
          }
        },
        {
          "id": "paragraph-6662cae6-3f92-4e14-8b29-79a617530993",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Beyond central bank communications, various other macroeconomic factors have also been identified as significant drivers of market movements. Among these, Non-farm Payrolls, Unemployment Releases, Initial Unemployment Claims, ISM Manufacturing Index, GDP Advance Releases, Consumer Confidence Index, and Producer Price Index (PPI) Reports have been found to notably influence price movements and market volatility through empirical statistical testings [3, 18-20, 26, 38]."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "除中央银行沟通外，各种其他宏观经济因素也被确定为市场变动的重要驱动因素。其中，非农就业数据、失业率发布、初请失业金人数、ISM制造业指数、GDP初步发布、消费者信心指数和生产者价格指数（PPI）报告通过经验统计测试[3, 18-20, 26, 38]被发现显著影响价格变动和市场波动性。"
              }
            ]
          }
        },
        {
          "id": "paragraph-14886264-cb31-48b5-83bf-d505c9ba37db",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "In this paper, we aim to leverage the most significant factors evidenced by the past financial literature [3, 18-20, 26, 38], which include FOMC Meeting Documents, Non-farm Payrolls, Unemployment Releases, Initial Unemployment Claims, ISM Manufacturing Index, GDP Advance Releases, Consumer Confidence Index, and Producer Price Index (PPI) Reports."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "在本文中，我们旨在利用过去金融文献[3, 18-20, 26, 38]证明的最显著因素，包括FOMC会议文件、非农就业数据、失业率发布、初请失业金人数、ISM制造业指数、GDP初步发布、消费者信心指数和生产者价格指数（PPI）报告。"
              }
            ]
          }
        },
        {
          "id": "paragraph-f77b98f8-a18e-4187-8888-c4ab111e70b9",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Counterfactual Data Augmentation seeks to reduce spurious correlations and enhance model robustness. Kaushik et al. "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-25"
                ],
                "displayText": "[25]"
              },
              {
                "type": "text",
                "content": " introduced a method that augments training data with counterfactuals written by human注释者，effectively helping to mitigate spurious patterns. Ross et al. "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-45"
                ],
                "displayText": "[45]"
              },
              {
                "type": "text",
                "content": ", Wu et al. "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-56"
                ],
                "displayText": "[56]"
              },
              {
                "type": "text",
                "content": " later proposed the use of hand-crafted templates and trained text generators to create counterfactual data through predefined perturbation types. However, these methods are limited by their reliance on fixed perturbations."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "反事实数据增强旨在减少虚假相关性并增强模型鲁棒性。Kaushik等人"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-25"
                ],
                "displayText": "[25]"
              },
              {
                "type": "text",
                "content": "引入了一种方法，用人类注释者编写的反事实增强训练数据，有效帮助减轻虚假模式。Ross等人"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-45"
                ],
                "displayText": "[45]"
              },
              {
                "type": "text",
                "content": "、Wu等人"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-56"
                ],
                "displayText": "[56]"
              },
              {
                "type": "text",
                "content": "后来提出了使用手工模板和训练文本生成器通过预定义扰动类型创建反事实数据。然而，这些方法受限于对固定扰动的依赖。"
              }
            ]
          }
        },
        {
          "id": "paragraph-d3e03885-3e6a-42be-b601-e7ea06209114",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "More recently, Chen et al. "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-9"
                ],
                "displayText": "[9]"
              },
              {
                "type": "text",
                "content": ", Wang et al. "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-55"
                ],
                "displayText": "[55]"
              },
              {
                "type": "text",
                "content": " proposed more flexible, LLM-based approaches that leverage specifically designed in-context learning prompts and generation pipelines for counterfactual and instruction data generation. Following this direction, we present a counterfactual generation framework specifically designed for macroeconomic releases."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "最近，Chen等人"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-9"
                ],
                "displayText": "[9]"
              },
              {
                "type": "text",
                "content": "、Wang等人"
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-55"
                ],
                "displayText": "[55]"
              },
              {
                "type": "text",
                "content": "提出了更灵活的基于LLM的方法，利用专门设计的上下文学习提示和生成管道进行反事实和指令数据生成。遵循这一方向，我们提出了一个专门为宏观经济发布设计的反事实生成框架。"
              }
            ]
          }
        },
        {
          "id": "paragraph-509d9aaf-6f9c-4a4b-ad66-29b10d587a3a",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Event Set is defined as "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbb{E} := \\{\\mathcal{E}_1, \\mathcal{E}_2, \\dots, \\mathcal{E}_{|\\mathbb{E}|}\\}"
              },
              {
                "type": "text",
                "content": ", where "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbb{E}"
              },
              {
                "type": "text",
                "content": " represents a collection of "
              },
              {
                "type": "inline-math",
                "latex": "|\\mathbb{E}|"
              },
              {
                "type": "text",
                "content": " event scripts. Each event "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i"
              },
              {
                "type": "text",
                "content": " occurs at a specific timestamp "
              },
              {
                "type": "inline-math",
                "latex": "i"
              },
              {
                "type": "text",
                "content": " and belongs to one of the event types shown in "
              },
              {
                "type": "table-ref",
                "tableId": "table-1",
                "displayText": "Table 1"
              },
              {
                "type": "text",
                "content": "A. Each event script "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i"
              },
              {
                "type": "text",
                "content": " consists of a sequence of word tokens, represented as "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i := \\{w_1, w_2, \\dots, w_m\\}"
              },
              {
                "type": "text",
                "content": "."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "事件集定义为 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbb{E} := \\{\\mathcal{E}_1, \\mathcal{E}_2, \\dots, \\mathcal{E}_{|\\mathbb{E}|}\\}"
              },
              {
                "type": "text",
                "content": "，其中 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbb{E}"
              },
              {
                "type": "text",
                "content": " 表示包含 "
              },
              {
                "type": "inline-math",
                "latex": "|\\mathbb{E}|"
              },
              {
                "type": "text",
                "content": " 个事件脚本的集合。每个事件 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i"
              },
              {
                "type": "text",
                "content": " 在特定时间戳 "
              },
              {
                "type": "inline-math",
                "latex": "i"
              },
              {
                "type": "text",
                "content": " 发生，并属于表1A中所示的事件类型之一。每个事件脚本 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i"
              },
              {
                "type": "text",
                "content": " 由一系列词标记组成，表示为 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i := \\{w_1, w_2, \\dots, w_m\\}"
              },
              {
                "type": "text",
                "content": "。"
              }
            ]
          }
        },
        {
          "id": "paragraph-9a7e87ce-5701-4bd7-961f-a8f826863dd9",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Time Series Data is defined as "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{X} \\coloneqq \\{X_1, X_2, \\ldots, X_{|\\mathcal{X}|}\\}"
              },
              {
                "type": "text",
                "content": ", where each "
              },
              {
                "type": "inline-math",
                "latex": "X_i"
              },
              {
                "type": "text",
                "content": " represents the numerical data at time step "
              },
              {
                "type": "inline-math",
                "latex": "i"
              },
              {
                "type": "text",
                "content": ". An event "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i"
              },
              {
                "type": "text",
                "content": " is aligned with a time series segment "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{X}_{i - \\tau : i + \\tau}"
              },
              {
                "type": "text",
                "content": ", where "
              },
              {
                "type": "inline-math",
                "latex": "i"
              },
              {
                "type": "text",
                "content": " denotes the time of the releasement of the event, and "
              },
              {
                "type": "inline-math",
                "latex": "\\tau"
              },
              {
                "type": "text",
                "content": " represents the duration of the time-series segment both preceding and succeeding time step "
              },
              {
                "type": "inline-math",
                "latex": "i"
              },
              {
                "type": "text",
                "content": ", denoted as "
              },
              {
                "type": "inline-math",
                "latex": "[\\mathcal{X}_{i - \\tau : i + \\tau} \\mapsto \\mathcal{E}_i]"
              },
              {
                "type": "text",
                "content": ". This alignment reflects the time series segment leading up to the event "
              },
              {
                "type": "inline-math",
                "latex": "(X_{i - \\tau})"
              },
              {
                "type": "text",
                "content": " and the period during which the event is expected to have an effect "
              },
              {
                "type": "inline-math",
                "latex": "(X_{i + \\tau})"
              },
              {
                "type": "text",
                "content": "."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "时间序列数据定义为 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{X} \\coloneqq \\{X_1, X_2, \\ldots, X_{|\\mathcal{X}|}\\}"
              },
              {
                "type": "text",
                "content": "，其中每个 "
              },
              {
                "type": "inline-math",
                "latex": "X_i"
              },
              {
                "type": "text",
                "content": " 表示时间步 "
              },
              {
                "type": "inline-math",
                "latex": "i"
              },
              {
                "type": "text",
                "content": " 的数值数据。事件 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i"
              },
              {
                "type": "text",
                "content": " 与时间序列段 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{X}_{i - \\tau : i + \\tau}"
              },
              {
                "type": "text",
                "content": " 对齐，其中 "
              },
              {
                "type": "inline-math",
                "latex": "i"
              },
              {
                "type": "text",
                "content": " 表示事件发布时间，"
              },
              {
                "type": "inline-math",
                "latex": "\\tau"
              },
              {
                "type": "text",
                "content": " 表示时间序列段在时间步 "
              },
              {
                "type": "inline-math",
                "latex": "i"
              },
              {
                "type": "text",
                "content": " 前后的持续时间，表示为 "
              },
              {
                "type": "inline-math",
                "latex": "[\\mathcal{X}_{i - \\tau : i + \\tau} \\mapsto \\mathcal{E}_i]"
              },
              {
                "type": "text",
                "content": "。这种对齐反映了事件发生前的时间序列段 "
              },
              {
                "type": "inline-math",
                "latex": "(X_{i - \\tau})"
              },
              {
                "type": "text",
                "content": " 和事件预期产生影响的时期 "
              },
              {
                "type": "inline-math",
                "latex": "(X_{i + \\tau})"
              },
              {
                "type": "text",
                "content": "。"
              }
            ]
          }
        },
        {
          "id": "paragraph-da6fa6e3-b5fb-45cf-ab2a-4e45d95d007f",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Event-Driven Forecasting: Given a dataset "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{U} = \\{[\\mathcal{X}_{i - \\tau ;i + \\tau}\\mapsto \\mathcal{E}_i]\\}_{i = 1}^n"
              },
              {
                "type": "text",
                "content": " consisting of "
              },
              {
                "type": "inline-math",
                "latex": "n"
              },
              {
                "type": "text",
                "content": " aligned event and time-series pairs, for each data pair in "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{U}"
              },
              {
                "type": "text",
                "content": ", the model uses both the event text "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i"
              },
              {
                "type": "text",
                "content": " and the historical time-series segment "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{X}_{i - \\tau ;i}"
              },
              {
                "type": "text",
                "content": ", which spans "
              },
              {
                "type": "inline-math",
                "latex": "\\tau"
              },
              {
                "type": "text",
                "content": " steps before the event's release at time "
              },
              {
                "type": "inline-math",
                "latex": "i"
              },
              {
                "type": "text",
                "content": ", to forecast the future time steps "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{X}_{i + 1:i + \\tau}"
              },
              {
                "type": "text",
                "content": "."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "事件驱动预测：给定由 "
              },
              {
                "type": "inline-math",
                "latex": "n"
              },
              {
                "type": "text",
                "content": " 个对齐的事件和时间序列对组成的数据集 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{U} = \\{[\\mathcal{X}_{i - \\tau ;i + \\tau}\\mapsto \\mathcal{E}_i]\\}_{i = 1}^n"
              },
              {
                "type": "text",
                "content": "，对于 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{U}"
              },
              {
                "type": "text",
                "content": " 中的每个数据对，模型同时使用事件文本 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i"
              },
              {
                "type": "text",
                "content": " 和历史时间序列段 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{X}_{i - \\tau ;i}"
              },
              {
                "type": "text",
                "content": "（该段跨越事件在时间 "
              },
              {
                "type": "inline-math",
                "latex": "i"
              },
              {
                "type": "text",
                "content": " 发布前的 "
              },
              {
                "type": "inline-math",
                "latex": "\\tau"
              },
              {
                "type": "text",
                "content": " 个步骤）来预测未来时间步 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{X}_{i + 1:i + \\tau}"
              },
              {
                "type": "text",
                "content": "。"
              }
            ]
          }
        },
        {
          "id": "paragraph-8f207fb6-e957-4fab-b3ec-c4991221099d",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Causal Effect Graph: A Causal Effect Graph represents the causal links among variables: textual modality "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}"
              },
              {
                "type": "text",
                "content": " (event scripts), current price trend "
              },
              {
                "type": "inline-math",
                "latex": "X"
              },
              {
                "type": "text",
                "content": ", and future time series movements "
              },
              {
                "type": "inline-math",
                "latex": "Y"
              },
              {
                "type": "text",
                "content": ". In event-driven financial prediction, events influence the market movements of financial assets, forming a causal chain denoted as "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E} \\to X \\to Y"
              },
              {
                "type": "text",
                "content": ", as illustrated in "
              },
              {
                "type": "figure-ref",
                "figureId": "fig-2",
                "displayText": "Figure 2"
              },
              {
                "type": "text",
                "content": "a."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "因果效应图：因果效应图表示变量之间的因果联系：文本模态 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}"
              },
              {
                "type": "text",
                "content": "（事件脚本）、当前价格趋势 "
              },
              {
                "type": "inline-math",
                "latex": "X"
              },
              {
                "type": "text",
                "content": " 和未来时间序列变动 "
              },
              {
                "type": "inline-math",
                "latex": "Y"
              },
              {
                "type": "text",
                "content": "。在事件驱动的金融预测中，事件影响金融资产的市场变动，形成表示为 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E} \\to X \\to Y"
              },
              {
                "type": "text",
                "content": " 的因果链，如图2a所示。"
              }
            ]
          }
        },
        {
          "id": "table-5f82a0db-1f8e-4aeb-b3eb-c4aabe256dc3",
          "type": "table",
          "caption": {
            "en": [
              {
                "type": "text",
                "content": "Summary of Macroeconomic and Time-Series Data Types, Characteristics and Sources"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "宏观经济和时间序列数据类型、特征及来源摘要"
              }
            ]
          },
          "headers": [
            "Event Type",
            "Data Type",
            "Frequency",
            "Period",
            "No. of Events",
            "No. of C.F.s",
            "Source"
          ],
          "rows": [
            [
              "FOMC",
              "Html",
              "Quarterly",
              "1993.3 ~2024.6",
              "255",
              "2,550",
              "www.federalreserve-gov"
            ],
            [
              "UnemploymentInsurance Claims",
              "PDF, Txt",
              "Weekly",
              "2002.10 ~2024.6",
              "913",
              "9,130",
              "oui.dola.gov"
            ],
            [
              "Employment Situation",
              "Html, Txt",
              "Monthly",
              "1994.2 ~2024.6",
              "363",
              "3,630",
              "www.bls.gov"
            ],
            [
              "GDP Advance Report",
              "Html",
              "Monthly",
              "1996.8 ~2024.6",
              "333",
              "3,330",
              "www.bea.gov"
            ],
            [
              "CPI Report",
              "Html, Txt",
              "Monthly",
              "1994.2 ~2024.6",
              "357",
              "3,570",
              "www.bls.gov"
            ],
            [
              "PPI Report",
              "Html, Txt",
              "Monthly",
              "1994.2 ~2024.6",
              "348",
              "3,480",
              "www.bls.gov"
            ]
          ]
        },
        {
          "id": "table-0c29ff05-bcb5-402f-abbd-cc34282c36db",
          "type": "table",
          "caption": {
            "en": [
              {
                "type": "text",
                "content": "Summary of Macroeconomic and Time-Series Data Types, Characteristics and Sources"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "宏观经济和时间序列数据类型、特征及来源摘要"
              }
            ]
          },
          "headers": [
            "Time Series Data",
            "Data Types",
            "Frequency",
            "Range",
            "No. of Data Points"
          ],
          "rows": [
            [
              "SP500 (SPX)",
              "Open, Close, High, Low",
              "5 Min",
              "2008.01 ~ 2024.06",
              "331,257"
            ],
            [
              "Dow Industrial (INDU)",
              "Open, Close, High, Low",
              "5 Min",
              "2012.07 ~ 2024.06",
              "263,445"
            ],
            [
              "NASDAQ (NDX)",
              "Open, Close, High, Low",
              "5 Min",
              "2008.01 ~ 2024.06",
              "332,616"
            ],
            [
              "US Treasury Bond at 1-Month (USGG1M)",
              "Open, Close, High, Low",
              "5 Min",
              "2013.01 ~ 2024.06",
              "751,443"
            ],
            [
              "US Treasury Bond at 5-Year (USGG5YR)",
              "Open, Close, High, Low",
              "5 Min",
              "2013.01 ~ 2024.06",
              "734,773"
            ]
          ]
        },
        {
          "id": "figure-b35c60e0-a58c-45b6-b7ed-80da7934fba5",
          "type": "figure",
          "src": "/uploads/images/5f6810f9-e873-442a-9010-512a38761b5c/figure-b35c60e0-a58c-45b6-b7ed-80da7934fba5.jpg",
          "alt": "Causal Effect Graph",
          "caption": {
            "en": [
              {
                "type": "text",
                "content": "Causal Effect Graph"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "因果效应图"
              }
            ]
          },
          "description": {},
          "uploadedFilename": "figure-b35c60e0-a58c-45b6-b7ed-80da7934fba5.jpg"
        },
        {
          "id": "figure-14efc7be-a4cf-4df3-94ed-a520c9712041",
          "type": "figure",
          "src": "/uploads/images/5f6810f9-e873-442a-9010-512a38761b5c/figure-14efc7be-a4cf-4df3-94ed-a520c9712041.jpg",
          "alt": "Cause-Effect Detection with Counterfactual Events",
          "caption": {
            "en": [
              {
                "type": "text",
                "content": "The illustration of causal relationships and counterfactual events"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "因果关系及反事实事件示意图"
              }
            ]
          },
          "description": {},
          "uploadedFilename": "figure-14efc7be-a4cf-4df3-94ed-a520c9712041.jpg"
        },
        {
          "id": "paragraph-3d9117e0-cfed-4f04-b0fc-45a91991da87",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Counterfactual Event: A Counterfactual Event (CE) represents a modified event script in which key variables (e.g., unemployment rates, GDP values) are altered relative to the factual event, while the surrounding context remains unchanged. These events are denoted as "
              },
              {
                "type": "inline-math",
                "latex": "\\{\\mathcal{E}_1^*,\\mathcal{E}_2^*,\\dots,\\mathcal{E}_n^*\\}"
              },
              {
                "type": "text",
                "content": ",\\mathcal{E}_2^",
                "style": {
                  "italic": true
                }
              },
              {
                "type": "text",
                "content": ",\\dots,\\mathcal{E}_n^*\\}$. CEs are utilized to train CAMEF, enabling it to identify factual cause-effect relationships, represented as "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}\\rightarrow"
              },
              {
                "type": "text",
                "content": " "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{X}\\rightarrow \\mathcal{Y}"
              },
              {
                "type": "text",
                "content": ", as illustrated in "
              },
              {
                "type": "figure-ref",
                "figureId": "fig-2",
                "displayText": "Figure 2"
              },
              {
                "type": "text",
                "content": "b."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "反事实事件：反事实事件（CE）表示修改后的事件脚本，其中关键变量（如失业率、GDP值）相对于事实事件被改变，而周围上下文保持不变。这些事件表示为 "
              },
              {
                "type": "inline-math",
                "latex": "\\{\\mathcal{E}_1^*,\\mathcal{E}_2^*,\\dots,\\mathcal{E}_n^*\\}"
              },
              {
                "type": "text",
                "content": ",\\mathcal{E}_2^",
                "style": {
                  "italic": true
                }
              },
              {
                "type": "text",
                "content": ",\\dots,\\mathcal{E}_n^*\\}$。反事实事件用于训练CAMEF，使其能够识别事实因果关系，表示为 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}\\rightarrow"
              },
              {
                "type": "text",
                "content": " "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{X}\\rightarrow \\mathcal{Y}"
              },
              {
                "type": "text",
                "content": "，如图2b所示。"
              }
            ]
          }
        },
        {
          "id": "paragraph-2db89660-674c-4171-931d-f8cb68bffd4c",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "This section introduces the proposed dataset and the methodology for counterfactual event augmentation. The dataset includes 6 types of key macroeconomic announcements ranging from 2004 to 2024, selected through an extensive review of the financial literature, along with *high-frequency trading data. Unlike the daily-based trading data used in previous studies, this high-frequency data provides more predictive accuracy and better reflects real trading behavior in the industry."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "本节介绍提出的数据集和反事实事件增强方法。该数据集包含2004年至2024年的6种关键宏观经济公告，通过广泛回顾金融文献筛选得出，同时包含*高频交易数据。与先前研究中使用的基于日度的交易数据不同，这种高频数据提供更高的预测准确性，并更好地反映行业中的实际交易行为。"
              }
            ]
          }
        },
        {
          "id": "paragraph-2cab6f79-e937-4346-9bf9-c6c387bdb571",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "The primary question guiding the collection of this dataset is: \"Which macroeconomic releases have the greatest impact on financial markets?\" To address this, we conducted a comprehensive review of the financial literature to identify key macroeconomic factors that influence market behavior. Several dominant factors emerged, including the FOMC Minutes [10, 17, 33, 34, 42-44, 52], along with Unemployment Insurance Claims, Employment Situation Reports, GDP Advance Releases, and the Consumer Price Index (CPI) and Producer Price Index (PPI) reports [3, 18-20, 26, 38], which serve as the textual modality data for our dataset."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "指导该数据集收集的主要问题是：\"哪些宏观经济发布对金融市场影响最大？\"为解决此问题，我们进行了全面的金融文献回顾，以识别影响市场行为的关键宏观经济因素。几个主要因素浮现出来，包括FOMC会议纪要[10, 17, 33, 34, 42-44, 52]，以及失业救济金申请、就业形势报告、GDP初步发布、消费者价格指数（CPI）和生产者价格指数（PPI）报告[3, 18-20, 26, 38]，这些作为我们数据集的文本模态数据。"
              }
            ]
          }
        },
        {
          "id": "paragraph-fb502095-9c0d-40a6-94d2-a621fb097077",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "To collect these data, we developed web crawlers to extract raw files directly from official sources, including HTML, PDF, and TXT formats. These raw files were then pre-processed and converted into a structured and unified text format, ensuring consistency and ease of subsequent analysis. "
              },
              {
                "type": "table-ref",
                "tableId": "table-1",
                "displayText": "Table 1"
              },
              {
                "type": "text",
                "content": " provides a summary of the data types, collection frequencies, time periods, and sources of the events included in our dataset. Further details on the data crawling and pre-processing methodologies can be found in Appendix B."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "为收集这些数据，我们开发了网络爬虫直接从官方来源提取原始文件，包括HTML、PDF和TXT格式。这些原始文件随后经过预处理并转换为结构化和统一的文本格式，确保一致性和后续分析的便利性。表1提供了我们数据集中包含事件的数据类型、收集频率、时间周期和来源的摘要。关于数据爬取和预处理方法的更多细节可在附录B中找到。"
              }
            ]
          }
        },
        {
          "id": "paragraph-aec98ffb-803d-4617-b3e6-4b0033e6587e",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "In addition to the textual data, studies [10, 17, 33, 34, 42-44, 52] have demonstrated that the largest market impacts are typically observed in major U.S. stock indexes and Treasury bonds. Therefore, we focused on collecting high-frequency trading time-series data at 5 minute interval for key stock indexes, including the S&P 500 (SPX), Dow Industrial (INDU), NASDAQ (NDX), as well as U.S. Treasury Bond at 1-Month (USGG1M) and Treasury Bond at 5-Year (USGG5YR)."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "除文本数据外，研究[10, 17, 33, 34, 42-44, 52]表明最大的市场影响通常出现在主要美国股票指数和国债中。因此，我们专注于收集关键股票指数的高频交易时间序列数据，时间间隔为5分钟，包括标普500（SPX）、道琼斯工业指数（INDU）、纳斯达克（NDX），以及美国1个月期国债（USGG1M）和5年期国债（USGG5YR）。"
              }
            ]
          }
        },
        {
          "id": "paragraph-560b98d8-2aa3-4605-95e7-b8f687c1f957",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "This section describes the process of counterfactual event generation, creating hypothetical scenarios from existing event scripts. The aim is to reflect a target sentiment of a given event script while maintaining logical consistency and coherence of the original script. Our goal is modifying sentiment-relevant elements (such as key facts, sentiment-indicative phrases, or numerical values) without disrupting the sentiment-neutral components of the script."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "本节描述反事实事件生成的过程，从现有事件脚本创建假设场景。目标是在保持原始脚本逻辑一致性和连贯性的同时，反映给定事件脚本的目标情感。我们的目标是修改情感相关元素（如关键事实、情感指示短语或数值），而不破坏脚本的情感中性部分。"
              }
            ]
          }
        },
        {
          "id": "paragraph-7501983c-7af4-4c63-9007-3cf47e33e2f9",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Formally, for a given event script "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i\\coloneqq \\{w_1,w_2,\\ldots ,w_m\\}"
              },
              {
                "type": "text",
                "content": " , the objective is to produce a counterfactual version "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i^\\prime"
              },
              {
                "type": "text",
                "content": " that embodies the desired target sentiment "
              },
              {
                "type": "inline-math",
                "latex": "S_{i}^{\\prime}"
              },
              {
                "type": "text",
                "content": " . Conceptually, the event script can be viewed as comprising sentiment-relevant content ( "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i^{\\mathrm{sentiment}}"
              },
              {
                "type": "text",
                "content": " ) and sentiment-neutral content ( "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i^{\\mathrm{neutral}}"
              },
              {
                "type": "text",
                "content": " ), so that "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i = \\mathcal{E}_i^{\\mathrm{neutral}}\\cup \\mathcal{E}_i^{\\mathrm{sentiment}}"
              },
              {
                "type": "text",
                "content": " . Instead of explicitly decomposing the script, we guide a language model (LLM) using structured prompts to modify only the sentiment-relevant content. This ensures that neutral content remains intact or is replaced with semantically equivalent expressions."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "正式地，对于给定的事件脚本 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i\\coloneqq \\{w_1,w_2,\\ldots ,w_m\\}"
              },
              {
                "type": "text",
                "content": " ，目标是生成体现所需目标情感 "
              },
              {
                "type": "inline-math",
                "latex": "S_{i}^{\\prime}"
              },
              {
                "type": "text",
                "content": " 的反事实版本 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i^\\prime"
              },
              {
                "type": "text",
                "content": " 。概念上，事件脚本可视为包含情感相关内容（ "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i^{\\mathrm{sentiment}}"
              },
              {
                "type": "text",
                "content": " ）和情感中性内容（ "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i^{\\mathrm{neutral}}"
              },
              {
                "type": "text",
                "content": " ），因此 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i = \\mathcal{E}_i^{\\mathrm{neutral}}\\cup \\mathcal{E}_i^{\\mathrm{sentiment}}"
              },
              {
                "type": "text",
                "content": " 。我们通过结构化提示引导语言模型（LLM）仅修改情感相关内容，而非显式分解脚本。这确保中性内容保持不变或被语义等价表达式替换。"
              }
            ]
          }
        },
        {
          "id": "math-1560292a-e8c8-451a-8f1a-fec21b2d3f8f",
          "type": "math",
          "latex": "\\mathcal {E} _ {i} ^ {\\prime} = \\mathcal {E} _ {i} ^ {\\text {n e u t r a l}} \\cup f _ {\\mathrm {L L M}} \\left(\\mathcal {E} _ {i} ^ {\\text {s e n t i m e n t}} \\mid S _ {i} ^ {\\prime}\\right)",
          "label": "eq-1"
        },
        {
          "id": "paragraph-ca7ea960-5dc6-48e7-a640-8ca244795d88",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where "
              },
              {
                "type": "inline-math",
                "latex": "f_{\\mathrm{LLM}}"
              },
              {
                "type": "text",
                "content": " adjusts "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i^{\\mathrm{sentiment}}"
              },
              {
                "type": "text",
                "content": " to align with "
              },
              {
                "type": "inline-math",
                "latex": "S_i'"
              },
              {
                "type": "text",
                "content": " , and "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i^{\\mathrm{neutral}}"
              },
              {
                "type": "text",
                "content": " remains unchanged or is replaced by equivalent expressions."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中 "
              },
              {
                "type": "inline-math",
                "latex": "f_{\\mathrm{LLM}}"
              },
              {
                "type": "text",
                "content": " 调整 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i^{\\mathrm{sentiment}}"
              },
              {
                "type": "text",
                "content": " 以对齐 "
              },
              {
                "type": "inline-math",
                "latex": "S_i'"
              },
              {
                "type": "text",
                "content": " ，而 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i^{\\mathrm{neutral}}"
              },
              {
                "type": "text",
                "content": " 保持不变或被等价表达式替换。"
              }
            ]
          }
        },
        {
          "id": "paragraph-5ee0b3ed-4345-4c52-9bd7-ec61beddbc60",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Specifically, we used the LLaMA-3 8B model with a series of carefully designed prompts. These prompts include three key steps, with detailed templates provided in Appendix A:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "具体地，我们使用 LLaMA-3 8B 模型和一系列精心设计的提示。这些提示包含三个关键步骤，详细模板见附录 A："
              }
            ]
          }
        },
        {
          "id": "ordered-list-4129f93c-6419-4160-8c29-de7920ae4093",
          "type": "ordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Summarization Prompt (Appendix A.1): Condenses lengthy event scripts into concise summaries, addressing memory constraints while retaining sentiment-relevant content and key numerical variables."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "摘要提示（附录 A.1）：将冗长事件脚本压缩为简洁摘要，解决内存限制，同时保留情感相关内容和关键数值变量。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "figure-04778369-2690-4ddc-a8bd-2874696d2898",
          "type": "figure",
          "src": "/uploads/images/5f6810f9-e873-442a-9010-512a38761b5c/figure-04778369-2690-4ddc-a8bd-2874696d2898.jpg",
          "alt": "CAMEF architecture diagram",
          "caption": {
            "en": [
              {
                "type": "text",
                "content": "The Pipeline and Neural Architecture of CAMEF"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "CAMEF 的流程和神经架构"
              }
            ]
          },
          "description": {},
          "uploadedFilename": "figure-04778369-2690-4ddc-a8bd-2874696d2898.jpg"
        },
        {
          "id": "ordered-list-033171dd-337c-45de-93eb-1ac13964a267",
          "type": "ordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Sentiment Analysis Prompt (Appendix A.2): Assigns a sentiment score (from 1, very negative, to 10, very positive) to the original event script. This score provides a baseline for generating counterfactual versions."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "情感分析提示（附录 A.2）：为原始事件脚本分配情感分数（从 1，非常负面，到 10，非常正面）。该分数为生成反事实版本提供基线。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "ordered-list-3911226f-e39d-4700-8832-3901b7c65751",
          "type": "ordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Counterfactual Generation Prompt (Appendix A.3): Produces multiple counterfactual scripts, each reflecting a different sentiment level. The prompt modifies sentiment-related phrases and numerical values "
                  },
                  {
                    "type": "inline-math",
                    "latex": "(\\mathcal{E}_i^{\\text {sentiment }})"
                  },
                  {
                    "type": "text",
                    "content": " while preserving or equivalently substituting neutral content "
                  },
                  {
                    "type": "inline-math",
                    "latex": "(\\mathcal{E}_i^{\\text {neutral }})"
                  },
                  {
                    "type": "text",
                    "content": " . This approach ensures numerical reasonability, sentiment relevance, and structural consistency."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "反事实生成提示（附录 A.3）：生成多个反事实脚本，每个反映不同情感水平。提示修改情感相关短语和数值 "
                  },
                  {
                    "type": "inline-math",
                    "latex": "(\\mathcal{E}_i^{\\text {sentiment }})"
                  },
                  {
                    "type": "text",
                    "content": " ，同时保留或等价替换中性内容 "
                  },
                  {
                    "type": "inline-math",
                    "latex": "(\\mathcal{E}_i^{\\text {neutral }})"
                  },
                  {
                    "type": "text",
                    "content": " 。该方法确保数值合理性、情感相关性和结构一致性。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "paragraph-5c97c261-240a-4c4e-8ae2-6543f1d71067",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "This multi-step prompt strategy facilitates the generation of coherent, contextually relevant counterfactual events, enabling exploration of diverse market scenarios and deeper causal understanding."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "这种多步骤提示策略促进生成连贯、上下文相关的反事实事件，支持探索多样化市场场景和更深入因果理解。"
              }
            ]
          }
        },
        {
          "id": "paragraph-dc04c27d-0146-4560-a72b-9e71d04f4715",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "The CAMEF model integrates both textual and time-series information through a structured architecture consisting of a textual encoder, a time-series encoder, and a forecasting decoder, as depicted in "
              },
              {
                "type": "figure-ref",
                "figureId": "fig-3",
                "displayText": "Fig. 3"
              },
              {
                "type": "text",
                "content": ". Each component is detailed below."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "CAMEF 模型通过结构化架构整合文本和时间序列信息，包括文本编码器、时间序列编码器和预测解码器，如图 3 所示。各组件详述如下。"
              }
            ]
          }
        },
        {
          "id": "paragraph-1c6a7f6b-6441-49db-9e3f-183316183eb9",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "We encode event scripts using RoBERTa "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-31"
                ],
                "displayText": "[31]"
              },
              {
                "type": "text",
                "content": ". Given an input script "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{E}_i = w_1, w_2, \\ldots, w_m"
              },
              {
                "type": "text",
                "content": " , RoBERTa produces contextual token embeddings:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "我们使用 RoBERTa "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-31"
                ],
                "displayText": "[31]"
              },
              {
                "type": "text",
                "content": " 编码事件脚本。给定输入脚本 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{E}_i = w_1, w_2, \\ldots, w_m"
              },
              {
                "type": "text",
                "content": " ，RoBERTa 生成上下文标记嵌入："
              }
            ]
          }
        },
        {
          "id": "math-5fa93816-0302-41ae-948b-c3576e205cf8",
          "type": "math",
          "latex": "\\left\\{\\mathbf {h} _ {1}, \\mathbf {h} _ {2}, \\dots , \\mathbf {h} _ {m} \\right\\} = \\operatorname {R o B E R T a} \\left(\\left\\{w _ {1}, w _ {2}, \\dots , w _ {m} \\right\\}\\right)",
          "label": "eq-2"
        },
        {
          "id": "paragraph-b1a206e0-0368-4d30-85f1-92084cd67bad",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{h}_j\\in \\mathbb{R}^{1\\times 768}"
              },
              {
                "type": "text",
                "content": " is the embedding of token "
              },
              {
                "type": "inline-math",
                "latex": "w_{j}"
              },
              {
                "type": "text",
                "content": " . Each embedding is passed through a projection network with three linear layers and GELU activations:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{h}_j\\in \\mathbb{R}^{1\\times 768}"
              },
              {
                "type": "text",
                "content": " 是标记 "
              },
              {
                "type": "inline-math",
                "latex": "w_{j}"
              },
              {
                "type": "text",
                "content": " 的嵌入。每个嵌入通过具有三个线性层和 GELU 激活的投影网络："
              }
            ]
          }
        },
        {
          "id": "math-3e33ea7e-d060-48c8-bc4c-c2b5dfecf730",
          "type": "math",
          "latex": "\\mathbf {e} _ {j} = \\mathbf {W} ^ {(3)} \\cdot \\operatorname {G E L U} \\left(\\mathbf {W} ^ {(2)} \\cdot \\operatorname {G E L U} \\left(\\mathbf {W} ^ {(1)} \\mathbf {h} _ {j} + \\mathbf {b} ^ {(1)}\\right) + \\mathbf {b} ^ {(2)}\\right) + \\mathbf {b} ^ {(3)}",
          "label": "eq-3"
        },
        {
          "id": "paragraph-02032949-f61f-4d4a-8ad3-abda3335eda0",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{W}^{(1)}\\in \\mathbb{R}^{768\\times 1024},\\mathbf{W}^{(2)}\\in \\mathbb{R}^{1024\\times 1024}"
              },
              {
                "type": "text",
                "content": " and "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{W}^{(3)}\\in \\mathbb{R}^{1024\\times 768}"
              },
              {
                "type": "text",
                "content": " . The final encoding vector "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{E}_i"
              },
              {
                "type": "text",
                "content": " for the script is computed as the average of the transformed embeddings, "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{E}_i = \\frac{1}{m}\\sum_{j = 1}^{m}\\mathbf{e}_j"
              },
              {
                "type": "text",
                "content": " ."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{W}^{(1)}\\in \\mathbb{R}^{768\\times 1024},\\mathbf{W}^{(2)}\\in \\mathbb{R}^{1024\\times 1024}"
              },
              {
                "type": "text",
                "content": " 和 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{W}^{(3)}\\in \\mathbb{R}^{1024\\times 768}"
              },
              {
                "type": "text",
                "content": " 。脚本的最终编码向量 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{E}_i"
              },
              {
                "type": "text",
                "content": " 计算为变换后嵌入的平均值， "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{E}_i = \\frac{1}{m}\\sum_{j = 1}^{m}\\mathbf{e}_j"
              },
              {
                "type": "text",
                "content": " 。"
              }
            ]
          }
        },
        {
          "id": "paragraph-aae04f91-bd6e-4d91-9fa6-7a847343502b",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "To encode the time series data, we employ a pretrained time series encoder, MOMENT "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-21"
                ],
                "displayText": "[21]"
              },
              {
                "type": "text",
                "content": ", which generates a fixed-dimensional vector for an input time series segment. Subsequently, we design a multi-residual layer to further refine the encoding vectors, as shown below:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "为编码时间序列数据，我们使用预训练时间序列编码器 MOMENT "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-21"
                ],
                "displayText": "[21]"
              },
              {
                "type": "text",
                "content": "，它为输入时间序列段生成固定维向量。随后，我们设计多残差层进一步精炼编码向量，如下所示："
              }
            ]
          }
        },
        {
          "id": "math-61ad5e50-ba21-41aa-9de8-272b0b989433",
          "type": "math",
          "latex": "\\mathcal {X} _ {i} = \\operatorname {M O M E N T} \\left(\\left\\{X _ {1}, X _ {2}, \\dots , X _ {n} \\right\\}\\right)",
          "label": "eq-4"
        },
        {
          "id": "paragraph-5b1a523a-0792-43a6-bb1c-28b217d741d0",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where "
              },
              {
                "type": "inline-math",
                "latex": "X_{i}\\in \\mathbb{R}^{d}"
              },
              {
                "type": "text",
                "content": " is the encoded vector for the input time series segment "
              },
              {
                "type": "inline-math",
                "latex": "\\{X_1,X_2,\\ldots ,X_n\\}"
              },
              {
                "type": "text",
                "content": " , and "
              },
              {
                "type": "inline-math",
                "latex": "d"
              },
              {
                "type": "text",
                "content": " represents the dimensionality of the encoded vector. To enhance this representation, we introduce a multi-residual projection layer:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中 "
              },
              {
                "type": "inline-math",
                "latex": "X_{i}\\in \\mathbb{R}^{d}"
              },
              {
                "type": "text",
                "content": " 是输入时间序列段 "
              },
              {
                "type": "inline-math",
                "latex": "\\{X_1,X_2,\\ldots ,X_n\\}"
              },
              {
                "type": "text",
                "content": " 的编码向量， "
              },
              {
                "type": "inline-math",
                "latex": "d"
              },
              {
                "type": "text",
                "content": " 表示编码向量的维度。为增强此表示，我们引入多残差投影层："
              }
            ]
          }
        },
        {
          "id": "math-7e159a25-05ff-4042-b118-6c2072a5896e",
          "type": "math",
          "latex": "\\mathbf {Z} _ {i} = \\mathcal {X} _ {i} + f _ {\\text {r e s i d u a l}} (\\mathcal {X} _ {i})",
          "label": "eq-5"
        },
        {
          "id": "paragraph-4077d123-9732-4c34-82b0-3be8d9df49e4",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where "
              },
              {
                "type": "inline-math",
                "latex": "f_{\\mathrm{residual}}(\\mathcal{X}_i)"
              },
              {
                "type": "text",
                "content": " represents the transformation applied through the residual projection layer, which consists of multiple linear layers interleaved with GELU activations:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中 "
              },
              {
                "type": "inline-math",
                "latex": "f_{\\mathrm{residual}}(\\mathcal{X}_i)"
              },
              {
                "type": "text",
                "content": " 表示通过残差投影层应用的变换，该层由多个线性层和 GELU 激活交错组成："
              }
            ]
          }
        },
        {
          "id": "math-806d4c8b-7fa8-4f31-8447-db4210e979d2",
          "type": "math",
          "latex": "f _ {\\text {r e s i d u a l}} \\left(\\chi_ {i}\\right) = \\mathbf {W} _ {3} \\cdot \\operatorname {G E L U} \\left(\\mathbf {W} _ {2} \\cdot \\operatorname {G E L U} \\left(\\mathbf {W} _ {1} \\cdot \\chi_ {i} + \\mathbf {b} _ {1}\\right) + \\mathbf {b} _ {2}\\right) + \\mathbf {b} _ {3}",
          "label": "eq-6"
        },
        {
          "id": "paragraph-6be6048a-7614-4230-88d7-583e642409de",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{W}_1, \\mathbf{W}_2 \\in \\mathbb{R}^{1024 \\times 1024}, \\mathbf{W}_3 \\in \\mathbb{R}^{1024 \\times 768}"
              },
              {
                "type": "text",
                "content": " are the weight matrices, and "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{b}_1, \\mathbf{b}_2 \\in \\mathbb{R}^{1024}, \\mathbf{b}_3 \\in \\mathbb{R}^{768}"
              },
              {
                "type": "text",
                "content": " are the respective biases. Finally, "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{Z}_i \\in \\mathbb{R}^{1024}"
              },
              {
                "type": "text",
                "content": " serves as the refined vector for the time series segment."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{W}_1, \\mathbf{W}_2 \\in \\mathbb{R}^{1024 \\times 1024}, \\mathbf{W}_3 \\in \\mathbb{R}^{1024 \\times 768}"
              },
              {
                "type": "text",
                "content": " 是权重矩阵， "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{b}_1, \\mathbf{b}_2 \\in \\mathbb{R}^{1024}, \\mathbf{b}_3 \\in \\mathbb{R}^{768}"
              },
              {
                "type": "text",
                "content": " 是相应偏置。最终， "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{Z}_i \\in \\mathbb{R}^{1024}"
              },
              {
                "type": "text",
                "content": " 作为时间序列段的精炼向量。"
              }
            ]
          }
        },
        {
          "id": "paragraph-e07e432d-c853-4f3e-8232-9273f1727783",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "After obtaining the encoded vectors from the textual and time series data, denoted as "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{E}_i"
              },
              {
                "type": "text",
                "content": " and "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{Z}_i"
              },
              {
                "type": "text",
                "content": " , respectively, we concatenate them to form a unified representation:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "从文本和时间序列数据获得编码向量 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{E}_i"
              },
              {
                "type": "text",
                "content": " 和 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{Z}_i"
              },
              {
                "type": "text",
                "content": " 后，我们拼接它们形成统一表示："
              }
            ]
          }
        },
        {
          "id": "math-fe7e896c-e88a-47fe-881e-ce95b4a80bcd",
          "type": "math",
          "latex": "\\mathbf {E} _ {\\text {c o m b i n e d}} = \\operatorname {C o n c a t} \\left(\\mathbf {E} _ {i}, \\mathbf {Z} _ {i}\\right)",
          "label": "eq-7"
        },
        {
          "id": "paragraph-8c23d6e3-f91b-43f6-8709-b617f422f562",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "which captures both semantic content from macroeconomic texts and temporal patterns from time series inputs. To fuse these modalities, "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{E}_{\\mathrm{combined}}"
              },
              {
                "type": "text",
                "content": " is passed through a two-layer feedforward network with GELU activation:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "它捕获宏观经济文本的语义内容和时间序列输入的时间模式。为融合这些模态， "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{E}_{\\mathrm{combined}}"
              },
              {
                "type": "text",
                "content": " 通过具有 GELU 激活的双层前馈网络："
              }
            ]
          }
        },
        {
          "id": "math-494390bb-fc47-4023-84ce-48dcd8b3c80d",
          "type": "math",
          "latex": "\\mathbf {E} _ {\\text {f u s e d}} = \\mathbf {W} ^ {(f 2)} \\cdot \\operatorname {G E L U} \\left(\\mathbf {W} ^ {(f 1)} \\cdot \\mathbf {E} * \\text {c o m b i n e d} + \\mathbf {b} ^ {(f 1)}\\right) + \\mathbf {b} ^ {(f 2)}",
          "label": "eq-8"
        },
        {
          "id": "paragraph-621b35d5-ef0d-4ebd-a3a9-f0ade24a4d60",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{W}^{(f1)}\\in \\mathbb{R}^{(2\\times 768)\\times 1024},\\mathbf{W}^{(f2)}\\in \\mathbb{R}^{1024\\times 1024}"
              },
              {
                "type": "text",
                "content": " , and "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{b}^{(f1)},\\mathbf{b}^{(f2)}\\in \\mathbb{R}^{1024}"
              },
              {
                "type": "text",
                "content": " are the corresponding weight matrices and bias terms. This fusion block enables interaction across modalities and produces a refined joint embedding for downstream decoding."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{W}^{(f1)}\\in \\mathbb{R}^{(2\\times 768)\\times 1024},\\mathbf{W}^{(f2)}\\in \\mathbb{R}^{1024\\times 1024}"
              },
              {
                "type": "text",
                "content": " ，且 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{b}^{(f1)},\\mathbf{b}^{(f2)}\\in \\mathbb{R}^{1024}"
              },
              {
                "type": "text",
                "content": " 是相应权重矩阵和偏置项。此融合块支持跨模态交互，并为下游解码生成精炼联合嵌入。"
              }
            ]
          }
        },
        {
          "id": "paragraph-a646d0af-2c64-43b7-868d-8a9297a88f86",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "We then employ GPT-2 "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-41"
                ],
                "displayText": "[41]"
              },
              {
                "type": "text",
                "content": " as the decoder to decode the fused vector by leveraging its effective auto-regressive ability:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "我们随后使用 GPT-2 "
              },
              {
                "type": "citation",
                "referenceIds": [
                  "ref-41"
                ],
                "displayText": "[41]"
              },
              {
                "type": "text",
                "content": " 作为解码器，利用其有效自回归能力解码融合向量："
              }
            ]
          }
        },
        {
          "id": "math-34c12d11-aebe-4659-88db-b135330b157d",
          "type": "math",
          "latex": "\\mathbf {H} ^ {(l)} = f _ {\\mathrm {G P T 2 \\_ l a y e r}} ^ {(l)} \\left(\\mathbf {H} ^ {(l - 1)}\\right)",
          "label": "eq-9"
        },
        {
          "id": "paragraph-834654c5-91f9-4d95-bff1-4858dfc11b07",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{H}^{(0)} = \\mathbf{E}_{\\mathrm{fused}}"
              },
              {
                "type": "text",
                "content": " , and "
              },
              {
                "type": "inline-math",
                "latex": "f_{\\mathrm{GPT2\\_layer}}^{(l)}"
              },
              {
                "type": "text",
                "content": " represents the transformation function of the "
              },
              {
                "type": "inline-math",
                "latex": "l"
              },
              {
                "type": "text",
                "content": " -th GPT-2 layer, where "
              },
              {
                "type": "inline-math",
                "latex": "l = 12"
              },
              {
                "type": "text",
                "content": " . After the final layer, the output is normalized using a layer normalization function:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{H}^{(0)} = \\mathbf{E}_{\\mathrm{fused}}"
              },
              {
                "type": "text",
                "content": " ，且 "
              },
              {
                "type": "inline-math",
                "latex": "f_{\\mathrm{GPT2\\_layer}}^{(l)}"
              },
              {
                "type": "text",
                "content": " 表示第 "
              },
              {
                "type": "inline-math",
                "latex": "l"
              },
              {
                "type": "text",
                "content": " 层 GPT-2 层的变换函数，其中 "
              },
              {
                "type": "inline-math",
                "latex": "l = 12"
              },
              {
                "type": "text",
                "content": " 。最终层后，输出使用层归一化函数归一化："
              }
            ]
          }
        },
        {
          "id": "math-c0e0e929-413a-4046-bf1c-237bfadce8ec",
          "type": "math",
          "latex": "\\mathbf {H} _ {\\text {f i n a l}} = \\operatorname {L a y e r N o r m} \\left(\\mathbf {H} ^ {(l)}\\right)",
          "label": "eq-10"
        },
        {
          "id": "paragraph-0b00086d-d146-41d9-a3f6-bb5862ce4dff",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "The final output "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{H}_{\\mathrm{final}}"
              },
              {
                "type": "text",
                "content": " is then used to generate predictions based on the combined multi-modal information."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "最终输出 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{H}_{\\mathrm{final}}"
              },
              {
                "type": "text",
                "content": " 随后用于基于组合多模态信息生成预测。"
              }
            ]
          }
        },
        {
          "id": "paragraph-3590b840-2704-48a6-a5d3-2450e6c4c3a4",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "We designed a Post-Regressor that applies a linear transformation to the concatenated vector "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{H}_{\\mathrm{final}}"
              },
              {
                "type": "text",
                "content": ", followed by GELU activation and a dropout layer with a rate of 0.1:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "我们设计了一个后回归器，对拼接向量 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{H}_{\\mathrm{final}}"
              },
              {
                "type": "text",
                "content": " 应用线性变换，随后进行GELU激活和丢弃率为0.1的丢弃层："
              }
            ]
          }
        },
        {
          "id": "math-b73ebdb8-b6f5-4199-9ae0-200de987ebec",
          "type": "math",
          "latex": "\\mathbf {R} ^ {(k)} = \\operatorname {G E L U} \\left(\\mathbf {W} ^ {(k)} \\cdot \\mathbf {R} ^ {(k - 1)} + \\mathbf {b} ^ {(k)}\\right)",
          "label": "eq-11"
        },
        {
          "id": "paragraph-ff545daf-cc54-436b-9d6e-bf02a7f9edc4",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{R}^{(0)} = \\mathbf{H}_{\\mathrm{final}}"
              },
              {
                "type": "text",
                "content": ", "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{W}^{(k)}"
              },
              {
                "type": "text",
                "content": " and "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{b}^{(k)}"
              },
              {
                "type": "text",
                "content": " are the weight matrix and bias of the "
              },
              {
                "type": "inline-math",
                "latex": "k"
              },
              {
                "type": "text",
                "content": "-th linear layer, respectively. "
              },
              {
                "type": "inline-math",
                "latex": "k = 4"
              },
              {
                "type": "text",
                "content": " is the total number of layers in the regressor. The final linear layer maps the representation to a vector of shape "
              },
              {
                "type": "inline-math",
                "latex": "(d \\times \\mathrm{pred\\_len})"
              },
              {
                "type": "text",
                "content": ", where "
              },
              {
                "type": "inline-math",
                "latex": "d"
              },
              {
                "type": "text",
                "content": " is the forecast dimensionality and "
              },
              {
                "type": "inline-math",
                "latex": "\\mathrm{pred\\_len}"
              },
              {
                "type": "text",
                "content": " is the number of predicted time steps:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{R}^{(0)} = \\mathbf{H}_{\\mathrm{final}}"
              },
              {
                "type": "text",
                "content": "，"
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{W}^{(k)}"
              },
              {
                "type": "text",
                "content": " 和 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{b}^{(k)}"
              },
              {
                "type": "text",
                "content": " 分别是第 "
              },
              {
                "type": "inline-math",
                "latex": "k"
              },
              {
                "type": "text",
                "content": " 个线性层的权重矩阵和偏置。"
              },
              {
                "type": "inline-math",
                "latex": "k = 4"
              },
              {
                "type": "text",
                "content": " 是回归器中的总层数。最终线性层将表示映射到形状为 "
              },
              {
                "type": "inline-math",
                "latex": "(d \\times \\mathrm{pred\\_len})"
              },
              {
                "type": "text",
                "content": " 的向量，其中 "
              },
              {
                "type": "inline-math",
                "latex": "d"
              },
              {
                "type": "text",
                "content": " 是预测维度，"
              },
              {
                "type": "inline-math",
                "latex": "\\mathrm{pred\\_len}"
              },
              {
                "type": "text",
                "content": " 是预测时间步数："
              }
            ]
          }
        },
        {
          "id": "math-42df10a6-f913-467f-b6c0-03206d2e84db",
          "type": "math",
          "latex": "\\hat {\\mathbf {Y}} = \\mathbf {W} _ {\\text {o u t}} \\cdot \\mathbf {R} ^ {(K)} + \\mathbf {b} _ {\\text {o u t}}",
          "label": "eq-12"
        },
        {
          "id": "paragraph-ca85aa28-2a38-46d7-91bf-d94f70402073",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where "
              },
              {
                "type": "inline-math",
                "latex": "\\hat{Y}"
              },
              {
                "type": "text",
                "content": ", represents the predicted time series values."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中 "
              },
              {
                "type": "inline-math",
                "latex": "\\hat{Y}"
              },
              {
                "type": "text",
                "content": " 表示预测的时间序列值。"
              }
            ]
          }
        },
        {
          "id": "paragraph-c27a62a3-e546-4540-981a-f3907eff79b3",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Learning Objectives for Time Series: We employ a combination of Mean Squared Error (MSE) loss and Mean Absolute Error (MAE) loss to optimize the model. The MSE loss minimizes the squared differences between the predicted time series values, "
              },
              {
                "type": "inline-math",
                "latex": "\\hat{\\mathbf{Y}}"
              },
              {
                "type": "text",
                "content": ", and the ground truth values, "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{Y}"
              },
              {
                "type": "text",
                "content": ", while the MAE loss minimizes the absolute differences. These are defined as:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "时间序列学习目标：我们采用均方误差（MSE）损失和平均绝对误差（MAE）损失的组合来优化模型。MSE损失最小化预测时间序列值 "
              },
              {
                "type": "inline-math",
                "latex": "\\hat{\\mathbf{Y}}"
              },
              {
                "type": "text",
                "content": " 与真实值 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{Y}"
              },
              {
                "type": "text",
                "content": " 之间的平方差，而MAE损失最小化绝对差。定义如下："
              }
            ]
          }
        },
        {
          "id": "math-0da335a3-e1f0-439f-a733-86cc037520e8",
          "type": "math",
          "latex": "\\mathcal {L} _ {\\mathrm {M S E}} = \\frac {1}{n} \\sum_ {i = 1} ^ {n} (\\hat {\\mathbf {Y}} _ {i} - \\mathbf {Y} _ {i}) ^ {2}, \\quad \\mathcal {L} _ {\\mathrm {M A E}} = \\frac {1}{n} \\sum_ {i = 1} ^ {n} | \\hat {\\mathbf {Y}} _ {i} - \\mathbf {Y} _ {i} |",
          "label": "eq-13"
        },
        {
          "id": "paragraph-9c1cddd4-1f47-42cd-93de-bbd1bcbc5475",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where "
              },
              {
                "type": "inline-math",
                "latex": "n"
              },
              {
                "type": "text",
                "content": " is the number of predicted values (e.g., 35, 70, or 140, as defined in Section 6.1). The total loss function combines both objectives to balance optimization for large and small errors:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中 "
              },
              {
                "type": "inline-math",
                "latex": "n"
              },
              {
                "type": "text",
                "content": " 是预测值的数量（例如35、70或140，如第6.1节所定义）。总损失函数结合两个目标以平衡对大误差和小误差的优化："
              }
            ]
          }
        },
        {
          "id": "math-0e46933e-d336-4b2b-9ed3-4715710778f4",
          "type": "math",
          "latex": "\\mathcal {L} _ {\\text {T i m e}} = \\mathcal {L} _ {\\text {M S E}} + \\mathcal {L} _ {\\text {M A E}}",
          "label": "eq-14"
        },
        {
          "id": "paragraph-e11c2db3-c533-4573-bf6a-eebe95b6447e",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Causal learning enhances the robustness of the CAMEF model by enabling it to identify the correct event script among sampled counterfactual events (CEs). To achieve this, we first design a Diverse Counterfactual Event Sampling Mechanism, which generates two types of CEs. These counterfactuals, along with their corresponding time-series data, are then encoded using the textual and time-series modalities of CAMEF. This process helps the model learn causal relationships between events and their corresponding time-series movements."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "因果学习通过使CAMEF模型能够在采样的反事实事件（CEs）中识别正确的事件脚本来增强其鲁棒性。为此，我们首先设计了一个多样反事实事件采样机制，生成两种类型的CEs。这些反事实事件及其对应的时间序列数据随后使用CAMEF的文本和时间序列模态进行编码。此过程帮助模型学习事件与其对应时间序列变动之间的因果关系。"
              }
            ]
          }
        },
        {
          "id": "paragraph-d0fbd90c-07be-4b68-9ea2-4a89df26eb57",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "We propose a Diverse Counterfactual Event Sampling Mechanism to enhance the model's ability to both identify the ground-truth event and distinguish between different event types. This mechanism is designed with two objectives: (1) to help the model recognize the ground-truth event among similar counterfactuals of the same type, and (2) to enable the model to differentiate between events of different types."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "我们提出一个多样反事实事件采样机制，以增强模型识别真实事件和区分不同事件类型的能力。该机制设计有两个目标：(1) 帮助模型在相同类型的相似反事实中识别真实事件，(2) 使模型能够区分不同类型的事件。"
              }
            ]
          }
        },
        {
          "id": "paragraph-fdeb9249-c4ed-46af-a247-95572bfb0404",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "To achieve these objectives, we generate two categories of counterfactual events for each factual event:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "为实现这些目标，我们为每个事实事件生成两类反事实事件："
              }
            ]
          }
        },
        {
          "id": "unordered-list-4fd66d51-7cdc-42bb-9419-41e40714f2d6",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Identical Type Sampling: Counterfactual events of the same type as the ground-truth event, created by modifying sentiment-relevant components and key numerical variables, as detailed in Sec. 4.2."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "相同类型采样：与真实事件类型相同的反事实事件，通过修改情感相关组件和关键数值变量创建，详见第4.2节。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "unordered-list-40ac6a35-f947-4f65-8393-f598884facc0",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Diverse Type Sampling: Counterfactual events of a different type, sampled by substituting the ground-truth event with 5 other event type occurring on the closest date."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "多样类型采样：不同类型的反事实事件，通过用最接近日期的5个其他事件类型替换真实事件进行采样。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "paragraph-42f7db54-4815-4fac-bd75-13978567d614",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "This mechanism provides a diverse set of counterfactual events, collectively denoted as "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbb{E}^{CF} \\coloneqq \\{\\mathcal{E}_1^{CF}, \\mathcal{E}_2^{CF}, \\ldots, \\mathcal{E}_{|\\mathbb{E}^{CF}|}^{CF}\\}"
              },
              {
                "type": "text",
                "content": ", we set the total number of diverse-type samples to be 5, and the default number of identical-type samples to be 10 as introduced in Sec. 4.2."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "该机制提供一组多样的反事实事件，统称为 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbb{E}^{CF} \\coloneqq \\{\\mathcal{E}_1^{CF}, \\mathcal{E}_2^{CF}, \\ldots, \\mathcal{E}_{|\\mathbb{E}^{CF}|}^{CF}\\}"
              },
              {
                "type": "text",
                "content": "，我们设置多样类型样本总数为5，相同类型样本默认数量为10，如第4.2节所述。"
              }
            ]
          }
        },
        {
          "id": "paragraph-d7b1ad09-691a-44b2-9edb-f6a2ad27c178",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "The causal learning process utilizes both the textual (see Sec. 5.1) and time-series (see Sec. 5.2) encoders of CAMEF to capture the relationships between events and market movements. The textual encoder is used to encode both the ground-truth event "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}^{GT}"
              },
              {
                "type": "text",
                "content": " and the sampled CEs "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}^{CF}"
              },
              {
                "type": "text",
                "content": ":"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "因果学习过程利用CAMEF的文本（见第5.1节）和时间序列（见第5.2节）编码器来捕捉事件与市场变动之间的关系。文本编码器用于编码真实事件 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}^{GT}"
              },
              {
                "type": "text",
                "content": " 和采样的CEs "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}^{CF}"
              },
              {
                "type": "text",
                "content": "："
              }
            ]
          }
        },
        {
          "id": "math-8e52c7d3-1a34-407e-8044-5fb7739a676d",
          "type": "math",
          "latex": "\\left\\{\\mathbf {P} ^ {G T}, \\mathbf {P} _ {1} ^ {C F}, \\dots , \\mathbf {P} _ {| \\mathbb {E} ^ {C F} |} ^ {C F} \\right\\} = \\mathbf {C A M E F} _ {\\text {T e x t u a l}} \\left(\\left\\{\\mathcal {E} ^ {G T} \\right\\} \\cup \\left\\{\\mathcal {E} _ {i} ^ {C F} \\right\\} _ {i = 1} ^ {| \\mathbb {E} ^ {C F} |}\\right)",
          "label": "eq-15"
        },
        {
          "id": "paragraph-8910076d-94e2-4b7b-87b2-6871bb7fc101",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{P}^{GT}"
              },
              {
                "type": "text",
                "content": " represents the embedding of the ground-truth event, and "
              },
              {
                "type": "inline-math",
                "latex": "\\{\\mathbf{P}_i^{CF}\\}_{i=1}^{\\|\\mathbb{E}^{CF}\\|}"
              },
              {
                "type": "text",
                "content": " represents the embeddings of the sampled counterfactual events."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{P}^{GT}"
              },
              {
                "type": "text",
                "content": " 表示真实事件的嵌入，"
              },
              {
                "type": "inline-math",
                "latex": "\\{\\mathbf{P}_i^{CF}\\}_{i=1}^{\\|\\mathbb{E}^{CF}\\|}"
              },
              {
                "type": "text",
                "content": " 表示采样反事实事件的嵌入。"
              }
            ]
          }
        },
        {
          "id": "paragraph-d0ed580b-7cc2-437a-85c0-66b6cb3fb227",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "The time-series encoder is used to encode the historical time-series segment "
              },
              {
                "type": "inline-math",
                "latex": "X"
              },
              {
                "type": "text",
                "content": " aligned with the ground-truth event, resulting in the time-series embedding:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "时间序列编码器用于编码与真实事件对齐的历史时间序列段 "
              },
              {
                "type": "inline-math",
                "latex": "X"
              },
              {
                "type": "text",
                "content": "，得到时间序列嵌入："
              }
            ]
          }
        },
        {
          "id": "math-8b873906-c365-495f-a6a4-7abb95ed1bc9",
          "type": "math",
          "latex": "\\mathbf {T} = \\mathbf {C A M E F} _ {\\text {T i m e - S e r i e s}} (\\mathcal {X})",
          "label": "eq-16"
        },
        {
          "id": "paragraph-9ba1a3ad-65df-4f9c-aa89-8290be848e6e",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Triplet Loss: The triplet loss is applied to enforce that the ground-truth event embedding "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{P}^{GT}"
              },
              {
                "type": "text",
                "content": " is closer to the time-series embedding "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{T}"
              },
              {
                "type": "text",
                "content": " than any counterfactual event embedding "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{P}_i^{CF}"
              },
              {
                "type": "text",
                "content": ", by a margin "
              },
              {
                "type": "inline-math",
                "latex": "\\alpha"
              },
              {
                "type": "text",
                "content": " (set to 1.0):"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "三元组损失：应用三元组损失以强制真实事件嵌入 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{P}^{GT}"
              },
              {
                "type": "text",
                "content": " 比任何反事实事件嵌入 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{P}_i^{CF}"
              },
              {
                "type": "text",
                "content": " 更接近时间序列嵌入 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{T}"
              },
              {
                "type": "text",
                "content": "，边界为 "
              },
              {
                "type": "inline-math",
                "latex": "\\alpha"
              },
              {
                "type": "text",
                "content": "（设为1.0）："
              }
            ]
          }
        },
        {
          "id": "table-300562e2-d6df-47e6-b6b9-5c2c61e73e1b",
          "type": "table",
          "caption": {
            "en": [
              {
                "type": "text",
                "content": "Financial Forecasting Results (MSE and MAE Scores) for CAMEF and Baselines Across Various Financial Assets: S&P500 (SPX), Dow Industrials (INDU), Nasdaq100 (NDX) Index, US 1-Month Treasury Bond (USGG1M), and US 5-Year Treasury Bond (USGG5YR)."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "CAMEF与基线模型在多种金融资产上的财务预测结果（MSE和MAE分数）：标普500（SPX）、道琼斯工业平均指数（INDU）、纳斯达克100指数（NDX）、美国1个月期国债（USGG1M）和美国5年期国债（USGG5YR）。"
              }
            ]
          },
          "headers": [
            ""
          ],
          "rows": [
            [
              ""
            ]
          ]
        },
        {
          "id": "table-d0534f4a-01bc-4c83-af11-fcefec4c3b69",
          "type": "table",
          "caption": {
            "en": [
              {
                "type": "text",
                "content": "Model performance comparison across different datasets and forecasting lengths"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "不同数据集和预测长度下的模型性能比较"
              }
            ]
          },
          "headers": [
            "Model/Datasets",
            "Forecasting Length",
            "SP500 (SPX) MSE",
            "SP500 (SPX) MAE",
            "Dow Industrial (INDU) MSE",
            "Dow Industrial (INDU) MAE",
            "NASDAQ (NDX) MSE",
            "NASDAQ (NDX) MAE",
            "USGG1M MSE",
            "USGG1M MAE",
            "USGG5YR MSE",
            "USGG5YR MAE"
          ],
          "rows": [
            [
              "ARIMA",
              "35",
              "0.0032628",
              "0.0308016",
              "0.0121513",
              "0.0523810",
              "0.0065253",
              "0.0435694",
              "0.0072223",
              "0.0262512",
              "0.0038973",
              "0.0340227"
            ],
            [
              "ARIMA",
              "70",
              "0.0035361",
              "0.0352004",
              "0.0139245",
              "0.0656002",
              "0.0082324",
              "0.0520933",
              "0.0028710",
              "0.0304132",
              "0.0039441",
              "0.0366630"
            ],
            [
              "ARIMA",
              "140",
              "0.0051080",
              "0.0439935",
              "0.0219147",
              "0.0793471",
              "0.0118692",
              "0.0665155",
              "0.0089949",
              "0.0338275",
              "0.0050746",
              "0.0455617"
            ],
            [
              "DLinear",
              "35",
              "0.0144331",
              "0.0896910",
              "0.0395136",
              "0.1380539",
              "0.0183989",
              "0.0999178",
              "0.0108576",
              "0.0706170",
              "0.0147211",
              "0.0876379"
            ],
            [
              "DLinear",
              "70",
              "0.0120578",
              "0.0817373",
              "0.0406573",
              "0.1282699",
              "0.0189431",
              "0.0972439",
              "0.0093591",
              "0.0678380",
              "0.0146430",
              "0.0881574"
            ],
            [
              "DLinear",
              "140",
              "0.0178138",
              "0.0931039",
              "0.0747210",
              "0.1724027",
              "0.0344153",
              "0.1287803",
              "0.0101465",
              "0.0645396",
              "0.0179185",
              "0.0977673"
            ],
            [
              "Autoformer",
              "35",
              "0.0068136",
              "0.0540556",
              "0.0277636",
              "0.0975948",
              "0.0135249",
              "0.0796486",
              "0.0047505",
              "0.0388076",
              "0.0092717",
              "0.0622862"
            ],
            [
              "Autoformer",
              "70",
              "0.0088997",
              "0.0628341",
              "0.0375279",
              "0.1185710",
              "0.0185264",
              "0.0933398",
              "0.0065554",
              "0.0471531",
              "0.0113750",
              "0.0727373"
            ],
            [
              "Autoformer",
              "140",
              "0.0158248",
              "0.0829188",
              "0.0772580",
              "0.1640365",
              "0.0334504",
              "0.1262163",
              "0.0086212",
              "0.0533337",
              "0.0152298",
              "0.0875821"
            ],
            [
              "FEDformer",
              "35",
              "0.0072377",
              "0.0576221",
              "0.0304808",
              "0.1044447",
              "0.0128668",
              "0.0758742",
              "0.0063596",
              "0.0519141",
              "0.0094995",
              "0.0494306"
            ],
            [
              "FEDformer",
              "70",
              "0.0088056",
              "0.0621386",
              "0.0399824",
              "0.1229772",
              "0.0171008",
              "0.0889995",
              "0.0062841",
              "0.0448822",
              "0.0099615",
              "0.0664197"
            ],
            [
              "FEDformer",
              "140",
              "0.0157429",
              "0.0819469",
              "0.0786426",
              "0.1677705",
              "0.0313433",
              "0.1214097",
              "0.0083784",
              "0.0518365",
              "0.0131231",
              "0.0782861"
            ],
            [
              "iTransformer",
              "35",
              "0.0064209",
              "0.0516341",
              "0.0270860",
              "0.0927605",
              "0.0125008",
              "0.0751656",
              "0.0011000",
              "0.0155975",
              "0.0056660",
              "0.0183524"
            ],
            [
              "iTransformer",
              "70",
              "0.0069612",
              "0.0540920",
              "0.0304566",
              "0.1038424",
              "0.0151214",
              "0.0816262",
              "0.0021811",
              "0.0221315",
              "0.0011721",
              "0.0226975"
            ],
            [
              "iTransformer",
              "140",
              "0.0128021",
              "0.0718771",
              "0.0680991",
              "0.1486782",
              "0.0254479",
              "0.1047119",
              "0.0052255",
              "0.0327429",
              "0.0017441",
              "0.0282537"
            ],
            [
              "PatchTST",
              "35",
              "0.0063304",
              "0.0507462",
              "0.0293131",
              "0.0989455",
              "0.0122679",
              "0.0764552",
              "0.0012060",
              "0.0163610",
              "0.0063078",
              "0.0520734"
            ],
            [
              "PatchTST",
              "70",
              "0.0072471",
              "0.0547738",
              "0.0339444",
              "0.1116023",
              "0.0153753",
              "0.0824677",
              "0.0021643",
              "0.0223036",
              "0.0079617",
              "0.0606007"
            ],
            [
              "PatchTST",
              "140",
              "0.0130219",
              "0.0712171",
              "0.0688582",
              "0.1452592",
              "0.0256001",
              "0.1047749",
              "0.0054544",
              "0.0341517",
              "0.0118553",
              "0.0747537"
            ],
            [
              "GPT4MTS",
              "35",
              "0.00795088",
              "0.0674255",
              "0.0026558",
              "0.0417553",
              "0.0011035",
              "0.0240469",
              "0.0017016",
              "0.0309320",
              "0.0028713",
              "0.0389277"
            ],
            [
              "GPT4MTS",
              "70",
              "0.00171038",
              "0.0305950",
              "0.0027033",
              "0.0393112",
              "0.0016205",
              "0.0336116",
              "0.0019098",
              "0.0279222",
              "0.0023371",
              "0.0354777"
            ],
            [
              "GPT4MTS",
              "140",
              "0.00212612",
              "0.0330497",
              "0.0045029",
              "0.0458267",
              "0.0025175",
              "0.0341671",
              "0.0013648",
              "0.0260887",
              "0.0037004",
              "0.0449272"
            ],
            [
              "TEST",
              "35",
              "0.00073333",
              "0.0199733",
              "0.0026572",
              "0.0296887",
              "0.0006593",
              "0.0194091",
              "0.0003252",
              "0.0137511",
              "0.0013633",
              "0.0265036"
            ],
            [
              "TEST",
              "70",
              "0.00078762",
              "0.0205412",
              "0.0088903",
              "0.0599179",
              "0.0010678",
              "0.0248594",
              "0.0010515",
              "0.0182706",
              "0.0034630",
              "0.0415002"
            ],
            [
              "TEST",
              "140",
              "0.00278572",
              "0.0467150",
              "0.0070749",
              "0.0557744",
              "0.0020130",
              "0.0362325",
              "0.0006995",
              "0.0207850",
              "0.0024356",
              "0.0375164"
            ],
            [
              "CAMEF",
              "35",
              "0.00048860",
              "0.0154050",
              "0.0025349",
              "0.0366245",
              "0.0005468",
              "0.0178845",
              "0.0002883",
              "0.0118010",
              "0.0013234",
              "0.0260618"
            ],
            [
              "CAMEF",
              "70",
              "0.00064780",
              "0.0178691",
              "0.0025042",
              "0.0365500",
              "0.0005814",
              "0.0162882",
              "0.0004402",
              "0.0139699",
              "0.0020701",
              "0.0326371"
            ],
            [
              "CAMEF",
              "140",
              "0.0010756",
              "0.0210284",
              "0.0039313",
              "0.0383459",
              "0.0010159",
              "0.0207716",
              "0.0004938",
              "0.0148485",
              "0.0022458",
              "0.0336680"
            ]
          ]
        },
        {
          "id": "math-0fab1a52-f19e-4c9a-bc33-ab9cd6665ad6",
          "type": "math",
          "latex": "\\mathcal {L} _ {\\text {C a u s a l - T L}} = \\max  \\left(0, d \\left(\\mathbf {P} ^ {G T}, \\mathbf {T}\\right) - d \\left(\\mathbf {P} _ {i} ^ {C F}, \\mathbf {T}\\right) + \\alpha\\right)",
          "label": "eq-17"
        },
        {
          "id": "paragraph-e8754209-0caf-40c3-a828-88fbaa8c9d55",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where  "
              },
              {
                "type": "inline-math",
                "latex": "d(\\cdot, \\cdot)"
              },
              {
                "type": "text",
                "content": "  denotes the distance between two embeddings (e.g., cosine similarity or Euclidean distance). This loss function encourages the model to capture the causal relationships between events and time-series movements by penalizing counterfactual events that deviate from the causal signal of the ground-truth event."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中 "
              },
              {
                "type": "inline-math",
                "latex": "d(\\cdot, \\cdot)"
              },
              {
                "type": "text",
                "content": " 表示两个嵌入之间的距离（例如余弦相似度或欧几里得距离）。该损失函数通过惩罚偏离真实事件因果信号的反事实事件，鼓励模型捕捉事件与时间序列变动之间的因果关系。"
              }
            ]
          }
        },
        {
          "id": "paragraph-df3ece20-23e1-4077-b712-f85db0a8634b",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "The combination of diverse counterfactual sampling and causal learning ensures that CAMEF effectively learns the true causal drivers of financial market movements, improving its robustness and predictive power."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "多样化的反事实采样和因果学习的结合确保CAMEF有效学习金融市场变动的真实因果驱动因素，提高其鲁棒性和预测能力。"
              }
            ]
          }
        },
        {
          "id": "paragraph-89993336-384f-4065-983d-f4ec406d1d6d",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Total Loss: The overall training loss for CAMEF is defined as:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "总损失：CAMEF的整体训练损失定义为："
              }
            ]
          }
        },
        {
          "id": "math-3ba728e7-1451-4c3e-83b7-0a010b9dd3f4",
          "type": "math",
          "latex": "\\mathcal {L} _ {\\text {T o t a l}} = \\mathcal {L} _ {\\text {T i m e}} + \\mathcal {L} _ {\\text {C a u s a l - T L}}",
          "label": "eq-18"
        },
        {
          "id": "paragraph-3ff3259c-c926-46f2-b8b4-4ef2f56c767b",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{L}_{\\mathrm{Time}}"
              },
              {
                "type": "text",
                "content": "  is the objective for time series forecasting, as defined in "
              },
              {
                "type": "equation-ref",
                "equationId": "eq-14",
                "displayText": "Equation 14"
              },
              {
                "type": "text",
                "content": "."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中 "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{L}_{\\mathrm{Time}}"
              },
              {
                "type": "text",
                "content": " 是时间序列预测的目标，如公式14所定义。"
              }
            ]
          }
        }
      ],
      "subsections": []
    },
    {
      "id": "section-daa52742-6a55-4a10-95e8-1975cc267ac1",
      "title": {
        "en": "Experiments",
        "zh": "实验"
      },
      "content": [
        {
          "id": "paragraph-3fbe5599-91f1-4b04-843d-76a9e33df678",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "In this section, we evaluate CAMEF by addressing the following key questions: RQ1. Accuracy: How accurately does CAMEF forecast final market based on events? RQ2. Model Effectiveness: How do different components enhance CAMEF's predictive performance? RQ3. Event Analysis: Which types of events exhibit stronger influences to financial market?"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "在本节中，我们通过解决以下关键问题来评估CAMEF：RQ1. 准确性：CAMEF基于事件预测最终市场的准确度如何？RQ2. 模型有效性：不同组件如何增强CAMEF的预测性能？RQ3. 事件分析：哪些类型的事件对金融市场表现出更强的影响？"
              }
            ]
          }
        }
      ],
      "subsections": [
        {
          "id": "section-3f7a3394-6b39-45ad-9b8e-ff3e4183844a",
          "title": {
            "en": "Experimental Settings",
            "zh": "实验设置"
          },
          "content": [],
          "subsections": [
            {
              "id": "section-5947fa2d-fb12-4d0e-900f-49bb5af2405a",
              "title": {
                "en": "Datasets",
                "zh": "数据集"
              },
              "content": [
                {
                  "id": "paragraph-e9316e83-b36e-46ff-b21d-844188447c29",
                  "type": "paragraph",
                  "content": {
                    "en": [
                      {
                        "type": "text",
                        "content": "We utilized the collected event scripts and time-series data as outlined in Sec. 4 and detailed in Appendix B. The dataset was divided into training, validation, and testing sets in a 6:2:2 ratio. The training set was used to train the models, while the validation set was used for convergence checking and early stopping to prevent overfitting. The final results, based on the test set, are reported in "
                      },
                      {
                        "type": "table-ref",
                        "tableId": "table-2",
                        "displayText": "Table 2"
                      },
                      {
                        "type": "text",
                        "content": "."
                      }
                    ],
                    "zh": [
                      {
                        "type": "text",
                        "content": "我们使用了第4节概述并在附录B中详细说明的收集的事件脚本和时间序列数据。数据集按6:2:2的比例划分为训练集、验证集和测试集。训练集用于训练模型，而验证集用于收敛检查和早停以防止过拟合。基于测试集的最终结果报告在表2中。"
                      }
                    ]
                  }
                }
              ],
              "subsections": []
            },
            {
              "id": "section-c20db5d2-1085-41fa-a97a-ad801a5d002f",
              "title": {
                "en": "Baselines",
                "zh": "基线方法"
              },
              "content": [
                {
                  "id": "paragraph-962b0071-cc50-47a2-b40c-3001075b8b9c",
                  "type": "paragraph",
                  "content": {
                    "en": [
                      {
                        "type": "text",
                        "content": "To evaluate our proposed method, we compare it against both uni-modal and multi-modal time series forecasting approaches. For the uni-modal baselines, we considered the traditional yet robust ARIMA model "
                      },
                      {
                        "type": "citation",
                        "referenceIds": [
                          "ref-6"
                        ],
                        "displayText": "[6]"
                      },
                      {
                        "type": "text",
                        "content": ", the linear neural model DLlinear "
                      },
                      {
                        "type": "citation",
                        "referenceIds": [
                          "ref-59"
                        ],
                        "displayText": "[59]"
                      },
                      {
                        "type": "text",
                        "content": ", and several state-of-the-art transformer-based time-series models, including AutoFormer "
                      },
                      {
                        "type": "citation",
                        "referenceIds": [
                          "ref-8"
                        ],
                        "displayText": "[8]"
                      },
                      {
                        "type": "text",
                        "content": ", FEDformer "
                      },
                      {
                        "type": "citation",
                        "referenceIds": [
                          "ref-61"
                        ],
                        "displayText": "[61]"
                      },
                      {
                        "type": "text",
                        "content": ", and iTransformer "
                      },
                      {
                        "type": "citation",
                        "referenceIds": [
                          "ref-30"
                        ],
                        "displayText": "[30]"
                      },
                      {
                        "type": "text",
                        "content": ". For the multi-modal baselines, we included TEST "
                      },
                      {
                        "type": "citation",
                        "referenceIds": [
                          "ref-51"
                        ],
                        "displayText": "[51]"
                      },
                      {
                        "type": "text",
                        "content": " and GPT4MTS "
                      },
                      {
                        "type": "citation",
                        "referenceIds": [
                          "ref-24"
                        ],
                        "displayText": "[24]"
                      },
                      {
                        "type": "text",
                        "content": "."
                      }
                    ],
                    "zh": [
                      {
                        "type": "text",
                        "content": "为了评估我们提出的方法，我们将其与单模态和多模态时间序列预测方法进行比较。对于单模态基线，我们考虑了传统但稳健的ARIMA模型"
                      },
                      {
                        "type": "citation",
                        "referenceIds": [
                          "ref-6"
                        ],
                        "displayText": "[6]"
                      },
                      {
                        "type": "text",
                        "content": "、线性神经模型DLlinear"
                      },
                      {
                        "type": "citation",
                        "referenceIds": [
                          "ref-59"
                        ],
                        "displayText": "[59]"
                      },
                      {
                        "type": "text",
                        "content": "以及几种最先进的基于Transformer的时间序列模型，包括AutoFormer"
                      },
                      {
                        "type": "citation",
                        "referenceIds": [
                          "ref-8"
                        ],
                        "displayText": "[8]"
                      },
                      {
                        "type": "text",
                        "content": "、FEDformer"
                      },
                      {
                        "type": "citation",
                        "referenceIds": [
                          "ref-61"
                        ],
                        "displayText": "[61]"
                      },
                      {
                        "type": "text",
                        "content": "和iTransformer"
                      },
                      {
                        "type": "citation",
                        "referenceIds": [
                          "ref-30"
                        ],
                        "displayText": "[30]"
                      },
                      {
                        "type": "text",
                        "content": "。对于多模态基线，我们包含了TEST"
                      },
                      {
                        "type": "citation",
                        "referenceIds": [
                          "ref-51"
                        ],
                        "displayText": "[51]"
                      },
                      {
                        "type": "text",
                        "content": "和GPT4MTS"
                      },
                      {
                        "type": "citation",
                        "referenceIds": [
                          "ref-24"
                        ],
                        "displayText": "[24]"
                      },
                      {
                        "type": "text",
                        "content": "。"
                      }
                    ]
                  }
                }
              ],
              "subsections": []
            },
            {
              "id": "section-09411b23-942d-4b90-89eb-a1616fe0ca78",
              "title": {
                "en": "Test Settings",
                "zh": "测试设置"
              },
              "content": [
                {
                  "id": "paragraph-59cc4661-4bdd-48d5-bfbc-50c84c59eefd",
                  "type": "paragraph",
                  "content": {
                    "en": [
                      {
                        "type": "text",
                        "content": "We evaluate the baselines and CAMEF across three time horizons—short, medium, and long run, to simulate real investment behavior. For each aligned pair of event and time-series data "
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\left[\\mathcal{X}_{i - \\tau ;i + \\tau}\\mapsto \\mathcal{E}_i\\right]"
                      },
                      {
                        "type": "text",
                        "content": " as defined in Sec. 3, we use the event script "
                      },
                      {
                        "type": "inline-math",
                        "latex": "(\\mathcal{X})"
                      },
                      {
                        "type": "text",
                        "content": " and the time-series segment preceding the event time point "
                      },
                      {
                        "type": "inline-math",
                        "latex": "i"
                      },
                      {
                        "type": "text",
                        "content": ", i.e., "
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\mathcal{X}_{i - \\tau ;i}"
                      },
                      {
                        "type": "text",
                        "content": ", to forecast the future time-series segment "
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\mathcal{X}_{i + 1:i + \\tau}"
                      },
                      {
                        "type": "text",
                        "content": ". The value of "
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\tau"
                      },
                      {
                        "type": "text",
                        "content": " is adjusted based on the time horizon: we set "
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\tau"
                      },
                      {
                        "type": "text",
                        "content": " to 35, 70, and 140 for short, medium, and long-term forecasts, respectively. These correspond to 175 minutes (about half a trading day), 350 minutes (about one trading day), and 700 minutes (about two trading days)."
                      }
                    ],
                    "zh": [
                      {
                        "type": "text",
                        "content": "我们在三个时间跨度——短期、中期和长期——上评估基线和CAMEF，以模拟真实投资行为。对于第3节中定义的每个对齐的事件和时间序列数据对"
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\left[\\mathcal{X}_{i - \\tau ;i + \\tau}\\mapsto \\mathcal{E}_i\\right]"
                      },
                      {
                        "type": "text",
                        "content": "，我们使用事件脚本"
                      },
                      {
                        "type": "inline-math",
                        "latex": "(\\mathcal{X})"
                      },
                      {
                        "type": "text",
                        "content": "和事件时间点"
                      },
                      {
                        "type": "inline-math",
                        "latex": "i"
                      },
                      {
                        "type": "text",
                        "content": "之前的时间序列段，即"
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\mathcal{X}_{i - \\tau ;i}"
                      },
                      {
                        "type": "text",
                        "content": "，来预测未来的时间序列段"
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\mathcal{X}_{i + 1:i + \\tau}"
                      },
                      {
                        "type": "text",
                        "content": "。"
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\tau"
                      },
                      {
                        "type": "text",
                        "content": "的值根据时间跨度调整：对于短期、中期和长期预测，我们分别将"
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\tau"
                      },
                      {
                        "type": "text",
                        "content": "设置为35、70和140。这些对应175分钟（约半个交易日）、350分钟（约一个交易日）和700分钟（约两个交易日）。"
                      }
                    ]
                  }
                },
                {
                  "id": "table-efa5a27d-eabb-466f-ae68-23bac3d66157",
                  "type": "table",
                  "caption": {
                    "en": [
                      {
                        "type": "text",
                        "content": "Ablation Study Results (MSE) Evaluating the CAMEF Model Components at Forecasting Lengths of 35, 70, and 140"
                      }
                    ],
                    "zh": [
                      {
                        "type": "text",
                        "content": "消融研究结果（MSE）评估CAMEF模型组件在预测长度35、70和140上的表现"
                      }
                    ]
                  },
                  "headers": [
                    "Textual Causal",
                    "Feature GPT2 Fusion Decoder Regression",
                    "SPX-35",
                    "SPX-70",
                    "SPX-140",
                    "INDU-35",
                    "INDU-70",
                    "INDU-140",
                    "NDX-35",
                    "NDX-70",
                    "NDX-140",
                    "USGG1M-35",
                    "USGG1M-70",
                    "USGG1M-140",
                    "USGG5YR-35",
                    "USGG5YR-70",
                    "USGG5YR-140",
                    "AVERAGE-35",
                    "AVERAGE-70",
                    "AVERAGE-140"
                  ],
                  "rows": [
                    [
                      "X",
                      "✓",
                      "✓",
                      "✓",
                      "✓",
                      "0.00074",
                      "0.00340",
                      "0.00120",
                      "0.00340",
                      "0.00330",
                      "0.01033",
                      "0.00131",
                      "0.00097",
                      "0.00197",
                      "0.00080",
                      "0.00179",
                      "0.00092",
                      "0.00222",
                      "0.00276",
                      "0.00380",
                      "0.00169",
                      "0.00199",
                      "0.00364"
                    ],
                    [
                      "✓",
                      "X",
                      "✓",
                      "✓",
                      "✓",
                      "0.00068",
                      "0.00095",
                      "0.00106",
                      "0.02939",
                      "0.00281",
                      "0.00533",
                      "0.00064",
                      "0.00073",
                      "0.00121",
                      "0.00065",
                      "0.00083",
                      "0.00099",
                      "0.00160",
                      "0.00220",
                      "0.00308",
                      "0.00659",
                      "0.00170",
                      "0.00233"
                    ],
                    [
                      "✓",
                      "✓",
                      "X",
                      "✓",
                      "✓",
                      "0.00080",
                      "0.00079",
                      "0.00110",
                      "0.01173",
                      "0.00391",
                      "0.00581",
                      "0.00069",
                      "0.00073",
                      "0.00168",
                      "0.00047",
                      "0.00046",
                      "0.00216",
                      "0.00251",
                      "0.00306",
                      "0.00426",
                      "0.00324",
                      "0.00212",
                      "0.00300"
                    ],
                    [
                      "✓",
                      "✓",
                      "✓",
                      "✓",
                      "X",
                      "0.00073",
                      "0.00067",
                      "0.00114",
                      "0.26768",
                      "0.72387",
                      "0.18091",
                      "0.00062",
                      "0.00069",
                      "0.00158",
                      "0.00043",
                      "0.02110",
                      "0.75057",
                      "0.00220",
                      "0.00309",
                      "0.00566",
                      "0.05433",
                      "0.14593",
                      "0.03801"
                    ],
                    [
                      "✓",
                      "✓",
                      "✓",
                      "✓",
                      "X",
                      "0.00662",
                      "0.03911",
                      "0.00979",
                      "0.50841",
                      "0.57007",
                      "0.22267",
                      "0.00774",
                      "0.00852",
                      "0.00950",
                      "0.28932",
                      "0.02110",
                      "0.75057",
                      "0.56705",
                      "0.06188",
                      "0.08251",
                      "0.27583",
                      "0.14014",
                      "0.21501"
                    ],
                    [
                      "Full CAMEF Model",
                      "",
                      "",
                      "0.00048",
                      "0.00064",
                      "0.00107",
                      "0.00253",
                      "0.00250",
                      "0.00393",
                      "0.00054",
                      "0.00058",
                      "0.00101",
                      "0.00028",
                      "0.00044",
                      "0.00049",
                      "0.00132",
                      "0.00207",
                      "0.00224",
                      "0.00104",
                      "0.00124",
                      "0.00174"
                    ]
                  ]
                },
                {
                  "id": "table-837e6b94-e683-4d7c-9061-2dacddd3d3fc",
                  "type": "table",
                  "caption": {
                    "en": [
                      {
                        "type": "text",
                        "content": "Ablation Study Results on Different Type of Events on S&P500 Index"
                      }
                    ],
                    "zh": [
                      {
                        "type": "text",
                        "content": "不同类型事件在S&P500指数上的消融研究结果"
                      }
                    ]
                  },
                  "headers": [
                    "Event Type",
                    "Forecasting Length = 35-MSE",
                    "Forecasting Length = 35-MAE",
                    "Forecasting Length = 70-MSE",
                    "Forecasting Length = 70-MAE",
                    "Forecasting Length = 140-MSE",
                    "Forecasting Length = 140-MAE"
                  ],
                  "rows": [
                    [
                      "Unemployment Insurance",
                      "0.0004870 ↓",
                      "0.0159497 ↑",
                      "0.0005199 ↓",
                      "0.0157778 ↓",
                      "0.0006948 ↓",
                      "0.0190141 ↓"
                    ],
                    [
                      "Employment Situation",
                      "0.0003923 ↓",
                      "0.0142684 ↓",
                      "0.0004612 ↓",
                      "0.0154431 ↓",
                      "0.0013767 ↑",
                      "0.0218677 ↑"
                    ],
                    [
                      "GDP Advance",
                      "0.0006203 ↑",
                      "0.0175397 ↑",
                      "0.0005897 ↓",
                      "0.0175464 ↑",
                      "0.0011554 ↑",
                      "0.0217548 ↑"
                    ],
                    [
                      "FOMC Minutes",
                      "0.0003401 ↓",
                      "0.0127694 ↓",
                      "0.0004448 ↓",
                      "0.0170094 ↓",
                      "0.0006433 ↓",
                      "0.0185657 ↓"
                    ],
                    [
                      "CPI Report",
                      "0.0005645 ↑",
                      "0.0160723 ↑",
                      "0.0010660 ↑",
                      "0.0212536 ↑",
                      "0.0008187 ↓",
                      "0.0197824 ↓"
                    ],
                    [
                      "PPI Report",
                      "0.0005275 ↑",
                      "0.0148434 ↓",
                      "0.0008054 ↑",
                      "0.0201844 ↑",
                      "0.0017646 ↑",
                      "0.0251856 ↑"
                    ],
                    [
                      "Full Selection",
                      "0.0004886",
                      "0.0152405",
                      "0.0006478",
                      "0.0178691",
                      "0.0010756",
                      "0.0210284"
                    ]
                  ]
                }
              ],
              "subsections": []
            },
            {
              "id": "section-73702d00-6a29-4d09-ab43-388dd4878881",
              "title": {
                "en": "Implementation Overview",
                "zh": "实现概述"
              },
              "content": [
                {
                  "id": "paragraph-0755cc08-a91e-4b20-8c4f-f5fe3fc19076",
                  "type": "paragraph",
                  "content": {
                    "en": [
                      {
                        "type": "text",
                        "content": "For the single-modality approaches (ARIMA, DLinear, AutoFormer, FEDformer, iTransformer, and PatchTST), we tested two methods: (1) training the models on continuous historical time-series data and testing on aligned event-based time-series segments from the test set, and (2) training the models directly on event-based time-series segments, and also test on the aligned event-based time-series segments from the test set. The second approach produced more accurate results, and these are the results presented in this paper. Specifically, for each aligned event data pair "
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\left[\\mathcal{X}_{i-\\tau:i+\\tau} \\mapsto \\mathcal{E}_i\\right]"
                      },
                      {
                        "type": "text",
                        "content": ", single-modality approaches use only the time-series segment preceding the event, "
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\mathcal{X}_{i-\\tau:i}"
                      },
                      {
                        "type": "text",
                        "content": ", to train the models and forecast the subsequent segment, "
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\mathcal{X}_{i+1:i+\\tau}"
                      },
                      {
                        "type": "text",
                        "content": "; and testing follows the same approach. Detailed settings for each model are provided in Appendix C."
                      }
                    ],
                    "zh": [
                      {
                        "type": "text",
                        "content": "对于单模态方法（ARIMA、DLinear、AutoFormer、FEDformer、iTransformer和PatchTST），我们测试了两种方法：（1）在连续历史时间序列数据上训练模型，并在测试集中的对齐事件时间序列段上进行测试；（2）直接在事件时间序列段上训练模型，并在测试集中的对齐事件时间序列段上进行测试。第二种方法产生了更准确的结果，本文展示的就是这些结果。具体来说，对于每个对齐的事件数据对"
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\left[\\mathcal{X}_{i-\\tau:i+\\tau} \\mapsto \\mathcal{E}_i\\right]"
                      },
                      {
                        "type": "text",
                        "content": "，单模态方法仅使用事件之前的时间序列段"
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\mathcal{X}_{i-\\tau:i}"
                      },
                      {
                        "type": "text",
                        "content": "来训练模型并预测后续段"
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\mathcal{X}_{i+1:i+\\tau}"
                      },
                      {
                        "type": "text",
                        "content": "；测试采用相同的方法。每个模型的详细设置见附录C。"
                      }
                    ]
                  }
                },
                {
                  "id": "paragraph-491a810f-dfe0-42d1-bf55-41d69b75e1fb",
                  "type": "paragraph",
                  "content": {
                    "en": [
                      {
                        "type": "text",
                        "content": "For the multi-modality approaches (GPT4MTS, TEST, and CAMEF), both the event script "
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\mathcal{E}_i"
                      },
                      {
                        "type": "text",
                        "content": " and the time-series segment preceding the event, "
                      },
                      {
                        "type": "inline-math",
                        "latex": "X_{i - \\tau :i}"
                      },
                      {
                        "type": "text",
                        "content": ", are used as input to train the models to forecast the post-event time-series segment, "
                      },
                      {
                        "type": "inline-math",
                        "latex": "X_{i + 1:i + \\tau}"
                      },
                      {
                        "type": "text",
                        "content": ". Implementation details, including model configurations and training settings, are explained in Appendix C."
                      }
                    ],
                    "zh": [
                      {
                        "type": "text",
                        "content": "对于多模态方法（GPT4MTS、TEST和CAMEF），事件脚本"
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\mathcal{E}_i"
                      },
                      {
                        "type": "text",
                        "content": "和事件之前的时间序列段"
                      },
                      {
                        "type": "inline-math",
                        "latex": "X_{i - \\tau :i}"
                      },
                      {
                        "type": "text",
                        "content": "都用作输入来训练模型，以预测事件后的时间序列段"
                      },
                      {
                        "type": "inline-math",
                        "latex": "X_{i + 1:i + \\tau}"
                      },
                      {
                        "type": "text",
                        "content": "。实现细节，包括模型配置和训练设置，在附录C中说明。"
                      }
                    ]
                  }
                }
              ],
              "subsections": []
            }
          ]
        },
        {
          "id": "section-6087ce3f-6a60-44f4-a4b6-068830f6e8f8",
          "title": {
            "en": "Experimental Results for Event-Driven Time-Series Forecasting (RQ1)",
            "zh": "事件驱动时间序列预测的实验结果（RQ1）"
          },
          "content": [
            {
              "id": "paragraph-c2fd147f-fe83-4a46-8816-a023f0652312",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "table-ref",
                    "tableId": "table-2",
                    "displayText": "Table 2"
                  },
                  {
                    "type": "text",
                    "content": " presents the forecasting results for the five datasets across short, medium, and long forecasting horizons. CAMEF outperformed other models in 24 out of 30 settings, achieving first-place rankings, and ranked second in the remaining 6 settings. Specifically, CAMEF demonstrated the best performance across all forecasting lengths for the Stock Market Indices (SPX, INDU, and NDX), except for short-horizon forecasting on INDU, highlighting its effectiveness in event-driven stock market forecasting. For treasury bonds, CAMEF achieved the best results across all forecasting lengths for the 1-month treasury bond (USGG1M) and ranked second for the 5-year treasury bond (USGG5YR). The slightly lower performance on USGG5YR suggests that long-run treasury bonds may be less sensitive to event-driven factors and more influenced by historical trends."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "表2展示了五个数据集在短期、中期和长期预测跨度上的预测结果。CAMEF在30个设置中的24个中优于其他模型，获得第一名排名，在其余6个设置中排名第二。具体来说，CAMEF在股票市场指数（SPX、INDU和NDX）的所有预测长度上表现出最佳性能，除了INDU的短期预测，突显了其在事件驱动股票市场预测中的有效性。对于国债，CAMEF在1个月期国债（USGG1M）的所有预测长度上取得了最佳结果，在5年期国债（USGG5YR）上排名第二。在USGG5YR上略低的性能表明长期国债可能对事件驱动因素较不敏感，而更受历史趋势的影响。"
                  }
                ]
              }
            },
            {
              "id": "paragraph-4ac13973-2a51-472b-83f6-204b8eb79062",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Compared to single-modality models (e.g., DLinear, Autoformer, FEDformer, PatchTST, and iTransformer), CAMEF achieved an average MSE reduction of  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "62.55\\%"
                  },
                  {
                    "type": "text",
                    "content": "  relative to the best-performing single-modality model, iTransformer. Among multi-modality models, CAMEF surpassed TEST, the second-best performer, with an average MSE reduction of  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "33.55\\%"
                  },
                  {
                    "type": "text",
                    "content": " ."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "与单模态模型（例如 DLinear、Autoformer、FEDformer、PatchTST 和 iTransformer）相比，CAMEF 相对于表现最佳的单模态模型 iTransformer 实现了平均 MSE 降低  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "62.55\\%"
                  },
                  {
                    "type": "text",
                    "content": " 。在多模态模型中，CAMEF 超越了表现第二好的 TEST，平均 MSE 降低  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "33.55\\%"
                  },
                  {
                    "type": "text",
                    "content": " 。"
                  }
                ]
              }
            },
            {
              "id": "paragraph-ac82c3e2-e3f4-46c6-b666-eaa6de37a4bf",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "These results highlight three key insights: (1) effectively leveraging multi-modality information provides significant performance gains, particularly for SPX, INDU, NDX, and USGG1M; (2) transformer-based methods consistently outperform classical models such as ARIMA; and (3) CAMEF's superior training and feature fusion strategies establish it as the most effective method for event-driven financial forecasting tasks."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "这些结果突出了三个关键见解：（1）有效利用多模态信息可带来显著的性能提升，特别是对于 SPX、INDU、NDX 和 USGG1M；（2）基于 transformer 的方法持续优于经典模型，如 ARIMA；（3）CAMEF 卓越的训练和特征融合策略使其成为事件驱动金融预测任务中最有效的方法。"
                  }
                ]
              }
            }
          ],
          "subsections": []
        },
        {
          "id": "section-2bde9668-0add-41a5-be79-9f5aee1355c3",
          "title": {
            "en": "Ablation Studies on Model Components",
            "zh": "模型组件消融研究"
          },
          "content": [
            {
              "id": "paragraph-618c7efa-916e-4b03-b4d8-ccc2a45af16f",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "To evaluate the effectiveness of each component in CAMEF, we conduct comprehensive ablation studies on Textual Modality, Causal Learning, Feature Fusion, GPT2 Decoder, and the Post-Regressor. Based on the full CAMEF model, we remove the corresponding neural layers, such as the RoBERTa encoder for textual modality or the causal learning component, to assess their individual contributions. The ablation results are presented in "
                  },
                  {
                    "type": "table-ref",
                    "tableId": "table-3",
                    "displayText": "Table 3"
                  },
                  {
                    "type": "text",
                    "content": ", where the left part of the table uses  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "\\checkmark"
                  },
                  {
                    "type": "text",
                    "content": "  or  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "\\times"
                  },
                  {
                    "type": "text",
                    "content": "  to indicate whether the specific component is included or excluded in the test. From the results, three key findings are: (1) The full CAMEF model achieves the best performance across all datasets, demonstrating the critical importance of utilizing both textual and time-series modalities; (2) Causal learning provides incremental improvements, confirming its value in capturing cause-effect relationships within the data; (3) The proposed feature fusion layers and GPT2 decoder effectively integrate and leverage multi-modality features, significantly enhancing the model's ability to decode time-series data. These findings underscore the necessity of each component in achieving optimal performance for event-driven financial forecasting tasks."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "为了评估 CAMEF 中每个组件的有效性，我们对文本模态、因果学习、特征融合、GPT2 解码器和后回归器进行了全面的消融研究。基于完整的 CAMEF 模型，我们移除了相应的神经层，例如用于文本模态的 RoBERTa 编码器或因果学习组件，以评估它们的个体贡献。消融结果呈现在表 3 中，其中表格左侧使用  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "\\checkmark"
                  },
                  {
                    "type": "text",
                    "content": "  或  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "\\times"
                  },
                  {
                    "type": "text",
                    "content": "  表示特定组件在测试中是否包含或排除。从结果中，三个关键发现是：（1）完整的 CAMEF 模型在所有数据集上实现了最佳性能，证明了利用文本和时间序列模态的关键重要性；（2）因果学习提供了增量改进，确认了其在捕捉数据中因果关系方面的价值；（3）提出的特征融合层和 GPT2 解码器有效整合并利用了多模态特征，显著增强了模型解码时间序列数据的能力。这些发现强调了每个组件在实现事件驱动金融预测任务最优性能中的必要性。"
                  }
                ]
              }
            },
            {
              "id": "table-8553d0b7-fceb-4a7f-a1db-43cc55f3d1fd",
              "type": "table",
              "caption": {
                "en": [
                  {
                    "type": "text",
                    "content": "Ablation results of CAMEF components"
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "CAMEF 组件消融结果"
                  }
                ]
              },
              "headers": [
                "Component",
                "Included",
                "Performance"
              ],
              "rows": [
                [
                  "Textual Modality",
                  "$\\checkmark$",
                  "High"
                ],
                [
                  "Causal Learning",
                  "$\\checkmark$",
                  "Medium"
                ],
                [
                  "Feature Fusion",
                  "$\\checkmark$",
                  "High"
                ]
              ]
            }
          ],
          "subsections": []
        },
        {
          "id": "section-1dcd7300-810b-4e54-9010-549818a8ae5b",
          "title": {
            "en": "Ablation Studies on Different Type of Events",
            "zh": "不同类型事件的消融研究"
          },
          "content": [
            {
              "id": "paragraph-5ee778f4-5861-4423-8f80-92ac98b32c85",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "table-ref",
                    "tableId": "table-4",
                    "displayText": "Table 4"
                  },
                  {
                    "type": "text",
                    "content": " shows the predictive performance of different events on the S&P500 Index. FOMC Minutes achieve the lowest MSE and MAE, confirming their critical importance for market prediction. Unemployment Insurance Claims and Unemployment Situation Reports also come with lower errors than the full selection, however the latter becomes less effective at long forecasting length. In contrast, CPI and PPI Reports show weaker predictive power, with PPI yielding the highest errors and CPI improving slightly at long forecasting length. These results emphasize the importance of FOMC and unemployment-related events for financial forecasting."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "表 4 显示了不同事件在 S&P500 指数上的预测性能。FOMC 会议纪要实现了最低的 MSE 和 MAE，确认了它们对市场预测的关键重要性。失业救济金申请和失业情况报告的错误也低于完整选择，但后者在长预测长度时效果较差。相比之下，CPI 和 PPI 报告显示出较弱的预测能力，PPI 产生最高错误，而 CPI 在长预测长度时略有改善。这些结果强调了 FOMC 和失业相关事件对金融预测的重要性。"
                  }
                ]
              }
            },
            {
              "id": "table-9293a115-f365-4447-9604-3a28dd3eab50",
              "type": "table",
              "caption": {
                "en": [
                  {
                    "type": "text",
                    "content": "Predictive performance of events on S&P500"
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "事件在 S&P500 上的预测性能"
                  }
                ]
              },
              "headers": [
                "Event Type",
                "MSE",
                "MAE"
              ],
              "rows": [
                [
                  "FOMC Minutes",
                  "Lowest",
                  "Lowest"
                ],
                [
                  "Unemployment Insurance Claims",
                  "Low",
                  "Low"
                ],
                [
                  "Unemployment Situation Reports",
                  "Low",
                  "Medium"
                ],
                [
                  "CPI Reports",
                  "High",
                  "High"
                ],
                [
                  "PPI Reports",
                  "Highest",
                  "Highest"
                ]
              ]
            },
            {
              "id": "figure-646dd150-6f40-4b41-af5e-a7a577cfd8fa",
              "type": "figure",
              "src": "/uploads/images/5f6810f9-e873-442a-9010-512a38761b5c/figure-646dd150-6f40-4b41-af5e-a7a577cfd8fa.jpg",
              "alt": "Graph showing performance vs counterfactual sample size",
              "caption": {
                "en": [
                  {
                    "type": "text",
                    "content": "Effect of counterfactual sample size "
                  },
                  {
                    "type": "inline-math",
                    "latex": "(\\alpha)"
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "反事实样本大小 "
                  },
                  {
                    "type": "inline-math",
                    "latex": "(\\alpha)"
                  },
                  {
                    "type": "text",
                    "content": " 的影响"
                  }
                ]
              },
              "description": {},
              "uploadedFilename": "figure-646dd150-6f40-4b41-af5e-a7a577cfd8fa.jpg"
            },
            {
              "id": "figure-1334126b-7eba-4f89-be8d-4644b3af3095",
              "type": "figure",
              "src": "/uploads/images/5f6810f9-e873-442a-9010-512a38761b5c/figure-1334126b-7eba-4f89-be8d-4644b3af3095.jpg",
              "alt": "Graph showing performance vs post-regressor depth",
              "caption": {
                "en": [
                  {
                    "type": "text",
                    "content": "Effect of post-regressor depth (k)"
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "后回归器深度 (k) 的影响"
                  }
                ]
              },
              "description": {},
              "uploadedFilename": "figure-1334126b-7eba-4f89-be8d-4644b3af3095.jpg"
            },
            {
              "id": "paragraph-4dccfa45-b93e-455e-b856-efe3cded99bf",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "figure-ref",
                    "figureId": "fig-4",
                    "displayText": "Figure 4"
                  },
                  {
                    "type": "text",
                    "content": ": Sensitivity analysis of CAMEF on the SP500 dataset with respect to key hyperparameters."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "图 4：CAMEF 在 SP500 数据集上对关键超参数的敏感性分析。"
                  }
                ]
              }
            }
          ],
          "subsections": []
        },
        {
          "id": "section-cb7c2d59-4a69-4790-9d4b-946f70644027",
          "title": {
            "en": "Parameter Sensitivity Analysis",
            "zh": "参数敏感性分析"
          },
          "content": [
            {
              "id": "paragraph-9bbf4e86-a6d5-401c-aa1f-d1e8819ecc9e",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "We examine the impact of two key hyperparameters in CAMEF on SPX dataset with 35 predictive length: the number of counterfactual samples  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "(\\alpha)"
                  },
                  {
                    "type": "text",
                    "content": "  and the depth of the post-regressor network  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "(k)"
                  },
                  {
                    "type": "text",
                    "content": " . The number of GPT-2 layers  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "(l)"
                  },
                  {
                    "type": "text",
                    "content": "  remains fixed, as we adopt the pre-trained model without modification. As shown in "
                  },
                  {
                    "type": "figure-ref",
                    "figureId": "fig-4",
                    "displayText": "Figure 4"
                  },
                  {
                    "type": "text",
                    "content": ", increasing  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "\\alpha"
                  },
                  {
                    "type": "text",
                    "content": "  enhances forecasting accuracy through stronger contrastive supervision, with performance gains saturating around  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "\\alpha = 10"
                  },
                  {
                    "type": "text",
                    "content": " . Similarly, increasing  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "k"
                  },
                  {
                    "type": "text",
                    "content": "  improves decoding capacity, though with diminishing returns beyond  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "k = 4"
                  },
                  {
                    "type": "text",
                    "content": " . These trends suggest that CAMEF performs robustly across a range of configurations, benefiting from moderate complexity increases without overfitting."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "我们检查了 CAMEF 中两个关键超参数在 SPX 数据集上（预测长度为 35）的影响：反事实样本数量  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "(\\alpha)"
                  },
                  {
                    "type": "text",
                    "content": "  和后回归器网络深度  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "(k)"
                  },
                  {
                    "type": "text",
                    "content": " 。GPT-2 层数  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "(l)"
                  },
                  {
                    "type": "text",
                    "content": "  保持固定，因为我们采用未经修改的预训练模型。如图 4 所示，增加  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "\\alpha"
                  },
                  {
                    "type": "text",
                    "content": "  通过更强的对比监督提高了预测准确性，性能增益在  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "\\alpha = 10"
                  },
                  {
                    "type": "text",
                    "content": "  左右饱和。类似地，增加  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "k"
                  },
                  {
                    "type": "text",
                    "content": "  提高了解码能力，但在  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "k = 4"
                  },
                  {
                    "type": "text",
                    "content": "  之后收益递减。这些趋势表明 CAMEF 在一系列配置中表现稳健，受益于适度的复杂性增加而不会过拟合。"
                  }
                ]
              }
            }
          ],
          "subsections": []
        }
      ]
    },
    {
      "id": "section-6dfe014a-55e6-4401-9e9e-7d681a07a531",
      "title": {
        "en": "Conclusion and Future Work",
        "zh": "结论与未来工作"
      },
      "content": [
        {
          "id": "paragraph-365b8e45-779c-4a53-929f-a438dca362ef",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "This paper proposed CAMEF, a multi-modality model for event-driven financial forecasting, which integrates effective causal learning and an LLM-based counterfactual event augmentation strategy. Alongside the model, we introduced a novel synthetic dataset comprising 6 types of salient macroeconomic event scripts, their counterfactual samples, and high-frequency time-series data for 5 key financial assets, aligned with real-world investment practices. Extensive experiments demonstrated CAMEF's superior predictive performance compared to prior deep time-series and multi-modality methods. Ablation studies testified the importance of causal learning and other designed components of CAMEF. Additionally, it is found that FOMC and unemployment-related events provided the most predictive value among the tested event types."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "本文提出了 CAMEF，一个用于事件驱动金融预测的多模态模型，它整合了有效的因果学习和基于 LLM 的反事实事件增强策略。除了模型外，我们引入了一个新颖的合成数据集，包含 6 种显著宏观经济事件脚本、它们的反事实样本和 5 个关键金融资产的高频时间序列数据，与现实世界投资实践对齐。广泛实验证明了 CAMEF 相较于先前深度时间序列和多模态方法的优越预测性能。消融研究证实了因果学习和 CAMEF 其他设计组件的重要性。此外，发现 FOMC 和失业相关事件在测试的事件类型中提供了最高的预测价值。"
              }
            ]
          }
        },
        {
          "id": "paragraph-16dcefa0-c893-46ce-9e88-56e21edfbc26",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "For future work, we plan to leverage advanced LLMs for enhanced textual encoding to extract deeper semantic information, refine the cross-modality causal inference mechanisms, and expand the dataset to include additional event types, such as political events and corporate market-sensitive news."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "对于未来工作，我们计划利用先进的 LLM 进行增强的文本编码以提取更深层的语义信息，改进跨模态因果推理机制，并扩展数据集以包含额外的事件类型，例如政治事件和公司市场敏感新闻。"
              }
            ]
          }
        }
      ],
      "subsections": []
    },
    {
      "id": "section-f3a9dcc3-a378-4cce-9c4c-b3e865fda1af",
      "title": {
        "en": "Acknowledgements",
        "zh": "致谢"
      },
      "content": [
        {
          "id": "paragraph-615c7ee8-2eef-4f3a-bc04-d867606562cd",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "This work was supported in part by the National Natural Science Foundation of China (NSFC) under Grant Nos. 62402396 and 72471197. We would like to thank the anonymous reviewers for their valuable comments and suggestions that helped improve the quality of this paper."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "本工作部分得到了中国国家自然科学基金（NSFC）资助，项目编号为 62402396 和 72471197。我们感谢匿名评审的宝贵评论和建议，帮助提高了本文的质量。"
              }
            ]
          }
        }
      ],
      "subsections": []
    },
    {
      "id": "section-b129f692-a1b4-435f-bf41-42252f85f676",
      "title": {
        "en": "References",
        "zh": "参考文献"
      },
      "content": [
        {
          "id": "unordered-list-d988dc67-db49-423e-8bdf-71496003f53c",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-1"
                    ],
                    "displayText": "[1]"
                  },
                  {
                    "type": "text",
                    "content": " Adebiyi A. Ariyo, Adewumi O. Adewumi, and Charles K. Ayo. [n.d.]. Stock Price Prediction Using the ARIMA Model. In UKSim-AMSS 2014."
                  }
                ],
                "zh": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-1"
                    ],
                    "displayText": "[1]"
                  },
                  {
                    "type": "text",
                    "content": " Adebiyi A. Ariyo、Adewumi O. Adewumi 和 Charles K. Ayo。[未注明日期]。使用 ARIMA 模型进行股票价格预测。载于 UKSim-AMSS 2014。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "unordered-list-15edae68-ca03-4eb3-a82c-bba62ac1dcaf",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-2"
                    ],
                    "displayText": "[2]"
                  },
                  {
                    "type": "text",
                    "content": " Wuzhida Bao, Yuting Cao, Yin Yang, Hangjun Che, Junjian Huang, and Shiping Wen. 2025. Data-driven stock forecasting models based on neural networks: A review. Information Fusion 113 (2025), 102616."
                  }
                ],
                "zh": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-2"
                    ],
                    "displayText": "[2]"
                  },
                  {
                    "type": "text",
                    "content": " 包无纸大、曹雨婷、杨寅、车航俊、黄俊健和文世平。2025。基于神经网络的数据驱动股票预测模型：综述。信息融合 113 (2025), 102616。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "unordered-list-ffe50c90-556a-491b-b67b-33776ef4e156",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-3"
                    ],
                    "displayText": "[3]"
                  },
                  {
                    "type": "text",
                    "content": " Leonardo Bartolini, Linda Goldberg, and Adam Sacarny. 2008. How economic news moves markets. Curr. Issues Econ. Finance 14, Aug (2008), 6."
                  }
                ],
                "zh": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-3"
                    ],
                    "displayText": "[3]"
                  },
                  {
                    "type": "text",
                    "content": " Leonardo Bartolini、Linda Goldberg 和 Adam Sacarny。2008。经济新闻如何影响市场。当前经济与金融问题 14, 8月 (2008), 6。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "unordered-list-0ff0004c-5dba-4516-a1e1-fcc1e1e3129b",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-4"
                    ],
                    "displayText": "[4]"
                  },
                  {
                    "type": "text",
                    "content": " Iz Beltagy, Matthew E. Peters, and Arman Cohan. 2020. Longformer: The Long-Document Transformer. arXiv (2020)."
                  }
                ],
                "zh": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-4"
                    ],
                    "displayText": "[4]"
                  },
                  {
                    "type": "text",
                    "content": " Iz Beltagy、Matthew E. Peters 和 Arman Cohan。2020。Longformer：长文档 Transformer。arXiv (2020)。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "unordered-list-752ef125-d4f7-4e03-bf5f-bcbd9d965b09",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-5"
                    ],
                    "displayText": "[5]"
                  },
                  {
                    "type": "text",
                    "content": " Dinesh Bhuriya, Girish Kaushal, Ashish Sharma, and Upendra Singh. 2017. Stock market predication using a linear regression. In ICECA 2017."
                  }
                ],
                "zh": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-5"
                    ],
                    "displayText": "[5]"
                  },
                  {
                    "type": "text",
                    "content": " Dinesh Bhuriya、Girish Kaushal、Ashish Sharma 和 Upendra Singh。2017。使用线性回归进行股票市场预测。载于 ICECA 2017。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "unordered-list-6fac5310-e3da-45ab-866c-375615d4ec35",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-6"
                    ],
                    "displayText": "[6]"
                  },
                  {
                    "type": "text",
                    "content": " George Edward Pelham Box and Gwilym M. Jenkins. 1994. Time Series Analysis: Forecasting and Control. Prentice Hall PTR."
                  }
                ],
                "zh": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-6"
                    ],
                    "displayText": "[6]"
                  },
                  {
                    "type": "text",
                    "content": " George Edward Pelham Box 和 Gwilym M. Jenkins。1994。时间序列分析：预测与控制。Prentice Hall PTR。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "unordered-list-9e5bf380-f821-425b-bc35-7cde200d1a04",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-7"
                    ],
                    "displayText": "[7]"
                  },
                  {
                    "type": "text",
                    "content": " C. Q. Cao and R. S. Tsay. 1992. Nonlinear time-series analysis of stock volatilities. J. Appl. Econom. 7, S1 (1992), 165-185."
                  }
                ],
                "zh": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-7"
                    ],
                    "displayText": "[7]"
                  },
                  {
                    "type": "text",
                    "content": " C. Q. Cao 和 R. S. Tsay。1992。股票波动率的非线性时间序列分析。应用计量经济学杂志 7, S1 (1992), 165-185。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "unordered-list-63aa117f-b9da-478e-8288-17890768ea93",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-8"
                    ],
                    "displayText": "[8]"
                  },
                  {
                    "type": "text",
                    "content": " Minghao Chen, Houwen Peng, Jianlong Fu, and Haibin Ling. 2021. AutoFormer: Searching Transformers for Visual Recognition. In ICCV 2021."
                  }
                ],
                "zh": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-8"
                    ],
                    "displayText": "[8]"
                  },
                  {
                    "type": "text",
                    "content": " 陈明浩、彭厚文、傅建龙和林海斌。2021。AutoFormer：为视觉识别搜索 Transformer。载于 ICCV 2021。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "unordered-list-173eaac8-2b44-49a8-bbf6-159af41a57f6",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-9"
                    ],
                    "displayText": "[9]"
                  },
                  {
                    "type": "text",
                    "content": " Zeming Chen, Qiyue Gao, Antoine Bosselut, Ashish Sabharwal, and Kyle Richardson. 2023. DISCO: Distilling Counterfactuals with Large Language Models. In ACL 2023."
                  }
                ],
                "zh": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-9"
                    ],
                    "displayText": "[9]"
                  },
                  {
                    "type": "text",
                    "content": " 陈泽明、高启越、Antoine Bosselut、Ashish Sabharwal 和 Kyle Richardson。2023。DISCO：使用大语言模型蒸馏反事实。载于 ACL 2023。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "unordered-list-3a345b03-e765-47f9-a5aa-f4faa5a2a1b6",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-10"
                    ],
                    "displayText": "[10]"
                  },
                  {
                    "type": "text",
                    "content": " ANNA CIESLAK, ADAIR MORSE, and ANNETTE VISSING-JORGENSEN. 2019. Stock Returns over the FOMC Cycle. J. Finance 74, 5 (2019), 2201-2248."
                  }
                ],
                "zh": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-10"
                    ],
                    "displayText": "[10]"
                  },
                  {
                    "type": "text",
                    "content": " ANNA CIESLAK、ADAIR MORSE 和 ANNETTE VISSING-JORGENSEN。2019。FOMC 周期内的股票回报。金融杂志 74, 5 (2019), 2201-2248。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "unordered-list-38db58c7-c39a-432b-b2f8-21680842859b",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-11"
                    ],
                    "displayText": "[11]"
                  },
                  {
                    "type": "text",
                    "content": " Kiyoshi Izumi Daigo Tashiro, Hiroyasu Matsushima and Hiroki Sakaji. 2019. Encoding of high-frequency order information and prediction of short-term stock price by deep learning. Quant. Finance 19, 9 (2019), 1499-1506."
                  }
                ],
                "zh": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-11"
                    ],
                    "displayText": "[11]"
                  },
                  {
                    "type": "text",
                    "content": " Kiyoshi Izumi Daigo Tashiro、Hiroyasu Matsushima 和 Hiroki Sakaji。2019。通过深度学习编码高频订单信息并预测短期股票价格。量化金融 19, 9 (2019), 1499-1506。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "unordered-list-a88d94b2-9d2c-4705-900e-2d4aabdd9fdb",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-12"
                    ],
                    "displayText": "[12]"
                  },
                  {
                    "type": "text",
                    "content": " Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAAACL 2019."
                  }
                ],
                "zh": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-12"
                    ],
                    "displayText": "[12]"
                  },
                  {
                    "type": "text",
                    "content": " Jacob Devlin、张明伟、Kenton Lee 和 Kristina Toutanova。2019。BERT：用于语言理解的深度双向 Transformer 预训练。载于 NAAACL 2019。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "unordered-list-48e55b23-fc59-4436-8e83-71539603d817",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-13"
                    ],
                    "displayText": "[13]"
                  },
                  {
                    "type": "text",
                    "content": " Patti Domm. 2021. One Year Ago, Stocks Dropped  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "12\\%"
                  },
                  {
                    "type": "text",
                    "content": "  in a Single Day—What Investors Have Learned Since Then. https://www.cNBC.com/2021/03/16/one-year-ago-stocks-dropped-12percent-in-a-single-day-what-investors-haslearned-since-then.html Accessed: 2024-10-06."
                  }
                ],
                "zh": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-13"
                    ],
                    "displayText": "[13]"
                  },
                  {
                    "type": "text",
                    "content": " Patti Domm。2021。一年前，股票在单日内下跌  "
                  },
                  {
                    "type": "inline-math",
                    "latex": "12\\%"
                  },
                  {
                    "type": "text",
                    "content": " —投资者自此学到了什么。https://www.cNBC.com/2021/03/16/one-year-ago-stocks-dropped-12percent-in-a-single-day-what-investors-haslearned-since-then.html 访问于：2024-10-06。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "unordered-list-a5e77a60-a95a-4f6d-b465-da4d9248f2da",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-14"
                    ],
                    "displayText": "[14]"
                  },
                  {
                    "type": "text",
                    "content": " Dr. M. Durairaj and B. H. Krishna Mohan. 2022. A convolutional neural network based approach to financial time series prediction. Neural Comput. Appl. 34, 16 (2022), 13319-13337."
                  }
                ],
                "zh": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-14"
                    ],
                    "displayText": "[14]"
                  },
                  {
                    "type": "text",
                    "content": " M. Durairaj 博士和 B. H. Krishna Mohan。2022。一种基于卷积神经网络的金融时间序列预测方法。神经计算与应用 34, 16 (2022), 13319-13337。"
                  }
                ]
              }
            }
          ]
        },
        {
          "id": "unordered-list-c02ae710-1b4b-45aa-a4bc-b393d0220f6f",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-15"
                    ],
                    "displayText": "[15]"
                  },
                  {
                    "type": "text",
                    "content": " Eugene F. Fama. 1965. The Behavior of Stock-Market Prices. J. Bus. 38, 1 (1965), 34-105."
                  }
                ],
                "zh": [
                  {
                    "type": "citation",
                    "referenceIds": [
                      "ref-15"
                    ],
                    "displayText": "[15]"
                  },
                  {
                    "type": "text",
                    "content": " Eugene F. Fama。1965。股票市场价格的行为。商业杂志 38, 1 (1965), 34-105。"
                  }
                ]
              }
            }
          ]
        }
      ],
      "subsections": []
    },
    {
      "id": "section-18693a54-48fd-4584-b60c-e001ba8d3d23",
      "title": {
        "en": "A Prompt Templates for Counterfactual Events Generations",
        "zh": "反事实事件生成的提示模板"
      },
      "content": [],
      "subsections": [
        {
          "id": "section-9bc491d0-0456-4116-9a53-8b70e452fd9a",
          "title": {
            "en": "Summarization Prompt Template",
            "zh": "摘要提示模板"
          },
          "content": [],
          "subsections": []
        }
      ]
    },
    {
      "id": "section-ad36f72b-f54e-475e-9ef7-af054112769a",
      "title": {
        "en": "Summarization Prompt Template",
        "zh": "摘要提示模板"
      },
      "content": [
        {
          "id": "paragraph-48297e62-fc9d-4b8f-b566-a805e74aff10",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Due to the script's length, we firstly prompt LLaMA-3 summarizes each chunk of an event script, followed by a second prompt to generate the full summary. Below is the chunk-level prompt, which instructs the model to summarize within a word limit. Text in “” indicates input variables."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "由于脚本长度，我们首先提示LLaMA-3对事件脚本的每个块进行摘要，然后使用第二个提示生成完整摘要。以下是块级提示，指导模型在字数限制内进行摘要。文本中的“”表示输入变量。"
              }
            ]
          }
        }
      ],
      "subsections": [
        {
          "id": "section-97b0edb4-5773-4c10-bb5c-cd1efe7ff91e",
          "title": {
            "en": "Prompt Template for Event Script Chunk Summarization",
            "zh": "事件脚本块摘要提示模板"
          },
          "content": [
            {
              "id": "paragraph-62b5ecb7-a52a-4916-a5ac-d42690722a55",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "You are given chunk {chunk_idx} of a {text_type} report. Your task is to generate a summary within {number_of_words} words."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "您获得了{text_type}报告的第{chunk_idx}块。您的任务是在{number_of_words}词内生成摘要。"
                  }
                ]
              }
            },
            {
              "id": "paragraph-1f1a1923-4102-484d-923a-092ebb0a6ac7",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "The content of chunk {chunk_idx} is as follows: {original_text}"
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "第{chunk_idx}块的内容如下：{original_text}"
                  }
                ]
              }
            },
            {
              "id": "paragraph-54ae3fa6-3b27-4481-83ae-af75ba682a66",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Please provide a concise summary, while keep the key variables:"
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "请提供简洁摘要，同时保留关键变量："
                  }
                ]
              }
            }
          ],
          "subsections": []
        },
        {
          "id": "section-1cd2aaad-ee88-4ebc-9333-7b28e5fb1c79",
          "title": {
            "en": "Prompt Template for Final Summarization",
            "zh": "最终摘要提示模板"
          },
          "content": [
            {
              "id": "paragraph-8e2aa2f1-b5f5-48a5-a405-53305f29f97c",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "You are given {chunk_num} summaries of different chunks from a {text_type} report. Your task is to generate an overall summary within {number_of_words} words."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "您获得了{text_type}报告中不同块的{chunk_num}个摘要。您的任务是在{number_of_words}词内生成整体摘要。"
                  }
                ]
              }
            },
            {
              "id": "paragraph-099224ee-e4ca-4558-a6ab-b5c8a73803a0",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "The chunk summaries are as follows: {chunk_summaries} Please provide a comprehensive summary of the entire report, while keep the key variables:"
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "块摘要如下：{chunk_summaries}请提供整个报告的全面摘要，同时保留关键变量："
                  }
                ]
              }
            }
          ],
          "subsections": []
        }
      ]
    },
    {
      "id": "section-f4fa5f97-4da3-4f9d-aa47-02593393dfce",
      "title": {
        "en": "Sentiment Analytical Prompt Template",
        "zh": "情感分析提示模板"
      },
      "content": [
        {
          "id": "paragraph-bbad5fdd-cf12-44db-9c5b-48120b6031b4",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "For sentiment analysis, the prompt asks the model to rate an event script's sentiment from 0 (negative) to 10 (positive) and explain the rating. Below is the prompt template, with “” denoting input variables."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "对于情感分析，提示要求模型将事件脚本的情感从0（负面）到10（正面）进行评分并解释评分。以下是提示模板，“”表示输入变量。"
              }
            ]
          }
        }
      ],
      "subsections": [
        {
          "id": "section-557d5fe1-6ee8-42b9-8e4c-d9ebb07cce0d",
          "title": {
            "en": "Sentiment Analysis Prompt",
            "zh": "情感分析提示"
          },
          "content": [
            {
              "id": "paragraph-8117c46b-03f3-4343-9a61-5f2b8dd137b8",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Please analyze the sentiment of the following {text_type} summary and rate it on a scale from 0 to 10, where:"
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "请分析以下{text_type}摘要的情感，并在0到10的尺度上评分，其中："
                  }
                ]
              }
            },
            {
              "id": "unordered-list-52e84765-77ef-46ec-a29a-b8613ff9246f",
              "type": "unordered-list",
              "items": [
                {
                  "content": {
                    "en": [
                      {
                        "type": "inline-math",
                        "latex": "0 ="
                      },
                      {
                        "type": "text",
                        "content": " Extremely Negative"
                      }
                    ],
                    "zh": [
                      {
                        "type": "inline-math",
                        "latex": "0 ="
                      },
                      {
                        "type": "text",
                        "content": " 极度负面"
                      }
                    ]
                  }
                },
                {
                  "content": {
                    "en": [
                      {
                        "type": "inline-math",
                        "latex": "1 ="
                      },
                      {
                        "type": "text",
                        "content": " Strongly Negative"
                      }
                    ],
                    "zh": [
                      {
                        "type": "inline-math",
                        "latex": "1 ="
                      },
                      {
                        "type": "text",
                        "content": " 强烈负面"
                      }
                    ]
                  }
                },
                {
                  "content": {
                    "en": [
                      {
                        "type": "inline-math",
                        "latex": "2 ="
                      },
                      {
                        "type": "text",
                        "content": " Very Negative"
                      }
                    ],
                    "zh": [
                      {
                        "type": "inline-math",
                        "latex": "2 ="
                      },
                      {
                        "type": "text",
                        "content": " 非常负面"
                      }
                    ]
                  }
                },
                {
                  "content": {
                    "en": [
                      {
                        "type": "inline-math",
                        "latex": "3 ="
                      },
                      {
                        "type": "text",
                        "content": " Moderate Negative"
                      }
                    ],
                    "zh": [
                      {
                        "type": "inline-math",
                        "latex": "3 ="
                      },
                      {
                        "type": "text",
                        "content": " 中等负面"
                      }
                    ]
                  }
                },
                {
                  "content": {
                    "en": [
                      {
                        "type": "inline-math",
                        "latex": "4 ="
                      },
                      {
                        "type": "text",
                        "content": " Slightly Negative"
                      }
                    ],
                    "zh": [
                      {
                        "type": "inline-math",
                        "latex": "4 ="
                      },
                      {
                        "type": "text",
                        "content": " 轻微负面"
                      }
                    ]
                  }
                },
                {
                  "content": {
                    "en": [
                      {
                        "type": "inline-math",
                        "latex": "5 ="
                      },
                      {
                        "type": "text",
                        "content": " Neutral"
                      }
                    ],
                    "zh": [
                      {
                        "type": "inline-math",
                        "latex": "5 ="
                      },
                      {
                        "type": "text",
                        "content": " 中性"
                      }
                    ]
                  }
                },
                {
                  "content": {
                    "en": [
                      {
                        "type": "inline-math",
                        "latex": "6 ="
                      },
                      {
                        "type": "text",
                        "content": " Slightly Positive"
                      }
                    ],
                    "zh": [
                      {
                        "type": "inline-math",
                        "latex": "6 ="
                      },
                      {
                        "type": "text",
                        "content": " 轻微正面"
                      }
                    ]
                  }
                },
                {
                  "content": {
                    "en": [
                      {
                        "type": "inline-math",
                        "latex": "7 ="
                      },
                      {
                        "type": "text",
                        "content": " Moderate Positive"
                      }
                    ],
                    "zh": [
                      {
                        "type": "inline-math",
                        "latex": "7 ="
                      },
                      {
                        "type": "text",
                        "content": " 中等正面"
                      }
                    ]
                  }
                },
                {
                  "content": {
                    "en": [
                      {
                        "type": "inline-math",
                        "latex": "8 ="
                      },
                      {
                        "type": "text",
                        "content": " Very Positive"
                      }
                    ],
                    "zh": [
                      {
                        "type": "inline-math",
                        "latex": "8 ="
                      },
                      {
                        "type": "text",
                        "content": " 非常正面"
                      }
                    ]
                  }
                },
                {
                  "content": {
                    "en": [
                      {
                        "type": "inline-math",
                        "latex": "9 ="
                      },
                      {
                        "type": "text",
                        "content": " Strongly Positive"
                      }
                    ],
                    "zh": [
                      {
                        "type": "inline-math",
                        "latex": "9 ="
                      },
                      {
                        "type": "text",
                        "content": " 强烈正面"
                      }
                    ]
                  }
                },
                {
                  "content": {
                    "en": [
                      {
                        "type": "inline-math",
                        "latex": "10 ="
                      },
                      {
                        "type": "text",
                        "content": " Extremely Positive"
                      }
                    ],
                    "zh": [
                      {
                        "type": "inline-math",
                        "latex": "10 ="
                      },
                      {
                        "type": "text",
                        "content": " 极度正面"
                      }
                    ]
                  }
                }
              ]
            },
            {
              "id": "paragraph-ebd8c807-6233-42e5-97b7-edb1744df3fc",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "{text_type} summary: {text}"
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "{text_type}摘要：{text}"
                  }
                ]
              }
            },
            {
              "id": "paragraph-1a349748-f143-4e1b-86fb-39586c783364",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Output the sentiment analysis as:"
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "输出情感分析为："
                  }
                ]
              }
            },
            {
              "id": "paragraph-badec785-766f-4c3d-8514-fcb499a7b573",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Sentiment rating: (0 to 10), Explanation:"
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "情感评分：(0到10)，解释："
                  }
                ]
              }
            }
          ],
          "subsections": []
        }
      ]
    },
    {
      "id": "section-5c985ae9-61ec-4613-87fa-32e1249a6fa0",
      "title": {
        "en": "Counterfactual Event Generation Prompt Template",
        "zh": "反事实事件生成提示模板"
      },
      "content": [
        {
          "id": "paragraph-6e6e1992-87c2-4585-b42f-837e27b5d26a",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "To generate counterfactual versions of a text with different sentiment levels, we use a prompt that instructs the model to modify key facts and information to align with a target sentiment rating. The model is provided with the original sentiment rating and sentiment description and is asked to adjust the text to reflect a specified target sentiment rating. Below is the prompt, where the text within "
              },
              {
                "type": "inline-math",
                "latex": "\\{\\}"
              },
              {
                "type": "text",
                "content": " indicates the input variables:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "为了生成具有不同情感水平的文本反事实版本，我们使用提示指导模型修改关键事实和信息以符合目标情感评分。模型被提供原始情感评分和情感描述，并要求调整文本以反映指定的目标情感评分。以下是提示，其中"
              },
              {
                "type": "inline-math",
                "latex": "\\{\\}"
              },
              {
                "type": "text",
                "content": "内的文本表示输入变量："
              }
            ]
          }
        }
      ],
      "subsections": [
        {
          "id": "section-36bc00ea-6836-41ca-bda3-aed4cbf13311",
          "title": {
            "en": "Counterfactual Text Generation Prompt",
            "zh": "反事实文本生成提示"
          },
          "content": [
            {
              "id": "paragraph-b4a0723e-fe26-42bd-9988-adf720527092",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "The original text has been identified with a sentiment rating of {current_sentimentrating} ( {current_sentiment})."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "原始文本已被识别为情感评分{current_sentimentrating}（{current_sentiment}）。"
                  }
                ]
              }
            },
            {
              "id": "paragraph-bef7bb26-b9bb-4379-ad36-1c8b5526a990",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Your task is to generate a counterfactual version of the text that aligns with a sentiment rating of {target_sentimentrating} (\\{target_sentiment\\}) by modifying the key facts and information to reflect the specified target sentiment score about the economy, while keep the overall format and the sentiment-neural content unchanged."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "您的任务是生成文本的反事实版本，通过修改关键事实和信息以反映指定的关于经济的目标情感评分{target_sentimentrating}（\\{target_sentiment\\}），同时保持整体格式和情感中性内容不变。"
                  }
                ]
              }
            },
            {
              "id": "paragraph-141e4c5a-87a1-45c1-91d7-38ec22e2651f",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Original text: {original_text}"
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "原始文本：{original_text}"
                  }
                ]
              }
            },
            {
              "id": "paragraph-f313b9f3-1894-476c-a465-453ea4417b1e",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Counterfactual text with a sentiment rating of {target_sentimentrating} (\\{target_sentiment\\}):"
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "情感评分为{target_sentimentrating}（\\{target_sentiment\\}）的反事实文本："
                  }
                ]
              }
            }
          ],
          "subsections": []
        }
      ]
    },
    {
      "id": "section-c3d1a5c8-d778-4f81-99eb-69fb5139417a",
      "title": {
        "en": "Implementation Details of Dataset Collection and Preprocessing",
        "zh": "数据集收集与预处理实现细节"
      },
      "content": [],
      "subsections": [
        {
          "id": "section-94ed2fca-0451-4dbc-b458-877bd101d6d6",
          "title": {
            "en": "Dataset Collection",
            "zh": "数据集收集"
          },
          "content": [
            {
              "id": "paragraph-64e6b592-7953-41bd-bbae-9012a418bd66",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "To construct the CAMEF dataset, raw macroeconomic event data are crawled from official government sources (Tab. 1) in various formats (PDF, HTML, TXT). We utilize the following Python libraries:"
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "为了构建CAMEF数据集，我们从官方政府来源（表1）以各种格式（PDF、HTML、TXT）爬取原始宏观经济事件数据。我们使用以下Python库："
                  }
                ]
              }
            },
            {
              "id": "unordered-list-058d33a4-123c-4771-8530-0e4ba15d2702",
              "type": "unordered-list",
              "items": [
                {
                  "content": {
                    "en": [
                      {
                        "type": "text",
                        "content": "Requests - to send HTTP requests for archive access"
                      }
                    ],
                    "zh": [
                      {
                        "type": "text",
                        "content": "Requests - 发送HTTP请求以访问档案"
                      }
                    ]
                  }
                },
                {
                  "content": {
                    "en": [
                      {
                        "type": "text",
                        "content": "Selenium - to locate and download files via HTML headers"
                      }
                    ],
                    "zh": [
                      {
                        "type": "text",
                        "content": "Selenium - 通过HTML头定位和下载文件"
                      }
                    ]
                  }
                },
                {
                  "content": {
                    "en": [
                      {
                        "type": "text",
                        "content": "BeautifulSoup - to parse HTML and extract file links"
                      }
                    ],
                    "zh": [
                      {
                        "type": "text",
                        "content": "BeautifulSoup - 解析HTML并提取文件链接"
                      }
                    ]
                  }
                }
              ]
            },
            {
              "id": "paragraph-bb10df18-62df-4b26-9bea-5288e4c4e093",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "The dataset covers six event types: FOMC minutes, CPI, PPI, unemployment insurance, unemployment rate, and GDP advance releases."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "数据集涵盖六种事件类型：FOMC会议纪要、CPI、PPI、失业保险、失业率和GDP预先发布。"
                  }
                ]
              }
            }
          ],
          "subsections": []
        },
        {
          "id": "section-6ca7a83a-ecd7-4e0b-9ac8-715b1a775f26",
          "title": {
            "en": "Preprocessing",
            "zh": "预处理"
          },
          "content": [
            {
              "id": "paragraph-8d56bc49-bfa8-4392-8672-3ce9e6ce591f",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Raw files are converted into a unified text format. PyPDF2 and pdfplumber extract content from PDFs, while BeautifulSoup parses HTML using depth-first traversal. TXT files are used as-is. We convert all the tables into structured text using the delimiter \"|\", as shown:"
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "原始文件被转换为统一文本格式。PyPDF2和pdfplumber从PDF中提取内容，而BeautifulSoup使用深度优先遍历解析HTML。TXT文件按原样使用。我们使用分隔符\"|\"将所有表格转换为结构化文本，如下所示："
                  }
                ]
              }
            },
            {
              "id": "code-b80567b8-ca09-4d9a-9192-0e8772137a7c",
              "type": "code",
              "code": "<table>\n\nHeader 1 | Header 2 | Header 3\n\n---\n\nCell 1 | Cell 2 | Cell 3\n\n</Table>"
            },
            {
              "id": "paragraph-4dabae86-3431-4d3d-93a9-d9f73499dfba",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "This preprocessing ensures clean, consistent, machine-readable data, supporting robust analysis and model training."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "此预处理确保干净、一致、机器可读的数据，支持稳健的分析和模型训练。"
                  }
                ]
              }
            }
          ],
          "subsections": []
        }
      ]
    },
    {
      "id": "section-16908e0c-7a2a-4093-a5c7-21e5bf97636e",
      "title": {
        "en": "Implementation Details",
        "zh": "实现细节"
      },
      "content": [
        {
          "id": "paragraph-292b0ae8-d896-46e1-924b-75c6da4c80b1",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Single-modality baselines (ARIMA, DLinear, AutoFormer, FED-Former, iTransformer, PatchTST) were adapted from Time-Series-Library to the event-driven setting, using pre-event segments to predict 35-, 70-, and 140-step trends. All models were trained for 10 epochs with batch size 32."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "单模态基线（ARIMA、DLinear、AutoFormer、FED-Former、iTransformer、PatchTST）从Time-Series-Library适应到事件驱动设置，使用事件前段预测35、70和140步趋势。所有模型训练10个周期，批次大小为32。"
              }
            ]
          }
        },
        {
          "id": "paragraph-92e4f9bd-4183-4168-b8c0-fdbe34efa6cf",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "For multi-modality baselines, we used TEST and a re-implemented GPT4MTS (with LongFormer replacing BERT). Both were aligned to the same forecasting horizons and training settings."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "对于多模态基线，我们使用了TEST和重新实现的GPT4MTS（用LongFormer替换BERT）。两者都对齐到相同的预测范围和训练设置。"
              }
            ]
          }
        },
        {
          "id": "paragraph-6ad968af-1dc1-4cf8-be64-d70fd494a31e",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "CAMEF followed a two-stage pipeline: MOMENT was pre-trained on time series, then the full model fine-tuned on aligned text-series pairs. MOMENT and RoBERTa (excluding final layer) were frozen, while GPT2 and fusion layers were trainable, enabling robust multimodal forecasting."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "CAMEF遵循两阶段流程：MOMENT在时间序列上预训练，然后完整模型在对齐的文本-序列对上进行微调。MOMENT和RoBERTa（排除最终层）被冻结，而GPT2和融合层可训练，实现稳健的多模态预测。"
              }
            ]
          }
        }
      ],
      "subsections": [
        {
          "id": "section-64a6db40-f745-496c-a79e-16e78a66752a",
          "title": {
            "en": "Implementation of Baseline Models",
            "zh": "基线模型实现"
          },
          "content": [
            {
              "id": "paragraph-d2c68085-1d2e-41dc-a6c0-0ded9a10aa0c",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Baseline models were developed with objectives distinct from our event-driven forecasting approach, as single-modality methods are primarily designed for continuous time-series forecasting. To enable a fair comparison, we adapted these models to align with an event-driven context, where past time-series data preceding an event is used to forecast trends within a defined forecasting horizon."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "基线模型的开发目标与我们的事件驱动预测方法不同，因为单模态方法主要设计用于连续时间序列预测。为了实现公平比较，我们调整这些模型以符合事件驱动上下文，其中事件前的过去时间序列数据用于预测定义预测范围内的趋势。"
                  }
                ]
              }
            },
            {
              "id": "paragraph-8a89eccb-21d2-43a2-a859-7c6d9ad30b5f",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Single-Modality Models: For time-series-based single-modality models, including DLinear, AutoFormer, FEDFormer, iTransformer, and PatchTST, we utilized the open-source library Time-Series-Library². Time-series segments were extracted with lengths covering both the input and forecasting periods surrounding each event, ensuring alignment with the respective event's time step. The input segment represents the historical trend information, while the forecasting period is treated as \"unseen\" data to be predicted. Input and forecasting lengths were consistently set to 35, 70, and 140 time steps across all experiments, as described in Sec. 6.1. All models were trained for 10 epochs, with a batch size of 32. These settings ensured convergence of the loss function and maintained consistency with CAMEF's training configuration."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "单模态模型：对于基于时间序列的单模态模型，包括DLinear、AutoFormer、FEDFormer、iTransformer和PatchTST，我们使用了开源库Time-Series-Library²。时间序列段的长度提取覆盖每个事件周围的输入和预测期，确保与相应事件的时间步对齐。输入段代表历史趋势信息，而预测期被视为要预测的\"未见\"数据。如第6.1节所述，在所有实验中，输入和预测长度一致设置为35、70和140时间步。所有模型训练10个周期，批次大小为32。这些设置确保损失函数收敛并与CAMEF的训练配置保持一致。"
                  }
                ]
              }
            },
            {
              "id": "paragraph-06b320c4-f6c5-4fc7-a79c-1fe563c2f8e6",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Multi-Modality Models: For multi-modality methods, including TEST and GPT4MTS, we followed implementation strategies specific to each model."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "多模态模型：对于多模态方法，包括TEST和GPT4MTS，我们遵循每个模型特定的实现策略。"
                  }
                ]
              }
            },
            {
              "id": "unordered-list-59113725-fc32-47fd-be50-a18d8fd4d0ce",
              "type": "unordered-list",
              "items": [
                {
                  "content": {
                    "en": [
                      {
                        "type": "text",
                        "content": "TEST: We followed the instructions provided in the opensource TEST repository<sup>3</sup>, which involved two training stages. In the first stage, the encoder was trained by selecting 10 prototype words based on GPT vocabulary clustering (as instructed in the repository) to align textual representations with time-series data. The second stage involved training the time-series decoder, where input and forecasting steps were set to 35, 70, and 140, similar to the single-modality models. The batch size was set to 7, and training epochs were kept at 10."
                      }
                    ],
                    "zh": [
                      {
                        "type": "text",
                        "content": "TEST：我们遵循开源TEST仓库<sup>3</sup>提供的说明，涉及两个训练阶段。在第一阶段，通过基于GPT词汇聚类（如仓库中指示）选择10个原型词来训练编码器，以对齐文本表示与时间序列数据。第二阶段涉及训练时间序列解码器，其中输入和预测步长设置为35、70和140，类似于单模态模型。批次大小设置为7，训练周期保持在10。"
                      }
                    ]
                  }
                },
                {
                  "content": {
                    "en": [
                      {
                        "type": "text",
                        "content": "GPT4MTS: As the official implementation of GPT4MTS was unavailable, we re-implemented the model based on its original paper. Instead of using BERT "
                      },
                      {
                        "type": "citation",
                        "referenceIds": [
                          "ref-12"
                        ],
                        "displayText": "[12]"
                      },
                      {
                        "type": "text",
                        "content": " as the textual encoder, we employed LongFormer "
                      },
                      {
                        "type": "citation",
                        "referenceIds": [
                          "ref-4"
                        ],
                        "displayText": "[4]"
                      },
                      {
                        "type": "text",
                        "content": ", which is better suited for encoding longer contexts, as our texts tend to be relatively lengthy. Input time-series segments were used to forecast the time-series data at the forecasting lengths of 35, 70, and 140. We kept training epochs at 10 and the batch size at 7 to ensure consistency with other baselines."
                      }
                    ],
                    "zh": [
                      {
                        "type": "text",
                        "content": "GPT4MTS：由于GPT4MTS的官方实现不可用，我们基于其原始论文重新实现了模型。我们使用LongFormer "
                      },
                      {
                        "type": "citation",
                        "referenceIds": [
                          "ref-4"
                        ],
                        "displayText": "[4]"
                      },
                      {
                        "type": "text",
                        "content": "而不是BERT "
                      },
                      {
                        "type": "citation",
                        "referenceIds": [
                          "ref-12"
                        ],
                        "displayText": "[12]"
                      },
                      {
                        "type": "text",
                        "content": "作为文本编码器，因为它更适合编码较长上下文，因为我们的文本往往相对较长。输入时间序列段用于预测35、70和140预测长度的时间序列数据。我们保持训练周期为10，批次大小为7，以确保与其他基线一致。"
                      }
                    ]
                  }
                }
              ]
            }
          ],
          "subsections": []
        },
        {
          "id": "section-b058a8a9-8c21-449b-aadc-86ef2b502499",
          "title": {
            "en": "Implementation of CAMEF",
            "zh": "CAMEF实现"
          },
          "content": [
            {
              "id": "paragraph-29162a89-226f-49af-afdc-5af3b6e104df",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "The batch size is set to 10, and the training epochs are set to 10, consistent with the baseline models."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "批次大小设置为10，训练周期设置为10，与基线模型一致。"
                  }
                ]
              }
            },
            {
              "id": "table-fbec564a-62bf-4c4d-977f-388bc481a3e6",
              "type": "table",
              "caption": {
                "en": [
                  {
                    "type": "text",
                    "content": "Learning Rates for CAMEF Components"
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "CAMEF组件学习率"
                  }
                ]
              },
              "headers": [
                "Model Component",
                "Learning Rate"
              ],
              "rows": [
                [
                  "MOMENT Model",
                  "1 × 10-6"
                ],
                [
                  "RoBERTa Model",
                  "5 × 10-7"
                ],
                [
                  "GPT2 Model",
                  "1 × 10-5"
                ],
                [
                  "Embedding Layer",
                  "1 × 10-5"
                ],
                [
                  "Residual Layer",
                  "1 × 10-5"
                ],
                [
                  "Fusion Layer",
                  "5 × 10-7"
                ],
                [
                  "Output Layer",
                  "1 × 10-5"
                ]
              ]
            },
            {
              "id": "paragraph-c2b773cc-9099-4b4f-82c8-014a8e1002b1",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "The implementation of CAMEF involves two distinct training stages to ensure effective learning of both time-series and textual features, while leveraging pre-trained components:"
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "CAMEF 的实现涉及两个不同的训练阶段，以确保有效学习时间序列和文本特征，同时利用预训练组件："
                  }
                ]
              }
            },
            {
              "id": "ordered-list-11cbbc84-fa3b-409f-acfc-271002b6aceb",
              "type": "ordered-list",
              "items": [
                {
                  "content": {
                    "en": [
                      {
                        "type": "text",
                        "content": "Pre-training MOMENT: In the first stage, we pre-train the MOMENT model using the time-series segments from the training data. This step focuses on learning representations of the past time-series patterns."
                      }
                    ],
                    "zh": [
                      {
                        "type": "text",
                        "content": "预训练 MOMENT：在第一阶段，我们使用训练数据中的时间序列片段预训练 MOMENT 模型。此步骤侧重于学习过去时间序列模式的表示。"
                      }
                    ]
                  }
                }
              ]
            },
            {
              "id": "ordered-list-2b5704e1-81cb-4ad5-b710-1aed2a6f0f69",
              "type": "ordered-list",
              "items": [
                {
                  "content": {
                    "en": [
                      {
                        "type": "text",
                        "content": "Training Entire CAMEF: In the second stage, we train the entire CAMEF model using both event scripts and their corresponding aligned time-series segments. During this stage, certain parameters are frozen to retain the pre-trained knowledge, while others remain open for fine-tuning:"
                      }
                    ],
                    "zh": [
                      {
                        "type": "text",
                        "content": "训练完整 CAMEF：在第二阶段，我们使用事件脚本及其对应的对齐时间序列片段训练整个 CAMEF 模型。在此阶段，某些参数被冻结以保留预训练知识，而其他参数保持开放以进行微调："
                      }
                    ]
                  }
                }
              ]
            },
            {
              "id": "unordered-list-c93a545b-4402-4fad-93a2-3838194adc3f",
              "type": "unordered-list",
              "items": [
                {
                  "content": {
                    "en": [
                      {
                        "type": "text",
                        "content": "Frozen Parameters: All parameters of the MOMENT model and RoBERTa (except for the last hidden layer) are frozen. Additionally, the token embedding layer of GPT2 in the decoder is frozen to preserve its pre-trained representations."
                      }
                    ],
                    "zh": [
                      {
                        "type": "text",
                        "content": "冻结参数：MOMENT 模型和 RoBERTa 的所有参数（除最后一隐藏层外）被冻结。此外，解码器中 GPT2 的令牌嵌入层被冻结以保留其预训练表示。"
                      }
                    ]
                  }
                }
              ]
            },
            {
              "id": "unordered-list-7f0ea75b-67e2-497d-ab32-9a32c00c0e0a",
              "type": "unordered-list",
              "items": [
                {
                  "content": {
                    "en": [
                      {
                        "type": "text",
                        "content": "Trainable Parameters: The remaining components of GPT2, the last hidden layer of RoBERTa, and other components such as the embedding, residual, fusion, and output layers are open for training."
                      }
                    ],
                    "zh": [
                      {
                        "type": "text",
                        "content": "可训练参数：GPT2 的其余组件、RoBERTa 的最后一隐藏层以及其他组件（如嵌入层、残差层、融合层和输出层）开放用于训练。"
                      }
                    ]
                  }
                }
              ]
            },
            {
              "id": "paragraph-cf21ee08-eeab-4156-8f90-6850712d6e2a",
              "type": "paragraph",
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "The hidden sizes of the different components of the CAMEF model are detailed in Sec. 5. To optimize the model effectively, we adopt component-specific learning rates as listed in "
                  },
                  {
                    "type": "table-ref",
                    "tableId": "table-5",
                    "displayText": "Table 5"
                  },
                  {
                    "type": "text",
                    "content": "."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "CAMEF 模型不同组件的隐藏大小在第 5 节中详细说明。为有效优化模型，我们采用如表 5 所列的组件特定学习率。"
                  }
                ]
              }
            }
          ],
          "subsections": []
        }
      ]
    }
  ],
  "references": [
    {
      "id": "b8eb7e08-0524-4248-85f4-9e6e1b545d8c",
      "authors": [
        "Adebiyi A. Ariyo",
        "Adewumi O. Adewumi",
        "Charles K. Ayo"
      ],
      "title": "Stock Price Prediction Using the ARIMA Model",
      "publication": "UKSim-AMSS",
      "year": 2014
    },
    {
      "id": "03306df8-421d-4a0d-8112-9827e960c459",
      "authors": [
        "Wuzhida Bao",
        "Yuting Cao",
        "Yin Yang",
        "Hangjun Che",
        "Junjian Huang",
        "Shiping Wen"
      ],
      "title": "Data-driven stock forecasting models based on neural networks: A review",
      "publication": "Information Fusion",
      "year": 2025,
      "volume": "113",
      "pages": "102616"
    },
    {
      "id": "aa5b46ee-1ca3-40c2-8d37-8512bba28e59",
      "authors": [
        "Leonardo Bartolini",
        "Linda Goldberg",
        "Adam Sacarny"
      ],
      "title": "How economic news moves markets",
      "publication": "Current Issues in Economics and Finance",
      "year": 2008,
      "volume": "14",
      "pages": "6"
    },
    {
      "id": "6f3d75e3-5a59-486c-8818-f46c26f50eb8",
      "authors": [
        "Iz Beltagy",
        "Matthew E. Peters",
        "Arman Cohan"
      ],
      "title": "Longformer: The Long-Document Transformer",
      "publication": "arXiv",
      "year": 2020
    },
    {
      "id": "a50204d2-4918-424d-bcd3-b39f4376997c",
      "authors": [
        "Dinesh Bhuriya",
        "Girish Kaushal",
        "Ashish Sharma",
        "Upendra Singh"
      ],
      "title": "Stock market predication using a linear regression",
      "publication": "ICECA",
      "year": 2017
    },
    {
      "id": "44b51878-e2e6-4ba4-b7d8-73d04bf8e0c3",
      "authors": [
        "George Edward Pelham Box",
        "Gwilym M. Jenkins"
      ],
      "title": "Time Series Analysis: Forecasting and Control",
      "publication": "Prentice Hall PTR",
      "year": 1994
    },
    {
      "id": "68f51c47-7cc4-42a5-aa16-f44383d653a1",
      "authors": [
        "C. Q. Cao",
        "R. S. Tsay"
      ],
      "title": "Nonlinear time-series analysis of stock volatilities",
      "publication": "Journal of Applied Econometrics",
      "year": 1992,
      "volume": "7",
      "pages": "165-185"
    },
    {
      "id": "ca87b8a9-bbc2-4273-8397-8a934dd44785",
      "authors": [
        "Minghao Chen",
        "Houwen Peng",
        "Jianlong Fu",
        "Haibin Ling"
      ],
      "title": "AutoFormer: Searching Transformers for Visual Recognition",
      "publication": "ICCV",
      "year": 2021
    },
    {
      "id": "83c40626-6e59-499e-a2a2-b06a156544f4",
      "authors": [
        "Zeming Chen",
        "Qiyue Gao",
        "Antoine Bosselut",
        "Ashish Sabharwal",
        "Kyle Richardson"
      ],
      "title": "DISCO: Distilling Counterfactuals with Large Language Models",
      "publication": "ACL",
      "year": 2023
    },
    {
      "id": "7fcc57c8-3699-4d7f-9016-6839fccf8f1c",
      "authors": [
        "Anna Cieslak",
        "Adair Morse",
        "Annette Vissing-Jorgensen"
      ],
      "title": "Stock Returns over the FOMC Cycle",
      "publication": "Journal of Finance",
      "year": 2019,
      "volume": "74",
      "pages": "2201-2248"
    },
    {
      "id": "8bcb3dc8-3965-4c17-8d4e-379f26bdf4a7",
      "authors": [
        "Daigo Tashiro",
        "Hiroyasu Matsushima",
        "Hiroki Sakaji",
        "Kiyoshi Izumi"
      ],
      "title": "Encoding of high-frequency order information and prediction of short-term stock price by deep learning",
      "publication": "Quantitative Finance",
      "year": 2019,
      "volume": "19",
      "pages": "1499-1506"
    },
    {
      "id": "3eab32d4-a8e1-42d3-ba03-7db0b1026ce7",
      "authors": [
        "Jacob Devlin",
        "Ming-Wei Chang",
        "Kenton Lee",
        "Kristina Toutanova"
      ],
      "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "publication": "NAACL",
      "year": 2019
    },
    {
      "id": "b5133a4d-3a72-425f-a3a6-3c0b37fc005b",
      "authors": [
        "Patti Domm"
      ],
      "title": "One Year Ago, Stocks Dropped 12% in a Single Day—What Investors Have Learned Since Then",
      "publication": "CNBC",
      "year": 2021,
      "url": "https://www.cnbc.com/2021/03/16/one-year-ago-stocks-dropped-12percent-in-a-single-day-what-investors-haslearned-since-then.html"
    },
    {
      "id": "a73aab5a-59dd-46a8-ab2f-3ff18e9e3c83",
      "authors": [
        "M. Durairaj",
        "B. H. Krishna Mohan"
      ],
      "title": "A convolutional neural network based approach to financial time series prediction",
      "publication": "Neural Computing and Applications",
      "year": 2022,
      "volume": "34",
      "pages": "13319-13337"
    },
    {
      "id": "c66269b2-96ae-4174-af47-b148af510438",
      "authors": [
        "Eugene F. Fama"
      ],
      "title": "The Behavior of Stock-Market Prices",
      "publication": "Journal of Business",
      "year": 1965,
      "volume": "38",
      "pages": "34-105"
    },
    {
      "id": "a6d7e45c-527f-4573-a9c2-91bade33791b",
      "authors": [
        "Eugene F. Fama",
        "Lawrence Fisher",
        "Michael C. Jensen",
        "Richard Roll"
      ],
      "title": "The Adjustment of Stock Prices to New Information",
      "publication": "International Economic Review",
      "year": 1969,
      "volume": "10",
      "pages": "1-21"
    },
    {
      "id": "25407a46-16f4-4bb9-8e5b-fce4336f7b61",
      "authors": [
        "Pavel Gertler",
        "Roman Horvath"
      ],
      "title": "Central bank communication and financial markets: New high-frequency evidence",
      "publication": "Journal of Financial Stability",
      "year": 2018,
      "volume": "36",
      "pages": "336-345"
    },
    {
      "id": "518d862a-42dd-48de-8857-bc87c9b5a206",
      "authors": [
        "T Gilbert",
        "C Scotti",
        "G Strasser",
        "C Vega"
      ],
      "title": "Why do certain macroeconomic news announcements have a big impact on asset prices?",
      "publication": "Applied Econometrics Forecasting Macro Finance Workshop",
      "year": 2010
    },
    {
      "id": "1413bac1-971d-4f84-929f-a1915df4601a",
      "authors": [
        "Thomas Gilbert",
        "Chiara Scotti",
        "Georg Strasser",
        "Clara Vega"
      ],
      "title": "Is the intrinsic value of a macroeconomic news announcement related to its asset price impact?",
      "publication": "Journal of Monetary Economics",
      "year": 2017,
      "volume": "92",
      "pages": "78-95"
    },
    {
      "id": "06493ede-4723-43fc-92f5-931b8541e255",
      "authors": [
        "Linda Goldberg",
        "Christian Grisse"
      ],
      "title": "Time variation in asset price responses to macro announcements",
      "publication": "Swiss National Bank Working Papers",
      "year": 2013,
      "volume": "2013-11"
    },
    {
      "id": "d0463a18-7651-4cb8-8264-33d01c5e9680",
      "authors": [
        "Mononito Goswami",
        "Konrad Szafer",
        "Arjun Choudhry",
        "Yifu Cai",
        "Shuo Li",
        "Artur Dubrawski"
      ],
      "title": "MOMENT: A Family of Open Time-series Foundation Models",
      "publication": "ICML",
      "year": 2024
    },
    {
      "id": "81d59b83-9432-4d73-81f5-63988cb3074b",
      "authors": [
        "Huy D. Huynh",
        "L. Minh Dang",
        "Duc Duong"
      ],
      "title": "A New Model for Stock Price Movements Prediction Using Deep Neural Network",
      "publication": "SoICT",
      "year": 2017
    },
    {
      "id": "31e53630-0ae4-4e3f-a753-3b860081451a",
      "authors": [
        "Tae Hyup Roh"
      ],
      "title": "Forecasting the volatility of stock price index",
      "publication": "Expert Systems with Applications",
      "year": 2007,
      "volume": "33",
      "pages": "916-922"
    },
    {
      "id": "2da4e868-3ee1-4846-b840-2a91b5353fd9",
      "authors": [
        "Furong Jia",
        "Kevin Wang",
        "Yixiang Zheng",
        "Defu Cao",
        "Yan Liu"
      ],
      "title": "GPT4MTS: Prompt-based Large Language Model for Multimodal Time-series Forecasting",
      "publication": "AAAI",
      "year": 2024
    },
    {
      "id": "ea05da57-a5d6-4977-aa33-2d58ffbbcdfc",
      "authors": [
        "Divyansh Kaushik",
        "Eduard Hovy",
        "Zachary Lipton"
      ],
      "title": "Learning The Difference That Makes A Difference With Counterfactually-Augmented Data",
      "publication": "ICLR",
      "year": 2020
    },
    {
      "id": "20a7cb74-4250-48ae-9534-802c9f6b42df",
      "authors": [
        "Suk Joong Kim",
        "Michael D. McKenzie",
        "Robert W. Faff"
      ],
      "title": "Macroeconomic news announcements and the role of expectations: Evidence for US bond, stock and foreign exchange markets",
      "publication": "Journal of Multinational Financial Management",
      "year": 2004,
      "volume": "14",
      "pages": "217-232"
    },
    {
      "id": "bcf986e4-bd1a-4b58-9dd6-edda9c7a6e0d",
      "authors": [
        "Geon Lee",
        "Wenchao Yu",
        "Wei Cheng",
        "Haifeng Chen"
      ],
      "title": "MoAT: Multi-Modal Augmented Time Series Forecasting",
      "publication": "OpenReview",
      "year": 2024
    },
    {
      "id": "f9230e81-951f-4b75-82ad-ae83eb4d6a4d",
      "authors": [
        "Qing Li",
        "TieJun Wang",
        "Ping Li",
        "Ling Liu",
        "Qixu Gong",
        "Yuanzhu Chen"
      ],
      "title": "The effect of news and public mood on stock movements",
      "publication": "Information Sciences",
      "year": 2014,
      "volume": "278",
      "pages": "826-840"
    },
    {
      "id": "894f1738-e0ac-45db-98a5-4e5477025ac0",
      "authors": [
        "Huicheng Liu"
      ],
      "title": "Leveraging Financial News for Stock Trend Prediction with Attention-Based Recurrent Neural Network",
      "publication": "arXiv",
      "year": 2018
    },
    {
      "id": "e7566508-363e-4c1b-9da1-6c0f5d81a7e9",
      "authors": [
        "Yong Liu",
        "Tengge Hu",
        "Haoran Zhang",
        "Haixu Wu",
        "Shiyu Wang",
        "Lintao Ma",
        "Mingsheng Long"
      ],
      "title": "iTransformer: Inverted Transformers Are Effective for Time Series Forecasting",
      "publication": "ICLR",
      "year": 2024
    },
    {
      "id": "927f7f83-fbb6-4788-9a6b-d07ab54b4a94",
      "authors": [
        "Yinhan Liu",
        "Myle Ott",
        "Naman Goyal",
        "Jingfei Du",
        "Mandar Joshi",
        "Danqi Chen",
        "Omer Levy",
        "Mike Lewis",
        "Luke Zettlemoyer",
        "Veselin Stoyanov"
      ],
      "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
      "publication": "arXiv",
      "year": 2019
    },
    {
      "id": "76bcc7cc-b510-461b-8741-d1eb4a4a5ebe",
      "authors": [
        "Yong Liu",
        "Haoran Zhang",
        "Chenyu Li",
        "Xiangdong Huang",
        "Jianmin Wang",
        "Mingsheng Long"
      ],
      "title": "Timer: Generative Pre-trained Transformers Are Large Time Series Models",
      "publication": "ICML",
      "year": 2024
    },
    {
      "id": "e21af09f-5c62-49fd-a070-b02b6176cc76",
      "authors": [
        "David O. Lucca",
        "Emanuel Moench"
      ],
      "title": "The Pre-FOMC Announcement Drift",
      "publication": "Journal of Finance",
      "year": 2015,
      "volume": "70",
      "pages": "329-371"
    },
    {
      "id": "188396da-17c1-481a-88b9-34af191abd25",
      "authors": [
        "Donato Masciandaro",
        "Oana Peia",
        "Davide Romelli"
      ],
      "title": "Central bank communication and social media: From silence to Twitter",
      "publication": "Journal of Economic Surveys",
      "year": 2024,
      "volume": "38",
      "pages": "365-388"
    },
    {
      "id": "b7272b62-9b54-44c2-a688-f7177a2a76f7",
      "authors": [
        "Puneet Mathur",
        "Atula Neerkaje",
        "Malika Chhibber",
        "Ramit Sawhney",
        "Fuming Guo",
        "Franck Dernoncourt",
        "Sanghamitra Dutta",
        "Dinesh Manocha"
      ],
      "title": "MONOPOLY: Financial Prediction from MONetary POLiCY Conference Videos Using Multimodal Cues",
      "publication": "MM",
      "year": 2022
    },
    {
      "id": "dc01a5e3-98a1-4e9b-9fd7-1c8ea20145c5",
      "authors": [
        "Thien Hai Nguyen",
        "Kiyoaki Shirai",
        "Julien Velcin"
      ],
      "title": "Sentiment analysis on social media for stock movement prediction",
      "publication": "Expert Systems with Applications",
      "year": 2015,
      "volume": "42",
      "pages": "9603-9611"
    },
    {
      "id": "f4bf8dff-5729-4b59-8f96-0612e11f520f",
      "authors": [
        "Kun Ouyang",
        "Yi Liu",
        "Shicheng Li",
        "Ruihan Bao",
        "Keiko Harimoto",
        "Xu Sun"
      ],
      "title": "Modal-adaptive Knowledge-enhanced Graph-based Financial Prediction from Monetary Policy Conference Calls with LLM",
      "publication": "FinNLP-KDF-ECONLP",
      "year": 2024
    },
    {
      "id": "ccb96a53-ba6c-4626-8200-37c377033fb8",
      "authors": [
        "Douglas K Pearce",
        "V. Vance Roley"
      ],
      "title": "Stock Prices and Economic News",
      "publication": "National Bureau of Economic Research Working Paper",
      "year": 1984
    },
    {
      "id": "b198a6f6-71d9-461a-966a-1cab1f0d5dad",
      "authors": [
        "G. Pui Cheong Fung",
        "J. Xu Yu",
        "Wai Lam"
      ],
      "title": "Stock prediction: Integrating text mining approach using real-time news",
      "publication": "CIFEr",
      "year": 2003,
      "pages": "395-402"
    },
    {
      "id": "bb81ff0f-f525-43f7-a12e-d046108ecd5b",
      "authors": [
        "Yu Qin",
        "Yi Yang"
      ],
      "title": "What You Say and How You Say It Matters: Predicting Stock Volatility Using Verbal and Vocal Cues",
      "publication": "ACL",
      "year": 2019
    },
    {
      "id": "658770b5-40db-4e24-8531-1541550dab22",
      "authors": [
        "Alec Radford",
        "Jeffrey Wu",
        "Rewon Child",
        "David Luan",
        "Dario Amodei",
        "Ilya Sutskever"
      ],
      "title": "Language models are unsupervised multitask learners",
      "publication": "OpenAI blog",
      "year": 2019,
      "volume": "1",
      "pages": "9"
    },
    {
      "id": "50d0e248-f37b-4e73-abf2-eae7d0ad4635",
      "authors": [
        "Carlo Rosa"
      ],
      "title": "Words that shake traders: The stock market's reaction to central bank communication in real time",
      "publication": "Journal of Empirical Finance",
      "year": 2011,
      "volume": "18",
      "pages": "915-934"
    },
    {
      "id": "d4b937af-b1cb-4781-a832-b70ad7480634",
      "authors": [
        "Carlo Rosa"
      ],
      "title": "The financial market effect of FOMC minutes",
      "publication": "Economic Policy Review",
      "year": 2013,
      "pages": "67-81"
    },
    {
      "id": "11749a0b-fe8a-4402-8ec1-0a9dc256f815",
      "authors": [
        "Carlo Rosa"
      ],
      "title": "Fedspeak: Who Moves U.S. Asset Prices?",
      "publication": "International Journal of Central Banking",
      "year": 2016,
      "volume": "12",
      "pages": "223-261"
    },
    {
      "id": "d54190a3-45e3-4eb8-98c2-ae7215c72fee",
      "authors": [
        "Alexis Ross",
        "Tongshuang Wu",
        "Hao Peng",
        "Matthew Peters",
        "Matt Gardner"
      ],
      "title": "Tailor: Generating and Perturbing Text with Semantic Controls",
      "publication": "ACL",
      "year": 2022
    },
    {
      "id": "7ce857f6-5440-4128-ac67-9601eedb9660",
      "authors": [
        "Ramit Sawhney",
        "Shivam Agarwal",
        "Arnav Wadhwa",
        "Rajiv Ratn Shah"
      ],
      "title": "Deep Attentive Learning for Stock Movement Prediction From Social Media Text and Company Correlations",
      "publication": "EMNLP",
      "year": 2020
    },
    {
      "id": "f6cde1da-3bd0-40d1-8768-21eac22edcf0",
      "authors": [
        "Ramit Sawhney",
        "Puneet Mathur",
        "Ayush Mangal",
        "Piyush Khanna",
        "Rajiv Ratn Shah",
        "Roger Zimmermann"
      ],
      "title": "Multimodal Multi-Task Financial Risk Forecasting",
      "publication": "MM",
      "year": 2020
    },
    {
      "id": "7662cd72-58b4-49a6-b224-62c3920de3cd",
      "authors": [
        "Sreelekhmy Selvin",
        "R Vinayakumar",
        "E. A Gopalakrishnan",
        "Vijay Krishna Menon",
        "K. P. Soman"
      ],
      "title": "Stock price prediction using LSTM, RNN and CNN-sliding window model",
      "publication": "ICACCI",
      "year": 2017
    },
    {
      "id": "0d24529a-7982-40fd-9d4f-285440c9ad6e",
      "authors": [
        "Agam Shah",
        "Suvan Paturi",
        "Sudheer Chava"
      ],
      "title": "Trillion Dollar Words: A New Financial Dataset, Task & Market Analysis",
      "publication": "ACL",
      "year": 2023
    },
    {
      "id": "2d0ef96e-87ad-4b52-8caa-a62e86204324",
      "authors": [
        "Jianfeng Si",
        "Arjun Mukherjee",
        "Bing Liu",
        "Qing Li",
        "Huayi Li",
        "Xiaotie Deng"
      ],
      "title": "Exploiting Topic based Twitter Sentiment for Stock Prediction",
      "publication": "ACL",
      "year": 2013
    },
    {
      "id": "c81696b1-9468-4ff4-9801-4dd2cd242c64",
      "authors": [
        "Chenxi Sun",
        "Hongyan Li",
        "Yaliang Li",
        "Shenda Hong"
      ],
      "title": "TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series",
      "publication": "ICLR",
      "year": 2024
    },
    {
      "id": "1fe7abb9-a294-4bc5-b20b-6403377d7acf",
      "authors": [
        "Raul Cruz Tadle"
      ],
      "title": "FOMC minutes sentiments and their impact on financial markets",
      "publication": "Journal of Economics and Business",
      "year": 2022,
      "volume": "118",
      "pages": "106021"
    },
    {
      "id": "a9421a7d-c9b8-4d63-8bb9-ae24a09a88d5",
      "authors": [
        "Sabera J Talukder",
        "Yisong Yue",
        "Georgia Gkioxari"
      ],
      "title": "TOTEM: TTokenizered Time Series EMBEDdings for General Time Series Analysis",
      "publication": "TMLR",
      "year": 2024
    },
    {
      "id": "a1c7c990-3601-4764-9a01-89f9f414028a",
      "authors": [
        "Stephen J Taylor"
      ],
      "title": "Modelling Financial Time Series",
      "publication": "World Scientific Publishing",
      "year": 2007
    },
    {
      "id": "82230592-8f5a-45e3-8345-d4fde93645ec",
      "authors": [
        "Yizhong Wang",
        "Yeganeh Kordi",
        "Swaroop Mishra",
        "Alisa Liu",
        "Noah A. Smith",
        "Daniel Khashabi",
        "Hannaneh Hajishirzi"
      ],
      "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
      "publication": "ACL",
      "year": 2023
    },
    {
      "id": "f738a97d-b966-4e17-b0d7-311126c29503",
      "authors": [
        "Tongshuang Wu",
        "Marco Tulio Ribeiro",
        "Jeffrey Heer",
        "Daniel Weld"
      ],
      "title": "Polyjuice: Generating Counterfactuals for Explaining, Evaluating, and Improving Models",
      "publication": "ACL",
      "year": 2021
    },
    {
      "id": "613f79eb-4328-443a-8531-df32654d5244",
      "authors": [
        "Yumo Xu",
        "Shay B. Cohen"
      ],
      "title": "Stock Movement Prediction from Tweets and Historical Prices",
      "publication": "ACL",
      "year": 2018
    },
    {
      "id": "a806b7a9-245f-4188-8852-baffc8bc6be4",
      "authors": [
        "Linyi Yang",
        "Tin Lok James Ng",
        "Barry Smyth",
        "Riuhai Dong"
      ],
      "title": "HTML: Hierarchical Transformer-based Multi-task Learning for Volatility Prediction",
      "publication": "WWW",
      "year": 2020
    },
    {
      "id": "247df378-e80b-4322-9840-4d16423f1a11",
      "authors": [
        "Ailing Zeng",
        "Muxi Chen",
        "Lei Zhang",
        "Qiang Xu"
      ],
      "title": "Are Transformers Effective for Time Series Forecasting?",
      "publication": "AAAI",
      "year": 2023
    },
    {
      "id": "668048fc-90e5-4b73-9644-40e7a27a320e",
      "authors": [
        "Haoyi Zhou",
        "Shanghang Zhang",
        "Jieqi Peng",
        "Shuai Zhang",
        "Jianxin Li",
        "Hui Xiong",
        "Wancai Zhang"
      ],
      "title": "Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting",
      "publication": "AAAI",
      "year": 2021
    },
    {
      "id": "72e03092-47da-447c-8311-14c8d02d936b",
      "authors": [
        "Tian Zhou",
        "Ziqing Ma",
        "Qingsong Wen",
        "Xue Wang",
        "Liang Sun",
        "Rong Jin"
      ],
      "title": "FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting",
      "publication": "ICML",
      "year": 2022
    },
    {
      "id": "7a1f58c8-1799-43ba-a61c-39917522cdbe",
      "authors": [
        "Zhihan Zhou",
        "Liqian Ma",
        "Han Liu"
      ],
      "title": "Trade the Event: Corporate Events Detection for News-Based Event-Driven Trading",
      "publication": "ACL Findings",
      "year": 2021
    }
  ],
  "blockNotes": [],
  "checklistNotes": [],
  "attachments": []
}
{
  "abstract": {
    "en": "Accurately forecasting the impact of macroeconomic events is critical for investors and policymakers. Salient events like monetary policy decisions and employment reports often trigger market movements by shaping expectations of economic growth and risk, thereby establishing causal relationships between events and market behavior. Existing forecasting methods typically focus either on textual analysis or time-series modeling, but fail to capture the multi-modal nature of financial markets and the causal relationship between events and price movements. To address these gaps, we propose CAMEF (Causal-Augmented Multi-Modality Event-Driven Financial Forecasting), a multi-modality framework that effectively integrates textual and time-series data with a causal learning mechanism and an LLM-based counterfactual event augmentation technique for causal-enhanced financial forecasting. Our contributions include: (1) a multi-modal framework that captures causal relationships between policy texts and historical price data; (2) a new financial dataset with six types of macroeconomic releases from 2008 to April 2024, and high-frequency real trading data for five key U.S. financial assets; and (3) an LLM-based counterfactual event augmentation strategy. We compare CAMEF to state-of-the-art transformer-based time-series and multi-modal baselines, and perform ablation studies to validate the effectiveness of the causal learning mechanism and event types.",
    "zh": "精准预测宏观经济事件的影响对投资者和政策制定者至关重要。货币政策决议与就业报告等重大事件往往通过塑造经济增长预期和风险认知来引发市场波动，从而在事件与市场行为之间建立因果关系。现有预测方法通常侧重于文本分析或时间序列建模，但未能捕捉金融市场的多模态特性以及事件与价格变动之间的因果联系。为弥补这些不足，我们提出CAMEF（因果增强多模态事件驱动金融预测框架），该多模态框架通过因果学习机制与基于大语言模型的反事实事件增强技术，将文本数据与时间序列数据进行有效整合，实现因果增强的金融预测。我们的贡献包括：（1）能够捕捉政策文本与历史价格数据间因果关系的多模态框架；（2）包含2008年至2024年4月六类宏观经济数据发布及五大美国金融资产高频实盘交易数据的新金融数据集；（3）基于大语言模型的反事实事件增强策略。我们将CAMEF与基于Transformer的先进时序模型和多模态基线进行对比，并通过消融实验验证因果学习机制与事件类型的有效性。"
  },
  "keywords": [],
  "sections": [
    {
      "id": "section-627c82cf-b1fb-4347-b172-b189de280ef5",
      "title": {
        "en": "Introduction",
        "zh": "引言"
      },
      "content": [
        {
          "id": "heading-df1d5fe2-2c04-470d-8682-1aa45bcd601b",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Introduction"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "引言"
              }
            ]
          }
        },
        {
          "id": "paragraph-64e14078-6786-4aef-bbd8-b65899375988",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "The prices of financial assets reflect all available information, according to Fama's Efficient Market Theory [15, 16]. Major financial releases from government sectors often trigger market movements by shaping investors' expectations and evaluations of economic conditions, asset growth potential, and associated risks. For example, during the FOMC meeting on March 16, 2020, the Fed's emergency rate cut to  "
              },
              {
                "type": "inline-math",
                "latex": "$0 - 0.25\\%$"
              },
              {
                "type": "text",
                "content": "  sharply altered investors' economic outlook, resulting in a massive sell-off. Major indices, including the S&P 500, NASDAQ, and Dow Jones, dropped by over  "
              },
              {
                "type": "inline-math",
                "latex": "10\\%"
              },
              {
                "type": "text",
                "content": " , marking the steepest single-day decline since 1987 [13]. These salient macroeconomic events cause reactions in financial assets, establishing causal relationships between events and financial assets. Figure 1 illustrates multiple types of events that cause financial market reactions. Therefore, accurately forecasting the causal consequences of the salient macroeconomic releases on financial market is essential, not only to help investors manage risks and maximize returns, but also to provide policymakers with valuable insights for evaluating and refining future policies.\nPrevious studies on event-driven forecasting have primarily adopted three lines of methodologies. The first line of approaches utilizes text feature-based models, where language models, ranging from self-crafted RNN-based architectures [11, 22, 29, 57] to pre-trained transformers [49, 62], embed sentiment information into text vectors, and then stock movements are predicted as a binary classification task (e.g., hawkish vs. dovish). The second line of methodology focuses on historical time-series data, treating"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "根据法玛的有效市场理论[15, 16]，金融资产价格反映所有可用信息。政府部门发布的重要金融信息往往通过影响投资者对经济状况、资产增长潜力及相关风险的预期和评估，从而引发市场波动。例如在2020年3月16日的FOMC会议期间，美联储紧急降息至    的举措急剧改变了投资者的经济预期，引发大规模抛售。标普500、纳斯达克和道琼斯等重要指数跌幅超过    ，创下1987年以来最大单日跌幅[13]。这类显著宏观经济事件会引起金融资产的反应，建立事件与金融资产间的因果关系。图1展示了引发金融市场反应的多类事件。因此，准确预测重大宏观经济发布对金融市场的因果影响至关重要，既能帮助投资者管理风险、最大化收益，也可为政策制定者评估和完善未来政策提供宝贵参考。\n\n现有事件驱动预测研究主要采用三类方法。第一类基于文本特征的模型，从自建的RNN架构[11, 22, 29, 57]到预训练Transformer[49, 62]等语言模型将情感信息嵌入文本向量，然后将股价变动作为二元分类任务（如鹰派vs鸽派）进行预测。第二类方法聚焦历史时间序列数据，将"
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "figure-53b1c60d-a20f-41fc-abba-964770e13312",
          "type": "figure",
          "src": "/uploads/images/57bd0223-f398-4636-a9c9-b50bc4e35c79/figure-53b1c60d-a20f-41fc-abba-964770e13312.jpg",
          "caption": {
            "en": [],
            "zh": []
          },
          "uploadedFilename": "figure-53b1c60d-a20f-41fc-abba-964770e13312.jpg"
        },
        {
          "id": "figure-a9ad11d8-d5d1-4ef3-8f3c-51d6403020b2",
          "type": "figure",
          "src": "/uploads/images/57bd0223-f398-4636-a9c9-b50bc4e35c79/figure-a9ad11d8-d5d1-4ef3-8f3c-51d6403020b2.jpg",
          "caption": {
            "en": [],
            "zh": []
          },
          "uploadedFilename": "figure-a9ad11d8-d5d1-4ef3-8f3c-51d6403020b2.jpg"
        },
        {
          "id": "paragraph-e7bde0e5-8b89-4cd6-adc7-1c6a5b4fb2c5",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Event: FOMC Release"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "事件：FOMC发布"
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "figure-c36040f5-044f-4326-9680-d1d1a5902dc7",
          "type": "figure",
          "src": "/uploads/images/57bd0223-f398-4636-a9c9-b50bc4e35c79/figure-c36040f5-044f-4326-9680-d1d1a5902dc7.jpg",
          "caption": {
            "en": [],
            "zh": []
          },
          "uploadedFilename": "figure-c36040f5-044f-4326-9680-d1d1a5902dc7.jpg"
        },
        {
          "id": "paragraph-26d442f3-559f-43b6-a0f8-fb8a5926c29d",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "New Event: CPI Release"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "新事件：CPI发布"
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "figure-236a38e2-0549-4194-a4fd-cf9c3566dc33",
          "type": "figure",
          "src": "/uploads/images/57bd0223-f398-4636-a9c9-b50bc4e35c79/figure-236a38e2-0549-4194-a4fd-cf9c3566dc33.jpg",
          "caption": {
            "en": [
              {
                "type": "text",
                "content": "Event-Driven Forecasting Examples: (a) Market reaction to employment insurance release; (b) Market reaction during FOMC meeting; (c) Forecasting market reactions to future events."
              }
            ],
            "zh": []
          },
          "uploadedFilename": "figure-236a38e2-0549-4194-a4fd-cf9c3566dc33.jpg"
        },
        {
          "id": "figure-b8f30235-b49b-4b8e-b136-9a992c12ba4a",
          "type": "figure",
          "src": "/uploads/images/57bd0223-f398-4636-a9c9-b50bc4e35c79/figure-b8f30235-b49b-4b8e-b136-9a992c12ba4a.jpg",
          "caption": {
            "en": [],
            "zh": []
          },
          "uploadedFilename": "figure-b8f30235-b49b-4b8e-b136-9a992c12ba4a.jpg"
        },
        {
          "id": "figure-0e854bd6-e849-49ed-a2e3-2d70585853ab",
          "type": "figure",
          "src": "/uploads/images/57bd0223-f398-4636-a9c9-b50bc4e35c79/figure-0e854bd6-e849-49ed-a2e3-2d70585853ab.jpg",
          "caption": {
            "en": [],
            "zh": []
          },
          "uploadedFilename": "figure-0e854bd6-e849-49ed-a2e3-2d70585853ab.jpg"
        },
        {
          "id": "paragraph-d5672f9b-23a7-4b60-b7f3-08c684cd433a",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "stock price movements as a regression problem [7, 54]. Recently, transformer-based architectures have been applied for time-series prediction, including Informer [60], FedFormer [61], and AutoFormer [8], etc. However, both of these directions typically focus on a single modality, neglecting multi-dimensional information. The third line of research adopts a multi-modality approach, leveraging multiple types of data sources to enhance forecasting performance. For instance, studies like [35, 37] incorporate textual, video, and audio data from FOMC meetings alongside corresponding market movements. While these approaches show promise for event-driven financial forecasts, they face three major limitations:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "股价变动视为回归问题[7, 54]。近期Transformer架构已被应用于时间序列预测，包括Informer[60]、FedFormer[61]和AutoFormer[8]等。然而这两类方法通常局限于单一模态，忽略了多维信息。第三类研究采用多模态方法，利用多源数据提升预测性能。例如[35, 37]等研究结合FOMC会议文本、视频和音频数据与对应市场波动。虽然这些方法在事件驱动金融预测中展现潜力，但存在三大局限："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "unordered-list-4af8ef09-5daf-4b1a-8efd-400565b27c4e",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Data Limitation: Existing approaches predominantly focus on a single type of event, such as FOMC meetings [35, 37, 49], while neglecting other crucial macroeconomic events like unemployment insurance releases, CPI, PPI, and GDP advance reports. Additionally, many studies rely on daily-based time-series data for financial assets [7, 8, 35, 37, 49, 54, 60, 61], which limits their applicability and precision in real-time trading scenarios where high-frequency data is mostly adopted."
                  }
                ],
                "zh": []
              }
            },
            {
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Modality Limitation: Most prior studies rely on single-modality analysis, using either textual models [11, 22, 29, 49, 57, 62] or time-series models [7, 8, 54, 60, 61], which fail to integrate the complementary strengths of both modalities. While some multi-modality approaches have been proposed [35, 37], they often lack advanced mechanisms for feature fusion, effective decoding strategies, and causal learning, which are critical for understanding the complex interplay between event texts and market dynamics."
                  }
                ],
                "zh": []
              }
            },
            {
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Causality Limitation: Existing methods [35, 37] fail to incorporate causal reasoning frameworks, overlooking the causal relationships between events and market reactions."
                  }
                ],
                "zh": []
              }
            }
          ]
        },
        {
          "id": "paragraph-85b46e2b-4b1c-4cab-a381-0fa7be05645a",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Without explicitly modeling these relationships, such approaches cannot fully capture the drivers of financial market behavior, limiting their predictive robustness.\nTo address the limitations of previous studies, we propose a novel multi-modality framework, CAMEF<sup>1</sup> (causal-Augmented Multi-Modality Event-Driven Financial Forecasting). CAMEF integrates time-series and textual features through specially designed multi-feature fusion techniques, time-series decoding mechanisms, and causal learning strategies. By conducting a thorough review of financial literature, we identify six types of salient macroeconomic events for the forecasting analysis. Furthermore, the framework employs causal data augmentation powered by Large Language Models (LLMs) and a causal contrastive learning approach to enhance the causal understanding and forecast accuracy of CAMEF. This paper offers three key contributions:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "由于未显式建模这些关系，此类方法无法完全捕捉金融市场行为的驱动因素，限制了预测稳健性。\n\n为克服现有研究的局限，我们提出新颖的多模态框架CAMEF<sup>1</sup>（因果增强多模态事件驱动金融预测）。该框架通过专门设计的多特征融合技术、时间序列解码机制和因果学习策略，整合时间序列与文本特征。基于对金融文献的系统梳理，我们确定了六类重要宏观经济事件用于预测分析。此外，框架采用大语言模型驱动的因果数据增强和因果对比学习方法，以强化CAMEF的因果理解与预测精度。本文有三项主要贡献："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "unordered-list-61fe6021-093b-4309-9fee-7617edb79879",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Novel Dataset: We introduce a novel open-source synthetic dataset comprising 6 types of macroeconomic event scripts (ref to Tab. 1 for details) from 2008 to April 2024 through reviewing from financial literature [3, 10, 17-20, 26, 33, 34, 38, 42-44, 52], alongside intra-day _high-frequency financial data at 5-minute intervals from key U.S. stock indexes and Treasury bonds. To support causal learning, the dataset also includes counterfactual event scripts generated using our LLM-based causal argumentation prompting, making it the first to integrate policy texts, high-frequency trading data, and causally augmented content."
                  }
                ],
                "zh": []
              }
            },
            {
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Novel Multi-Modality Model: We propose a novel multimodality approach, CAMEF, that integrates time-series and textual features, incorporating specifically designed multi-feature fusion and time-series decoding networks, which"
                  }
                ],
                "zh": []
              }
            }
          ]
        },
        {
          "id": "paragraph-88d59cb2-dce0-45de-a0ad-5433fbd05ba6",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "have been demonstrated to be effective for forecasting. Additionally, the model includes a causal learning mechanism to enhance forecasting capability by capturing the causal relationships between events and market reactions."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "已被证明对预测有效。同时模型包含因果学习机制，通过捕捉事件与市场反应间的因果关系来增强预测能力。"
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "unordered-list-828aaf5f-4271-4d39-b95a-7d5066309b44",
          "type": "unordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Counterfactual Generation and Learning: We introduce a counterfactual data augmentation strategy to generate counterfactual event scripts based on collected macroeconomic releases. This approach leverages LLMs to create scripts with varying sentiment levels by modifying key numerical values and sentiment-relevant phrases, while preserving the original format, writing style, and neutral words of the factual reports. Counterfactual events enable CAMEF to better understand the causal relationships between events and market reactions by learning from hypothetical scenarios, thereby improving its forecasting ability."
                  }
                ],
                "zh": []
              }
            }
          ]
        }
      ],
      "subsections": []
    },
    {
      "id": "section-7148b52a-d709-480f-bb94-0dfa165b9829",
      "title": {
        "en": "Related Work",
        "zh": "相关工作"
      },
      "content": [
        {
          "id": "heading-8bc9b327-2792-4ad2-b4f4-e1eb4b92ef0b",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Related Work"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "相关工作"
              }
            ]
          }
        }
      ],
      "subsections": []
    },
    {
      "id": "section-4c583659-6a45-48c0-8f9b-0bce4c238a6c",
      "title": {
        "en": "Event-Drive Financial Forecasting",
        "zh": "事件驱动金融预测"
      },
      "content": [
        {
          "id": "heading-4a21f09b-d05f-412f-8539-b57aa154f1fe",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Event-Drive Financial Forecasting"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "事件驱动金融预测"
              }
            ]
          }
        },
        {
          "id": "paragraph-25f8ff08-9897-42d2-86dd-5703a0e6c5ba",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Event-driven financial forecasting [2] focuses on predicting asset prices [18, 20] and market volatility [10, 33] based on events like macroeconomic releases [18], news [29], corporate announcements [62], and social media activity [57]. Three main approaches exist in this area. The first leverages text analysis to predict asset responses based on event-related text. Early works utilized TF-IDF [28, 39] and topic models [36, 50], progressing to RNN-based models [22, 29] and pre-trained transformers [49, 62], which capture nuanced semantics. Although these models excel at semantic extraction, they often lack integration with historical price data, crucial for holistic forecasting.\nThe second line of approaches uses statistical and sequential models on numerical data, such as linear regression [5], ARIMA [1], and GARCH [23]. Later, deep learning methods like RNNs [29] and CNNs [14, 48] enhanced nonlinear modeling capabilities. More recently, transformer-based models, such as Informer [60] and FedFormer [61], improved long-range dependency modeling for time series data. However, these models tend to be \"case-specific,\" requiring task-specific training. In contrast, the latest pre-trained models for time-series data, like MOMENT [21], Timer [32], and TOKEN [53], offer more generalized and adaptable solutions for time-series tasks.\nThe third line of research adopts multi-modality approaches, combining diverse data types to improve forecasting accuracy. Some studies incorporate text and audio [40, 58] but often overlook time-series dependencies. Recent work has integrated time-series and textual data; for example, [46, 47] employed SVM and GRU models to capture time-series features. However, these models are relatively shallow for extracting complex patterns. More recent studies [24, 27] leverage transformer-based models for time-series analysis, better capturing deeper temporal structures. Building on these advancements, this paper aims to utilize state-of-the-art pre-trained models with enhanced feature fusion and causal learning for multimodality forecasting."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "事件驱动金融预测[2]专注于基于宏观经济发布[18]、新闻[29]、企业公告[62]和社交媒体活动[57]等事件预测资产价格[18, 20]和市场波动率[10, 33]。该领域存在三类主流方法。第一类利用文本分析基于事件相关文本预测资产反应。早期研究采用TF-IDF[28, 39]和主题模型[36, 50]，逐步发展到基于RNN的模型[22, 29]和预训练Transformer[49, 62]，后者能捕捉细微语义。虽然这些模型擅长语义提取，但常缺乏与历史价格数据的整合，而这对于全面预测至关重要。\n\n第二类方法对数值数据使用统计和序列模型，如线性回归[5]、ARIMA[1]和GARCH[23]。随后RNN[29]和CNN[14, 48]等深度学习方法增强了非线性建模能力。最近，基于Transformer的模型如Informer[60]和FedFormer[61]改进了时间序列数据的长期依赖建模。但这些模型往往具有“案例特异性”，需针对特定任务训练。相比之下，最新时间序列预训练模型如MOMENT[21]、Timer[32]和TOKEN[53]为时间序列任务提供了更通用、适应性更强的解决方案。\n\n第三类研究采用多模态方法，结合多类数据提升预测精度。部分研究纳入文本和音频[40, 58]但常忽略时间序列依赖。近期研究开始整合时间序列与文本数据，例如[46, 47]使用SVM和GRU模型捕捉时间序列特征。但这些模型在提取复杂模式时深度不足。最新研究[24, 27]利用基于Transformer的模型进行时间序列分析，能更好捕捉深层时间结构。基于这些进展，本文旨在利用最先进的预训练模型，通过增强的特征融合和因果学习实现多模态预测。"
              }
            ]
          },
          "align": "left"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-d51a64f6-7f00-4010-87bc-8a55cc9714a9",
      "title": {
        "en": "Salient Macroeconomic Factors",
        "zh": "重要宏观经济因素"
      },
      "content": [
        {
          "id": "heading-3ddbf0ab-0331-4008-a34a-80201bb58fdd",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Salient Macroeconomic Factors"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "重要宏观经济因素"
              }
            ]
          }
        },
        {
          "id": "paragraph-6086d047-935d-4c44-845d-9ce41184e50d",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Which macroeconomic announcements have a greater impact on financial markets than others? This question has been\nwidely studied in the financial literature, with Central Bank Communications standing out as the most-researched factor [10, 17, 33, 34, 42-44, 52]. Beyond central bank communications, various other macroeconomic factors have also been identified as significant drivers of market movements. Among these, Non-farm Payrolls, Unemployment Releases, Initial Unemployment Claims, ISM Manufacturing Index, GDP Advance Releases, Consumer Confidence Index, and Producer Price Index (PPI) Reports have been found to notably influence price movements and market volatility through empirical statistical testings [3, 18-20, 26, 38]. In this paper, we aim to leverage the most significant factors evidenced by the past financial literautre [3, 18-20, 26, 38], which include FOMC Meeting Documents, Non-farm Payrolls, Unemployment Releases, Initial Unemployment Claims, ISM Manufacturing Index, GDP Advance Releases, Consumer Confidence Index, and Producer Price Index (PPI) Reports."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "哪些宏观经济公告对金融市场影响更大？这个问题在金融文献中被广泛研究，其中央行沟通是被研究最多的因素[10, 17, 33, 34, 42-44, 52]。除央行沟通外，其他多种宏观经济因素也被确认为市场波动的重要驱动因素。其中，非农就业数据、失业率发布、首次失业救济申请、ISM制造业指数、GDP初值、消费者信心指数和生产价格指数（PPI）报告通过实证统计检验[3, 18-20, 26, 38]被证明显著影响价格波动和市场波动性。本文旨在利用过往金融文献[3, 18-20, 26, 38]证实的最重要因素，包括FOMC会议文件、非农就业数据、失业率发布、首次失业救济申请、ISM制造业指数、GDP初值、消费者信心指数和生产价格指数（PPI）报告。"
              }
            ]
          },
          "align": "left"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-8675b22e-176c-4215-9269-1744343ca961",
      "title": {
        "en": "Counterfactual Data Augmentation by LLMs",
        "zh": "LLM反事实数据增强"
      },
      "content": [
        {
          "id": "heading-2b5b79a1-f1e7-48ea-9e97-d03e122f28e5",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Counterfactual Data Augmentation by LLMs"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "LLM反事实数据增强"
              }
            ]
          }
        },
        {
          "id": "paragraph-e1182a76-226f-407d-b9a8-e88526aca9c2",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Counterfactual Data Augmentation seeks to reduce spurious correlations and enhance model robustness. Kaushik et al. [25] introduced a method that augments training data with counterfactuals written by human annotators, effectively helping to mitigate spurious patterns. Ross et al. [45], Wu et al. [56] later proposed the use of hand-crafted templates and trained text generators to create counterfactual data through predefined perturbation types. However, these methods are limited by their reliance on fixed perturbations. More recently, Chen et al. [9], Wang et al. [55] proposed more flexible, LLM-based approaches that leverage specifically designed in-context learning prompts and generation pipelines for counterfactual and instruction data generation. Following this direction, we present a counterfactual generation framework specifically designed for macroeconomic releases."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "反事实数据增强旨在减少伪相关并增强模型鲁棒性。Kaushik等人[25]提出通过人工标注者撰写反事实样本来增强训练数据的方法，有效帮助缓解伪模式。Ross等人[45]、Wu等人[56]后续提出使用手工模板和训练文本生成器，通过预定义扰动类型创建反事实数据。但这些方法受限于对固定扰动的依赖。最近，Chen等人[9]、Wang等人[55]提出更灵活的基于LLM的方法，利用专门设计的上下文学习提示和生成流程进行反事实与指令数据生成。沿此方向，我们提出了专为宏观经济发布设计的反事实生成框架。"
              }
            ]
          },
          "align": "left"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-0977c39e-6185-4ebe-b92e-88d71ddc449d",
      "title": {
        "en": "Problem Formulation",
        "zh": "问题表述"
      },
      "content": [
        {
          "id": "heading-f66a87b7-a7b5-494f-a4c0-60e7ddfda6ba",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Problem Formulation"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "问题表述"
              }
            ]
          }
        },
        {
          "id": "paragraph-5d32f2f7-1bac-482c-b2cc-398cea3ecb45",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Event Set is defined as  "
              },
              {
                "type": "inline-math",
                "latex": "$\\mathbb{E} := \\{\\mathcal{E}_1, \\mathcal{E}_2, \\dots, \\mathcal{E}_{|\\mathbb{E}|}\\}$"
              },
              {
                "type": "text",
                "content": " , where  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbb{E}"
              },
              {
                "type": "text",
                "content": "  represents a collection of  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbb{E}"
              },
              {
                "type": "text",
                "content": "  event scripts. Each event  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i"
              },
              {
                "type": "text",
                "content": "  occurs at a specific timestamp  "
              },
              {
                "type": "inline-math",
                "latex": "$i$"
              },
              {
                "type": "text",
                "content": "  and belongs to one of the event types shown in Table 1A. Each event script  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i"
              },
              {
                "type": "text",
                "content": "  consists of a sequence of word tokens, represented as  "
              },
              {
                "type": "inline-math",
                "latex": "$\\mathcal{E}_i := \\{w_1, w_2, \\dots, w_m\\}$"
              },
              {
                "type": "text",
                "content": " .\nTime Series Data is defined as  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{X} \\coloneqq \\{X_1, X_2, \\ldots, X_{|\\mathcal{X}|}\\}"
              },
              {
                "type": "text",
                "content": " , where each  "
              },
              {
                "type": "inline-math",
                "latex": "X_i"
              },
              {
                "type": "text",
                "content": "  represents the numerical data at time step  "
              },
              {
                "type": "inline-math",
                "latex": "$i$"
              },
              {
                "type": "text",
                "content": " . An event  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i"
              },
              {
                "type": "text",
                "content": "  is aligned with a time series segment  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{X}_{i - \\tau : i + \\tau}"
              },
              {
                "type": "text",
                "content": " , where  "
              },
              {
                "type": "inline-math",
                "latex": "$i$"
              },
              {
                "type": "text",
                "content": "  denotes the time of the releasement of the event, and  "
              },
              {
                "type": "inline-math",
                "latex": "\\tau"
              },
              {
                "type": "text",
                "content": "  represents the duration of the time-series segment both preceding and succeeding time step  "
              },
              {
                "type": "inline-math",
                "latex": "$i$"
              },
              {
                "type": "text",
                "content": " , denoted as  "
              },
              {
                "type": "inline-math",
                "latex": "$\\mathcal{X}_{i - \\tau : i + \\tau} \\mapsto \\mathcal{E}_i$"
              },
              {
                "type": "text",
                "content": " . This alignment reflects the time series segment leading up to the event  "
              },
              {
                "type": "inline-math",
                "latex": "(X_{i - \\tau})"
              },
              {
                "type": "text",
                "content": "  and the period during which the event is expected to have an effect  "
              },
              {
                "type": "inline-math",
                "latex": "(X_{i + \\tau})"
              },
              {
                "type": "text",
                "content": " .\nEvent-Driven Forecasting: Given a dataset  "
              },
              {
                "type": "inline-math",
                "latex": "$\\mathcal{U} = \\{[\\mathcal{X}_{i - \\tau ;i + \\tau}\\mapsto \\mathcal{E}_i]\\}_{i = 1}^n$"
              },
              {
                "type": "text",
                "content": "  consisting of  "
              },
              {
                "type": "inline-math",
                "latex": "n"
              },
              {
                "type": "text",
                "content": "  aligned event and time-series pairs, for each data pair in  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{U}"
              },
              {
                "type": "text",
                "content": " , the model uses both the event text  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i"
              },
              {
                "type": "text",
                "content": "  and the historical time-series segment  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{X}_{i - \\tau ; i}"
              },
              {
                "type": "text",
                "content": " , which spans  "
              },
              {
                "type": "inline-math",
                "latex": "\\tau"
              },
              {
                "type": "text",
                "content": "  steps before the event's release at time  "
              },
              {
                "type": "inline-math",
                "latex": "$i$"
              },
              {
                "type": "text",
                "content": " , to forecast the future time steps  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{X}_{i + 1:i + \\tau}"
              },
              {
                "type": "text",
                "content": " .\nCausal Effect Graph: A Causal Effect Graph represents the causal links among variables: textual modality  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}"
              },
              {
                "type": "text",
                "content": "  (event scripts), current price trend  "
              },
              {
                "type": "inline-math",
                "latex": "$X$"
              },
              {
                "type": "text",
                "content": " , and future time series movements  "
              },
              {
                "type": "inline-math",
                "latex": "$Y$"
              },
              {
                "type": "text",
                "content": " . In event-driven financial prediction, events influence the market movements"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "事件集定义为   ，其中    表示包含    个事件脚本的集合。每个事件    发生在特定时间戳    ，属于表1A所示事件类型之一。每个事件脚本    由词元序列组成，表示为    。\n时间序列数据定义为   ，其中每个    表示时间步    的数值数据。事件    与时间序列段    对齐，其中    表示事件发布时间，    表示时间序列段在时间步    前后持续的时长，记为    。该对齐反映了事件    发生前的时间序列段及事件预期产生影响的时段    。\n事件驱动预测：给定包含    个对齐事件与时间序列对的数据集    ，对于    中的每个数据对，模型同时使用事件文本    和历史时间序列段    （涵盖事件在时间    发布前    个时间步）来预测未来时间步    。\n因果效应图：因果效应图表示变量间的因果联系：文本模态    （事件脚本）、当前价格趋势    和未来时间序列变动    。在事件驱动金融预测中，事件通过影响资产价格波动形成因果链，记为    ，如图2a所示。\n反事实事件：反事实事件（CE）指关键变量（如失业率、GDP值）相对于事实事件被修改，而上下文保持不变的事件脚本，记为    。CE用于训练CAMEF，使其能识别事实因果关系，表示为    ，如图2b所示。"
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "ordered-list-75befab8-1022-4421-a0e2-ffa7d1fb83d8",
          "type": "ordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Macroeconomic Event Summary"
                  }
                ],
                "zh": []
              }
            }
          ]
        },
        {
          "id": "paragraph-fc0bb88f-4c79-43d6-88f2-4a7d2bed71e5",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "<table><tr><td>Event Type</td><td>Data Type</td><td>Frequency</td><td>Period</td><td>No. of Events</td><td>No. of C.F.s</td><td>Source</td></tr><tr><td>FOMC</td><td>Html</td><td>Quarterly</td><td>1993.3 ~2024.6</td><td>255</td><td>2,550</td><td>www.federalreserve-gov</td></tr><tr><td>UnemploymentInsurance Claims</td><td>PDF, Txt</td><td>Weekly</td><td>2002.10 ~2024.6</td><td>913</td><td>9,130</td><td>oui.dola.gov</td></tr><tr><td>Employment Situation</td><td>Html, Txt</td><td>Monthly</td><td>1994.2 ~2024.6</td><td>363</td><td>3,630</td><td>www.bls.gov</td></tr><tr><td>GDP Advance Report</td><td>Html</td><td>Monthly</td><td>1996.8 ~2024.6</td><td>333</td><td>3,330</td><td>www.bea.gov</td></tr><tr><td>CPI Report</td><td>Html, Txt</td><td>Monthly</td><td>1994.2 ~2024.6</td><td>357</td><td>3,570</td><td>www.bls.gov</td></tr><tr><td>PPI Report</td><td>Html, Txt</td><td>Monthly</td><td>1994.2 ~2024.6</td><td>348</td><td>3,480</td><td>www.bls.gov</td></tr></table>\nTable 1: Summary of Macroeconomic and Time-Series Data Types, Characteristics and Sources"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "<table><tr><td>事件类型</td><td>数据类型</td><td>频率</td><td>期间</td><td>事件数量</td><td>反事实数量</td><td>来源</td></tr><tr><td>FOMC</td><td>Html</td><td>季度</td><td>1993.3~2024.6</td><td>255</td><td>2,550</td><td>www.federalreserve.gov</td></tr><tr><td>失业救济申请</td><td>PDF, Txt</td><td>每周</td><td>2002.10~2024.6</td><td>913</td><td>9,130</td><td>oui.dol.gov</td></tr><tr><td>就业形势报告</td><td>Html, Txt</td><td>每月</td><td>1994.2~2024.6</td><td>363</td><td>3,630</td><td>www.bls.gov</td></tr><tr><td>GDP初值报告</td><td>Html</td><td>每月</td><td>1996.8~2024.6</td><td>333</td><td>3,330</td><td>www.bea.gov</td></tr><tr><td>CPI报告</td><td>Html, Txt</td><td>每月</td><td>1994.2~2024.6</td><td>357</td><td>3,570</td><td>www.bls.gov</td></tr><tr><td>PPI报告</td><td>Html, Txt</td><td>每月</td><td>1994.2~2024.6</td><td>348</td><td>3,480</td><td>www.bls.gov</td></tr></table>\n表1：宏观经济与时间序列数据类型、特征及来源汇总"
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "ordered-list-97e19f29-04f3-4a37-90a3-d9f5b223638a",
          "type": "ordered-list",
          "items": [
            {
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Time-Series Data Summary"
                  }
                ],
                "zh": []
              }
            }
          ]
        },
        {
          "id": "paragraph-7348f623-fe37-4168-aaae-19e92ad3d5ee",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "<table><tr><td>Time Series Data</td><td>Data Types</td><td>Frequency</td><td>Range</td><td>No. of Data Points</td></tr><tr><td>SP500 (SPX)</td><td>Open, Close, High, Low</td><td>5 Min</td><td>2008.01 ~ 2024.06</td><td>331,257</td></tr><tr><td>Dow Industrial (INDU)</td><td>Open, Close, High, Low</td><td>5 Min</td><td>2012.07 ~ 2024.06</td><td>263,445</td></tr><tr><td>NASDAQ (NDX)</td><td>Open, Close, High, Low</td><td>5 Min</td><td>2008.01 ~ 2024.06</td><td>332,616</td></tr><tr><td>US Treasury Bond at 1-Month (USGG1M)</td><td>Open, Close, High, Low</td><td>5 Min</td><td>2013.01 ~ 2024.06</td><td>751,443</td></tr><tr><td>US Treasury Bond at 5-Year (USGG5YR)</td><td>Open, Close, High, Low</td><td>5 Min</td><td>2013.01 ~ 2024.06</td><td>734,773</td></tr></table>"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "<table><tr><td>时间序列数据</td><td>数据类型</td><td>频率</td><td>时间范围</td><td>数据点数量</td></tr><tr><td>标普500(SPX)</td><td>开盘价,收盘价,最高价,最低价</td><td>5分钟</td><td>2008.01~2024.06</td><td>331,257</td></tr><tr><td>道琼斯工业指数(INDU)</td><td>开盘价,收盘价,最高价,最低价</td><td>5分钟</td><td>2012.07~2024.06</td><td>263,445</td></tr><tr><td>纳斯达克(NDX)</td><td>开盘价,收盘价,最高价,最低价</td><td>5分钟</td><td>2008.01~2024.06</td><td>332,616</td></tr><tr><td>1个月期美国国债(USGG1M)</td><td>开盘价,收盘价,最高价,最低价</td><td>5分钟</td><td>2013.01~2024.06</td><td>751,443</td></tr><tr><td>5年期美国国债(USGG5YR)</td><td>开盘价,收盘价,最高价,最低价</td><td>5分钟</td><td>2013.01~2024.06</td><td>734,773</td></tr></table>"
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "figure-7a3f13a6-c987-4c75-a20a-e3220272064f",
          "type": "figure",
          "src": "/uploads/images/57bd0223-f398-4636-a9c9-b50bc4e35c79/figure-7a3f13a6-c987-4c75-a20a-e3220272064f.jpg",
          "caption": {
            "en": [],
            "zh": []
          },
          "uploadedFilename": "figure-7a3f13a6-c987-4c75-a20a-e3220272064f.jpg"
        },
        {
          "id": "paragraph-ffd700e3-4886-42df-9833-f304565ed0a9",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "(a) Causal Effect Graph"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "(a) 因果效应图"
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "figure-ddef56b7-969b-4102-b663-4a78652dd317",
          "type": "figure",
          "src": "/uploads/images/57bd0223-f398-4636-a9c9-b50bc4e35c79/figure-ddef56b7-969b-4102-b663-4a78652dd317.jpg",
          "caption": {
            "en": [
              {
                "type": "text",
                "content": "The illustration of causal relationships and counterfactual events."
              }
            ],
            "zh": []
          },
          "uploadedFilename": "figure-ddef56b7-969b-4102-b663-4a78652dd317.jpg"
        },
        {
          "id": "paragraph-165dde88-f352-4e59-b322-d92c0868b0c0",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "(b) Cause-Effect Detection with Counterfactual Events\nof financial assets, forming a causal chain denoted as  "
              },
              {
                "type": "inline-math",
                "latex": "$\\mathcal{E} \\to X \\to Y$"
              },
              {
                "type": "text",
                "content": " , as illustrated in Figure 2a.\nCounterfactual Event: A Counterfactual Event (CE) represents a modified event script in which key variables (e.g., unemployment rates, GDP values) are altered relative to the factual event, while the surrounding context remains unchanged. These events are denoted as  "
              },
              {
                "type": "inline-math",
                "latex": "$\\{\\mathcal{E}_1^*,\\mathcal{E}_2^*,\\dots,\\mathcal{E}_n^*\\}$"
              },
              {
                "type": "text",
                "content": " . CEs are utilized to train CAMEF, enabling it to identify factual cause-effect relationships, represented as  "
              },
              {
                "type": "inline-math",
                "latex": "$\\mathcal{E}\\rightarrow$"
              },
              {
                "type": "text",
                "content": " "
              },
              {
                "type": "inline-math",
                "latex": "$\\mathcal{X}\\rightarrow \\mathcal{Y}$"
              },
              {
                "type": "text",
                "content": " , as illustrated in Figure 2b."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "(b) 基于反事实事件的因果检测"
              }
            ]
          },
          "align": "left"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-05ced65d-5a2e-466b-8caf-9abccac1606f",
      "title": {
        "en": "Data Collection and Counterfactual Event Augmentation",
        "zh": "数据收集与反事实事件增强"
      },
      "content": [
        {
          "id": "heading-3c0095bc-0339-425c-953c-b0f9f577c8ca",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Data Collection and Counterfactual Event Augmentation"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "数据收集与反事实事件增强"
              }
            ]
          }
        },
        {
          "id": "paragraph-26d83d8f-d994-4e3b-a3c6-097e35284b3c",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "This section introduces the proposed dataset and the methodology for counterfactual event augmentation. The dataset includes 6 types of key macroeconomic announcements ranging from 2004 to 2024, selected through an extensive review of the financial literature, along with _high-frequency trading data. Unlike the daily-based trading data used in previous studies, this high-frequency data provides more predictive accuracy and better reflects real trading behavior in the industry."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "本节介绍所提出的数据集及反事实事件增强方法。该数据集包含2004年至2024年间的6类关键宏观经济公告，这些公告通过金融文献的广泛综述筛选得出，并辅以_高频交易数据_。与既往研究中使用的日度交易数据不同，高频数据能提供更高的预测精度，更真实地反映行业实际交易行为。"
              }
            ]
          },
          "align": "left"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-7f1a4374-509c-484e-bb92-d1d236ac4629",
      "title": {
        "en": "Dataset Acquisition",
        "zh": "数据集获取"
      },
      "content": [
        {
          "id": "heading-b8ce49a7-2c8d-4b87-9101-ef0d16a574b8",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Dataset Acquisition"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "数据集获取"
              }
            ]
          }
        },
        {
          "id": "paragraph-e87845c9-d212-49c5-bce4-cd66fc1ae6f7",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "The primary question guiding the collection of this dataset is: \"Which macroeconomic releases have the greatest impact on financial markets?\" To address this, we conducted a comprehensive review of the financial literature to identify key macroeconomic factors that influence market behavior. Several dominant factors emerged, including the FOMC Minutes [10, 17, 33, 34, 42-44, 52], along with Unemployment Insurance Claims, Employment Situation Reports, GDP Advance Releases, and the Consumer Price Index (CPI) and Producer Price Index (PPI) reports [3, 18-20, 26, 38], which serve as the textual modality data for our dataset.\nTo collect these data, we developed web crawlers to extract raw files directly from official sources, including HTML, PDF, and TXT formats. These raw files were then pre-processed and converted into a structured and unified text format, ensuring consistency and ease of subsequent analysis. Table 1 provides a summary of the data types, collection frequencies, time periods, and sources of the events included in our dataset. Further details on the data crawling and pre-processing methodologies can be found in Appendix B.\nIn addition to the textual data, studies [10, 17, 33, 34, 42-44, 52] have demonstrated that the largest market impacts are typically observed in major U.S. stock indexes and Treasury bonds. Therefore, we focused on collecting high-frequency trading time-series data at 5 minute interval for key stock indexes, including the S&P 500 (SPX), Dow Industrial (INDU), NASDAQ (NDX), as well as U.S. Treasury Bond at 1-Month (USGG1M) and Treasury Bond at 5-Year (USGG5YR)."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "指导本数据集收集的核心问题是：“哪些宏观经济信息发布对金融市场影响最大？”为此，我们系统梳理金融文献，识别影响市场行为的关键宏观经济因子。其中凸显的主要因子包括联邦公开市场委员会会议纪要[10, 17, 33, 34, 42-44, 52]，以及失业救济金申领数据、就业形势报告、GDP初值报告、消费者价格指数（CPI）和生产者价格指数（PPI）报告[3, 18-20, 26, 38]，这些构成了数据集的文本模态数据。\n\n为收集这些数据，我们开发网络爬虫直接从官方来源获取原始文件（包括HTML、PDF和TXT格式）。原始文件经预处理后转换为统一的结构化文本格式，确保数据一致性并便于后续分析。表1汇总了数据集中事件的数据类型、采集频率、时间跨度和来源。数据爬取与预处理方法的详细说明见附录B。\n\n除文本数据外，研究[10, 17, 33, 34, 42-44, 52]表明最大市场影响通常体现在美国主要股指和国债市场。因此我们重点采集了标普500指数（SPX）、道琼斯工业指数（INDU）、纳斯达克指数（NDX）等关键股指的5分钟高频交易时序数据，以及1个月期美国国债（USGG1M）和5年期美国国债（USGG5YR）。"
              }
            ]
          },
          "align": "left"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-5241ab4a-f164-4245-9a25-8cd7fb571cb3",
      "title": {
        "en": "Counterfactual Events Generation based on LLM",
        "zh": "基于大语言模型的反事实事件生成"
      },
      "content": [
        {
          "id": "heading-12c38bb4-505b-42fd-a494-f480050eda99",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Counterfactual Events Generation based on LLM"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "基于大语言模型的反事实事件生成"
              }
            ]
          }
        },
        {
          "id": "paragraph-6c3890dd-b6ca-4ea3-adab-03d7db1de25b",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "This section describes the process of counterfactual event generation, creating hypothetical scenarios from existing event scripts. The aim is to reflect a target sentiment of a given event script while maintaining logical consistency and coherence of the original script. Our goal is modifying sentiment-relevant elements (such as key facts, sentiment-indicative phrases, or numerical values) without disrupting the sentiment-neutral components of the script.\nFormally, for a given event script  "
              },
              {
                "type": "inline-math",
                "latex": "$\\mathcal{E}_i\\coloneqq \\{w_1,w_2,\\ldots ,w_m\\}$"
              },
              {
                "type": "text",
                "content": " , the objective is to produce a counterfactual version  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i^\\prime"
              },
              {
                "type": "text",
                "content": "  that embodies the desired target sentiment  "
              },
              {
                "type": "inline-math",
                "latex": "S_{i}^{\\prime}"
              },
              {
                "type": "text",
                "content": " . Conceptually, the event script can be viewed as comprising sentiment-relevant content ( "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i^{\\mathrm{sentiment}}"
              },
              {
                "type": "text",
                "content": " ) and sentiment-neutral content ( "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i^{\\mathrm{neutral}}"
              },
              {
                "type": "text",
                "content": " ), so that  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i = \\mathcal{E}_i^{\\mathrm{neutral}}\\cup \\mathcal{E}_i^{\\mathrm{sentiment}}"
              },
              {
                "type": "text",
                "content": " . Instead of explicitly decomposing the script, we guide a language model (LLM) using structured prompts to modify only the sentiment-relevant content. This ensures that neutral content remains intact or is replaced with semantically equivalent expressions. Formally:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "本节阐述反事实事件生成流程，即从既有事件脚本创建假设情景。其目标是在保持原始脚本逻辑一致性与连贯性的前提下，体现特定情感倾向。我们通过修改情感相关要素（如关键事实、情感指示短语或数值），同时保持脚本中情感中性内容不受影响。\n\n形式化地，对于给定事件脚本\\( \\mathcal{S} \\)，目标是生成体现目标情感\\( \\tau \\)的反事实版本\\( \\mathcal{S}' \\)。概念上，事件脚本可视为由情感相关内容\\( \\mathcal{S}_\\tau \\)与情感中性内容\\( \\mathcal{S}_\\perp \\)构成，即\\( \\mathcal{S} = \\mathcal{S}_\\tau \\cup \\mathcal{S}_\\perp \\)。我们通过结构化提示词引导语言模型（LLM）仅修改情感相关内容，确保中性内容保持不变或被语义等效表达替换。形式化表示为："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "math-ae00ba1c-b6d1-4229-a9e0-0365ee933909",
          "type": "math",
          "latex": "\\mathcal {E} _ {i} ^ {\\prime} = \\mathcal {E} _ {i} ^ {\\text {n e u t r a l}} \\cup f _ {\\mathrm {L L M}} \\left(\\mathcal {E} _ {i} ^ {\\text {s e n t i m e n t}} \\mid S _ {i} ^ {\\prime}\\right), \\tag {1}"
        },
        {
          "id": "paragraph-48b1069b-ebfb-4bd7-933b-e55790880d83",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where  "
              },
              {
                "type": "inline-math",
                "latex": "f_{\\mathrm{LLM}}"
              },
              {
                "type": "text",
                "content": "  adjusts  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i^{\\mathrm{sentiment}}"
              },
              {
                "type": "text",
                "content": "  to align with  "
              },
              {
                "type": "inline-math",
                "latex": "$S_i'$"
              },
              {
                "type": "text",
                "content": " , and  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}_i^{\\mathrm{neutral}}"
              },
              {
                "type": "text",
                "content": "  remains unchanged or is replaced by equivalent expressions.\nSpecifically, we used the LLaMA-3 8B model with a series of carefully designed prompts. These prompts include three key steps, with detailed templates provided in Appendix A:\n(1) Summarization Prompt (Appendix A.1): Condenses lengthy event scripts into concise summaries, addressing memory"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "\\( \\mathcal{S}' = f(\\mathcal{S}_\\tau; \\tau) \\cup g(\\mathcal{S}_\\perp) \\)\n其中\\( f(\\cdot) \\)调整\\( \\mathcal{S}_\\tau \\)以对齐\\( \\tau \\)，\\( g(\\cdot) \\)保持\\( \\mathcal{S}_\\perp \\)不变或替换为等效表达。\n\n具体采用LLaMA-3 8B模型配合精心设计的提示词流程，包含三个关键步骤（详细模板见附录A）：\n(1) 摘要提示（附录A.1）：将冗长事件脚本压缩为简洁摘要，在满足内存限制的同时保留情感相关内容和关键数值变量"
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "figure-d4388a9c-965f-43d7-b9b6-67aedd57f9df",
          "type": "figure",
          "src": "/uploads/images/57bd0223-f398-4636-a9c9-b50bc4e35c79/figure-d4388a9c-965f-43d7-b9b6-67aedd57f9df.jpg",
          "caption": {
            "en": [
              {
                "type": "text",
                "content": "The Pipeline and Neural Architecture of CAMEF"
              }
            ],
            "zh": []
          },
          "uploadedFilename": "figure-d4388a9c-965f-43d7-b9b6-67aedd57f9df.jpg"
        },
        {
          "id": "paragraph-c347b591-5dbf-43fb-b6ea-255b806ba13f",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "constraints while retaining sentiment-relevant content and key numerical variables.\n(2) Sentiment Analysis Prompt (Appendix A.2): Assigns a sentiment score (from 1, very negative, to 10, very positive) to the original event script. This score provides a baseline for generating counterfactual versions.\n(3) Counterfactual Generation Prompt (Appendix A.3): Produces multiple counterfactual scripts, each reflecting a different sentiment level. The prompt modifies sentiment-related phrases and numerical values  "
              },
              {
                "type": "inline-math",
                "latex": "(\\mathcal{E}_i^{\\text{sentiment}})"
              },
              {
                "type": "text",
                "content": "  while preserving or equivalently substituting neutral content  "
              },
              {
                "type": "inline-math",
                "latex": "(\\mathcal{E}_i^{\\text{neutral}})"
              },
              {
                "type": "text",
                "content": " . This approach ensures numerical reasonability, sentiment relevance, and structural consistency.\nThis multi-step prompt strategy facilitates the generation of coherent, contextually relevant counterfactual events, enabling exploration of diverse market scenarios and deeper causal understanding."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "(2) 情感分析提示（附录A.2）：为原始事件脚本分配情感分数（1分代表极度负面，10分代表极度正面），该分数为生成反事实版本提供基准\n(3) 反事实生成提示（附录A.3）：生成多个反事实脚本，每个体现不同情感层级。提示词在保持中性内容\\( \\mathcal{S}_\\perp \\)的同时，修改情感相关短语和数值\\( \\mathcal{S}_\\tau \\)，确保数值合理性、情感相关性与结构一致性\n\n这种多步骤提示策略能生成连贯且上下文相关的反事实事件，助力多维度市场情景探索与深层因果理解。"
              }
            ]
          },
          "align": "left"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-a6e62923-ebe4-41e8-bd41-2b6a24bb4559",
      "title": {
        "en": "CAMEF Architecture",
        "zh": "CAMEF架构"
      },
      "content": [
        {
          "id": "heading-a4fe4248-62b9-4e81-a9cc-78b03c30a4bc",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "CAMEF Architecture"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "CAMEF架构"
              }
            ]
          }
        },
        {
          "id": "paragraph-cd93c4b8-cecf-4541-93a6-2d4837548afa",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "The CAMEF model integrates both textual and time-series information through a structured architecture consisting of a textual encoder, a time-series encoder, and a forecasting decoder, as depicted in Fig. 3. Each component is detailed below."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "如图3所示，CAMEF模型通过文本编码器、时序编码器和预测解码器的结构化架构整合文本与时序信息，各组件详述如下。"
              }
            ]
          },
          "align": "left"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-0c41f832-dd92-4c98-b7eb-10426fee169a",
      "title": {
        "en": "Textual Modality Encoder (CAMEFTextual)",
        "zh": "文本模态编码器（CAMEFTextual）"
      },
      "content": [
        {
          "id": "heading-c03c61f6-abe7-44f0-861c-2327082de32d",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Textual Modality Encoder (CAMEFTextual)"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "文本模态编码器（CAMEFTextual）"
              }
            ]
          }
        },
        {
          "id": "paragraph-93a1bcc7-c8ac-4408-b4be-50ea08e6cad7",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "We encode event scripts using RoBERTa [31]. Given an input script  "
              },
              {
                "type": "inline-math",
                "latex": "$\\mathbf{E}_i = w_1, w_2, \\ldots, w_m$"
              },
              {
                "type": "text",
                "content": " , RoBERTa produces contextual token embeddings:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "我们采用RoBERTa[31]对事件脚本进行编码。给定输入脚本\\( \\mathcal{S} \\)，RoBERTa生成上下文词符嵌入："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "math-4961ae45-f981-4693-a079-2ed773965af9",
          "type": "math",
          "latex": "\\left\\{\\mathbf {h} _ {1}, \\mathbf {h} _ {2}, \\dots , \\mathbf {h} _ {m} \\right\\} = \\operatorname {R o B E R T a} \\left(\\left\\{w _ {1}, w _ {2}, \\dots , w _ {m} \\right\\}\\right), \\tag {2}"
        },
        {
          "id": "paragraph-695d10c6-e6fd-48ce-b17e-d199bc65da3f",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where  "
              },
              {
                "type": "inline-math",
                "latex": "$\\mathbf{h}_j\\in \\mathbb{R}^{1\\times 768}$"
              },
              {
                "type": "text",
                "content": "  is the embedding of token  "
              },
              {
                "type": "inline-math",
                "latex": "w_{j}"
              },
              {
                "type": "text",
                "content": " . Each embedding is passed through a projection network with three linear layers and GELU activations:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "\\( \\mathbf{H} = \\{\\mathbf{h}_1, \\mathbf{h}_2, ..., \\mathbf{h}_L\\} = \\text{RoBERTa}(\\mathcal{S}) \\)\n其中\\( \\mathbf{h}_i \\)为词符\\( i \\)的嵌入向量。每个嵌入通过包含三个线性层与GELU激活函数的投影网络："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "math-df8c483f-296c-4505-9f50-9e35e003726f",
          "type": "math",
          "latex": "\\mathbf {e} _ {j} = \\mathbf {W} ^ {(3)} \\cdot \\operatorname {G E L U} \\left(\\mathbf {W} ^ {(2)} \\cdot \\operatorname {G E L U} \\left(\\mathbf {W} ^ {(1)} \\mathbf {h} _ {j} + \\mathbf {b} ^ {(1)}\\right) + \\mathbf {b} ^ {(2)}\\right) + \\mathbf {b} ^ {(3)}, \\tag {3}"
        },
        {
          "id": "paragraph-e213134a-a698-491a-8d9f-e9b92e89be49",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where  "
              },
              {
                "type": "inline-math",
                "latex": "$\\mathbf{W}^{(1)}\\in \\mathbb{R}^{768\\times 1024},\\mathbf{W}^{(2)}\\in \\mathbb{R}^{1024\\times 1024}$"
              },
              {
                "type": "text",
                "content": "  and  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{W}^{(3)}\\in \\mathbb{R}^{1024\\times 768}"
              },
              {
                "type": "text",
                "content": " . The final encoding vector  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{E}_i"
              },
              {
                "type": "text",
                "content": "  for the script is computed as the average of the transformed embeddings,  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{E}_i = \\frac{1}{m}\\sum_{j = 1}^{m}\\mathbf{e}_j"
              },
              {
                "type": "text",
                "content": " ."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "\\( \\tilde{\\mathbf{h}}_i = \\mathbf{W}_3(\\text{GELU}(\\mathbf{W}_2(\\text{GELU}(\\mathbf{W}_1\\mathbf{h}_i + \\mathbf{b}_1)) + \\mathbf{b}_2)) + \\mathbf{b}_3 \\)\n其中\\( \\mathbf{W}_* \\)和\\( \\mathbf{b}_* \\)为可学习参数。脚本的最终编码向量通过变换后嵌入的均值计算：\\( \\mathbf{z}_{\\text{text}} = \\frac{1}{L}\\sum_{i=1}^L \\tilde{\\mathbf{h}}_i \\)"
              }
            ]
          },
          "align": "left"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-b6399d15-e7d1-4a02-b5cd-2458c1665850",
      "title": {
        "en": "Time-Series Modality Encoder (CAMEFTime-Series)",
        "zh": "时序模态编码器（CAMEFTime-Series）"
      },
      "content": [
        {
          "id": "heading-f3d10f61-4987-4a13-9539-635bb3a047df",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Time-Series Modality Encoder (CAMEFTime-Series)"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "时序模态编码器（CAMEFTime-Series）"
              }
            ]
          }
        },
        {
          "id": "paragraph-8c5ab511-d4d9-4926-b9a2-4ddba47c748d",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "To encode the time series data, we employ a pretrained time series encoder, MOMENT [21], which generates a fixed-dimensional vector for an input time series segment. Subsequently, we design a multi-residual layer to further refine the encoding vectors, as shown below:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "为编码时序数据，我们采用预训练时序编码器MOMENT[21]对输入时序片段生成固定维向量。随后设计多残差层进一步精化编码向量："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "math-54762a9c-cdcd-4bfc-804c-95ef796c7433",
          "type": "math",
          "latex": "\\mathcal {X} _ {i} = \\operatorname {M O M E N T} \\left(\\left\\{X _ {1}, X _ {2}, \\dots , X _ {n} \\right\\}\\right), \\tag {4}"
        },
        {
          "id": "paragraph-70d55d48-5a1e-494f-ba28-addd86bfe95f",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where  "
              },
              {
                "type": "inline-math",
                "latex": "$X_{i}\\in \\mathbb{R}^{d}$"
              },
              {
                "type": "text",
                "content": "  is the encoded vector for the input time series segment  "
              },
              {
                "type": "inline-math",
                "latex": "$\\{X_1,X_2,\\ldots ,X_n\\}$"
              },
              {
                "type": "text",
                "content": " , and  "
              },
              {
                "type": "inline-math",
                "latex": "$d$"
              },
              {
                "type": "text",
                "content": "  represents the dimensionality of the encoded vector. To enhance this representation, we introduce a multi-residual projection layer:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "\\( \\mathbf{e} = \\text{MOMENT}(\\mathcal{T}) \\in \\mathbb{R}^d \\)\n其中\\( \\mathbf{e} \\)为输入时序片段\\( \\mathcal{T} \\)的编码向量，\\( d \\)表示编码向量维度。为增强表征，引入多残差投影层："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "math-a29e86ee-c04c-43fc-88ba-801c010f7f9b",
          "type": "math",
          "latex": "\\mathbf {Z} _ {i} = \\mathcal {X} _ {i} + f _ {\\text {r e s i d u a l}} (\\mathcal {X} _ {i}), \\tag {5}"
        },
        {
          "id": "paragraph-f134b38f-a1f8-4432-aa5b-c27bcf972b76",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where  "
              },
              {
                "type": "inline-math",
                "latex": "f_{\\mathrm{residual}}(\\mathcal{X}_i)"
              },
              {
                "type": "text",
                "content": "  represents the transformation applied through the residual projection layer, which consists of multiple linear layers interleaved with GELU activations:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "\\( \\mathbf{z}_{\\text{ts}} = \\mathbf{e} + \\text{Proj}_{\\text{residual}}(\\mathbf{e}) \\)\n其中\\( \\text{Proj}_{\\text{residual}}(\\cdot) \\)表示通过残差投影层实施的变换，该层由多个线性层与GELU激活函数交错构成："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "math-8a7a9fca-1524-457a-affc-f89d6bbc2f97",
          "type": "math",
          "latex": "f _ {\\text {r e s i d u a l}} \\left(\\chi_ {i}\\right) = \\mathbf {W} _ {3} \\cdot \\operatorname {G E L U} \\left(\\mathbf {W} _ {2} \\cdot \\operatorname {G E L U} \\left(\\mathbf {W} _ {1} \\cdot \\chi_ {i} + \\mathbf {b} _ {1}\\right) + \\mathbf {b} _ {2}\\right) + \\mathbf {b} _ {3}, \\tag {6}"
        },
        {
          "id": "paragraph-b5777c5f-946f-4ce5-bb23-4a506437aee7",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where  "
              },
              {
                "type": "inline-math",
                "latex": "$\\mathbf{W}_1, \\mathbf{W}_2 \\in \\mathbb{R}^{1024 \\times 1024}, \\mathbf{W}_3 \\in \\mathbb{R}^{1024 \\times 768}$"
              },
              {
                "type": "text",
                "content": "  are the weight matrices, and  "
              },
              {
                "type": "inline-math",
                "latex": "$\\mathbf{b}_1, \\mathbf{b}_2 \\in \\mathbb{R}^{1024}, \\mathbf{b}_3 \\in \\mathbb{R}^{768}$"
              },
              {
                "type": "text",
                "content": "  are the respective biases. Finally,  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{Z}_i \\in \\mathbb{R}^{1024}"
              },
              {
                "type": "text",
                "content": "  serves as the refined vector for the time series segment."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "\\( \\text{Proj}_{\\text{residual}}(\\mathbf{e}) = \\mathbf{W}_k(\\cdots\\text{GELU}(\\mathbf{W}_2(\\text{GELU}(\\mathbf{W}_1\\mathbf{e} + \\mathbf{b}_1)) + \\mathbf{b}_2)\\cdots) + \\mathbf{b}_k \\)\n其中\\( \\mathbf{W}_* \\)为权重矩阵，\\( \\mathbf{b}_* \\)为对应偏置项。最终\\( \\mathbf{z}_{\\text{ts}} \\)作为精化后的时序片段向量。"
              }
            ]
          },
          "align": "left"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-89ae1253-dabf-448f-a50f-ae0f24639c33",
      "title": {
        "en": "Feature Fusion and Time Series Decoder",
        "zh": "特征融合与时序解码器"
      },
      "content": [
        {
          "id": "heading-f1054c75-ed92-4aed-9784-fe20a01b3c6d",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Feature Fusion and Time Series Decoder"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "特征融合与时序解码器"
              }
            ]
          }
        },
        {
          "id": "paragraph-40a4e3ec-5415-4d50-865d-33121fd2d6f7",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "After obtaining the encoded vectors from the textual and time series data, denoted as  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{E}_i"
              },
              {
                "type": "text",
                "content": "  and  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{Z}_i"
              },
              {
                "type": "text",
                "content": " , respectively, we concatenate them to form a unified representation:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "从文本和时间序列数据中分别获得编码向量（记为  和  ）后，我们将其拼接形成统一表征："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "math-3ee55a15-8bde-498a-9a6b-03479c742e3b",
          "type": "math",
          "latex": "\\mathbf {E} _ {\\text {c o m b i n e d}} = \\operatorname {C o n c a t} \\left(\\mathbf {E} _ {i}, \\mathbf {Z} _ {i}\\right), \\tag {7}"
        },
        {
          "id": "paragraph-f31942ae-0415-476a-a1db-93810405148e",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "which captures both semantic content from macroeconomic texts and temporal patterns from time series inputs. To fuse these modalities,  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{E}_{\\mathrm{combined}}"
              },
              {
                "type": "text",
                "content": "  is passed through a two-layer feedforward network with GELU activation:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "该表征同时捕捉了宏观经济文本的语义内容和时间序列输入的时序模式。为融合这些模态，将   输入具有GELU激活函数的双层前馈网络："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "math-05518c78-1923-4515-8534-63eaa7f7ad56",
          "type": "math",
          "latex": "\\mathbf {E} _ {\\text {f u s e d}} = \\mathbf {W} ^ {(f 2)} \\cdot \\operatorname {G E L U} \\left(\\mathbf {W} ^ {(f 1)} \\cdot \\mathbf {E} * \\text {c o m b i n e d} + \\mathbf {b} ^ {(f 1)}\\right) + \\mathbf {b} ^ {(f 2)}, \\tag {8}"
        },
        {
          "id": "paragraph-dfaa0db7-4621-49c8-8e5b-a161893bb51e",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where  "
              },
              {
                "type": "inline-math",
                "latex": "$\\mathbf{W}^{(f1)}\\in \\mathbb{R}^{(2\\times 768)\\times 1024},\\mathbf{W}^{(f2)}\\in \\mathbb{R}^{1024\\times 1024}$"
              },
              {
                "type": "text",
                "content": " , and  "
              },
              {
                "type": "inline-math",
                "latex": "$\\mathbf{b}^{(f1)},\\mathbf{b}^{(f2)}\\in \\mathbb{R}^{1024}$"
              },
              {
                "type": "text",
                "content": "  are the corresponding weight matrices and bias terms. This fusion block enables interaction across modalities and produces a refined joint embedding for downstream decoding.\nWe then employ GPT-2 [41] as the decoder to decode the fused vector by leveraging its effective auto-regressive ability:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中   、   和   为对应权重矩阵与偏置项。该融合模块支持跨模态交互，并为下游解码生成精细化联合嵌入。\n随后采用GPT-2[41]作为解码器，利用其高效自回归能力对融合向量进行解码："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "math-5ea89bc5-156e-4b2f-b4ca-80eb0a88b171",
          "type": "math",
          "latex": "\\mathbf {H} ^ {(l)} = f _ {\\mathrm {G P T 2 \\_ l a y e r}} ^ {(l)} \\left(\\mathbf {H} ^ {(l - 1)}\\right), \\tag {9}"
        },
        {
          "id": "paragraph-757bc3e6-6718-4bbd-9baa-991bb899509c",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{H}^{(0)} = \\mathbf{E}_{\\mathrm{fused}}"
              },
              {
                "type": "text",
                "content": " , and  "
              },
              {
                "type": "inline-math",
                "latex": "f_{\\mathrm{GPT2\\_layer}}^{(l)}"
              },
              {
                "type": "text",
                "content": "  represents the transformation function of the  "
              },
              {
                "type": "inline-math",
                "latex": "$l$"
              },
              {
                "type": "text",
                "content": " -th GPT-2 layer, where  "
              },
              {
                "type": "inline-math",
                "latex": "$l = 12$"
              },
              {
                "type": "text",
                "content": " . After the final layer, the output is normalized using a layer normalization function:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中   ，   表示第  层GPT-2层的变换函数（  ）。最终层输出通过层归一化函数处理："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "math-463a2f21-d51a-41c3-9ac6-98f05e21d480",
          "type": "math",
          "latex": "\\mathbf {H} _ {\\text {f i n a l}} = \\operatorname {L a y e r N o r m} \\left(\\mathbf {H} ^ {(l)}\\right), \\tag {10}"
        },
        {
          "id": "paragraph-9b7106cb-07b2-4534-9551-863d0fae19b1",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "The final output  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{H}_{\\mathrm{final}}"
              },
              {
                "type": "text",
                "content": "  is then used to generate predictions based on the combined multi-modal information."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "基于融合多模态信息的最终输出   用于生成预测结果。"
              }
            ]
          },
          "align": "left"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-bc4491be-dd63-4d4e-ace4-58cbdf06f7f5",
      "title": {
        "en": "Time-Series Forecasting Post-Regressor and Learning Objectives",
        "zh": "时序预测后置回归器与学习目标"
      },
      "content": [
        {
          "id": "heading-60e5703d-3833-47c3-a147-75a6938bef41",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Time-Series Forecasting Post-Regressor and Learning Objectives"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "时序预测后置回归器与学习目标"
              }
            ]
          }
        },
        {
          "id": "paragraph-27330f5f-977c-4af6-823c-f6c7fc9c84ea",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "We designed a Post-Regressor that applies a linear transformation to the concatenated vector  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{H}_{\\mathrm{final}}"
              },
              {
                "type": "text",
                "content": " , followed by GELU activation and a dropout layer with a rate of 0.1:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "我们设计了后置回归器，对拼接向量   进行线性变换后接GELU激活和丢弃率为0.1的Dropout层："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "math-79cf6eb3-48bd-4054-8c53-f4d677cdd151",
          "type": "math",
          "latex": "\\mathbf {R} ^ {(k)} = \\operatorname {G E L U} \\left(\\mathbf {W} ^ {(k)} \\cdot \\mathbf {R} ^ {(k - 1)} + \\mathbf {b} ^ {(k)}\\right), \\tag {11}"
        },
        {
          "id": "paragraph-ee0d3926-dceb-4c84-87d6-ead551639017",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{R}^{(0)} = \\mathbf{H}_{\\mathrm{final}}"
              },
              {
                "type": "text",
                "content": " ,  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{W}^{(k)}"
              },
              {
                "type": "text",
                "content": "  and  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{b}^{(k)}"
              },
              {
                "type": "text",
                "content": "  are the weight matrix and bias of the  "
              },
              {
                "type": "inline-math",
                "latex": "k"
              },
              {
                "type": "text",
                "content": " -th linear layer, respectively.  "
              },
              {
                "type": "inline-math",
                "latex": "$k = 4$"
              },
              {
                "type": "text",
                "content": "  is the total number of layers in the regressor. The final linear layer maps the representation to a vector of shape  "
              },
              {
                "type": "inline-math",
                "latex": "$(d \\times \\mathrm{pred\\_len})$"
              },
              {
                "type": "text",
                "content": " , where  "
              },
              {
                "type": "inline-math",
                "latex": "$d$"
              },
              {
                "type": "text",
                "content": "  is the forecast dimensionality and  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathrm{pred\\_len}"
              },
              {
                "type": "text",
                "content": "  is the number of predicted time steps:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中   、   和   分别为第  个线性层的权重矩阵与偏置，   为回归器总层数。最终线性层将表征映射为   形状的向量（   为预测维度，   为预测时间步数）："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "math-eebc1f7d-f154-4a21-958d-39271dcd0a15",
          "type": "math",
          "latex": "\\hat {\\mathbf {Y}} = \\mathbf {W} _ {\\text {o u t}} \\cdot \\mathbf {R} ^ {(K)} + \\mathbf {b} _ {\\text {o u t}}, \\tag {12}"
        },
        {
          "id": "paragraph-346d9903-f712-437b-8367-83f14a574c90",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where  "
              },
              {
                "type": "inline-math",
                "latex": "\\hat{Y}"
              },
              {
                "type": "text",
                "content": " , represents the predicted time series values.\nLearning Objectives for Time Series: We employ a combination of Mean Squared Error (MSE) loss and Mean Absolute Error (MAE) loss to optimize the model. The MSE loss minimizes the squared differences between the predicted time series values,  "
              },
              {
                "type": "inline-math",
                "latex": "\\hat{\\mathbf{Y}}"
              },
              {
                "type": "text",
                "content": " , and the ground truth values,  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{Y}"
              },
              {
                "type": "text",
                "content": " , while the MAE loss minimizes the absolute differences. These are defined as:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中   表示预测的时序数值。\n时序学习目标：采用均方误差（MSE）损失与平均绝对误差（MAE）损失的组合优化模型。MSE损失最小化预测时序值   与真实值   的平方差异，MAE损失最小化绝对差异："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "math-3f46bb3d-0adc-4ae5-b7ee-282c0e5b7b38",
          "type": "math",
          "latex": "\\mathcal {L} _ {\\mathrm {M S E}} = \\frac {1}{n} \\sum_ {i = 1} ^ {n} (\\hat {\\mathbf {Y}} _ {i} - \\mathbf {Y} _ {i}) ^ {2}, \\quad \\mathcal {L} _ {\\mathrm {M A E}} = \\frac {1}{n} \\sum_ {i = 1} ^ {n} | \\hat {\\mathbf {Y}} _ {i} - \\mathbf {Y} _ {i} |, \\tag {13}"
        },
        {
          "id": "paragraph-8ba7e624-35aa-4e39-87c7-cc0c6dcafe4b",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where  "
              },
              {
                "type": "inline-math",
                "latex": "n"
              },
              {
                "type": "text",
                "content": "  is the number of predicted values (e.g., 35, 70, or 140, as defined in Section 6.1). The total loss function combines both objectives to balance optimization for large and small errors:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中   为预测值数量（如第6.1节定义的35、70或140）。总损失函数结合两个目标以平衡大小误差的优化："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "math-358bddd6-1f80-4189-bb02-e49c90cddb3f",
          "type": "math",
          "latex": "\\mathcal {L} _ {\\text {T i m e}} = \\mathcal {L} _ {\\text {M S E}} + \\mathcal {L} _ {\\text {M A E}}. \\tag {14}"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-cc019598-962d-43eb-b2e4-6ff1f858e2b7",
      "title": {
        "en": "Counterfactual Events Sampling and Causal Learning Objective",
        "zh": "反事实事件采样与因果学习目标"
      },
      "content": [
        {
          "id": "heading-2a0fc9d3-ab3c-46fd-8693-f8bb1c09672a",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Counterfactual Events Sampling and Causal Learning Objective"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "反事实事件采样与因果学习目标"
              }
            ]
          }
        },
        {
          "id": "paragraph-e516fc1c-08c4-4522-bf00-69bda25284b7",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Causal learning enhances the robustness of the CAMEF model by enabling it to identify the correct event script among sampled counterfactual events (CEs). To achieve this, we first design a Diverse Counterfactual Event Sampling Mechanism, which generates two types of CEs. These counterfactuals, along with their corresponding time-series data, are then encoded using the textual and time-series modalities of CAMEF. This process helps the model learn causal relationships between events and their corresponding time-series movements.\n5.5.1 Diverse Counterfactual Event Sampling Mechanism. We propose a Diverse Counterfactual Event Sampling Mechanism to enhance the model's ability to both identify the ground-truth event and distinguish between different event types. This mechanism is designed with two objectives: (1) to help the model recognize the ground-truth event among similar counterfactuals of the same type, and (2) to enable the model to differentiate between events of different types.\nTo achieve these objectives, we generate two categories of counterfactual events for each factual event:\n(1) Identical Type Sampling: Counterfactual events of the same type as the ground-truth event, created by modifying sentiment-relevant components and key numerical variables, as detailed in Sec. 4.2.\n(2) Diverse Type Sampling: Counterfactual events of a different type, sampled by substituting the ground-truth event with 5 other event type occurring on the closest date.\nThis mechanism provides a diverse set of counterfactual events, collectively denoted as  "
              },
              {
                "type": "inline-math",
                "latex": "$\\mathbb{E}^{CF} \\coloneqq \\{\\mathcal{E}_1^{CF}, \\mathcal{E}_2^{CF}, \\ldots, \\mathcal{E}_{|\\mathbb{E}^{CF}|}^{CF}\\}$"
              },
              {
                "type": "text",
                "content": " , we set the total number of diverse-type samples to be 5, and the default number of identical-type samples to be 10 as introduced in Sec. 4.2.\n5.5.2 Causal Learning Objective. The causal learning process utilizes both the textual (see Sec. 5.1) and time-series (see Sec. 5.2) encoders of CAMEF to capture the relationships between events and market movements. The textual encoder is used to encode both the ground-truth event  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}^{GT}"
              },
              {
                "type": "text",
                "content": "  and the sampled CEs  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{E}^{CF}"
              },
              {
                "type": "text",
                "content": " :"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "因果学习通过使CAMEF模型能够从采样的反事实事件（CE）中识别正确事件脚本，增强其鲁棒性。为此首先设计多样化反事实事件采样机制，生成两类CE。这些反事实事件及其对应时序数据通过CAMEF的文本与时序模态编码，帮助模型学习事件与对应时序波动间的因果关系。\n5.5.1 多样化反事实事件采样机制。提出该机制以增强模型识别真实事件和区分不同事件类型的能力，其设计目标为：（1）帮助模型在同类相似反事实中识别真实事件；（2）使模型能区分不同类型事件。\n为实现这些目标，为每个事实事件生成两类反事实事件：\n（1）同类型采样：与真实事件同类型的反事实事件，通过修改情感相关成分和关键数值变量生成（详见第4.2节）；\n（2）多类型采样：不同类型的反事实事件，通过将真实事件替换为最近日期发生的5种其他事件类型进行采样。\n该机制提供多样化反事实事件集合，记为   ，设置多类型样本总数5个，同类型样本默认数量10个（如第4.2节所述）。\n5.5.2 因果学习目标。因果学习过程利用CAMEF的文本（见第5.1节）和时序（见第5.2节）编码器捕捉事件与市场波动的关系。文本编码器用于编码真实事件   和采样CE  ："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "math-282749de-e064-48b9-88b6-2a3f2c8912eb",
          "type": "math",
          "latex": "\\left\\{\\mathbf {P} ^ {G T}, \\mathbf {P} _ {1} ^ {C F}, \\dots , \\mathbf {P} _ {| \\mathbb {E} ^ {C F} |} ^ {C F} \\right\\} = \\mathbf {C A M E F} _ {\\text {T e x t u a l}} \\left(\\left\\{\\mathcal {E} ^ {G T} \\right\\} \\cup \\left\\{\\mathcal {E} _ {i} ^ {C F} \\right\\} _ {i = 1} ^ {| \\mathbb {E} ^ {C F} |}\\right), \\tag {15}"
        },
        {
          "id": "paragraph-8c96127e-153f-479c-899e-a160897fdb47",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{P}^{GT}"
              },
              {
                "type": "text",
                "content": "  represents the embedding of the ground-truth event, and  "
              },
              {
                "type": "inline-math",
                "latex": "$\\{\\mathbf{P}_i^{CF}\\}_{i=1}^{\\|\\mathbb{E}^{CF}\\|}$"
              },
              {
                "type": "text",
                "content": "  represents the embeddings of the sampled counterfactual events.\nThe time-series encoder is used to encode the historical time-series segment  "
              },
              {
                "type": "inline-math",
                "latex": "$X$"
              },
              {
                "type": "text",
                "content": "  aligned with the ground-truth event, resulting in the time-series embedding:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中   表示真实事件嵌入，   表示采样反事实事件嵌入。\n时序编码器用于编码与真实事件对齐的历史时序片段  ，得到时序嵌入："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "math-9edf5f48-f5f4-49ce-b189-ad46f32e45a8",
          "type": "math",
          "latex": "\\mathbf {T} = \\mathbf {C A M E F} _ {\\text {T i m e - S e r i e s}} (\\mathcal {X}). \\tag {16}"
        },
        {
          "id": "paragraph-0bffb713-c5c6-4d53-848e-c7b92a7d88a4",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Triplet Loss: The triplet loss is applied to enforce that the ground-truth event embedding  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{P}^{GT}"
              },
              {
                "type": "text",
                "content": "  is closer to the time-series embedding  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{T}"
              },
              {
                "type": "text",
                "content": "  than any counterfactual event embedding  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathbf{P}_i^{CF}"
              },
              {
                "type": "text",
                "content": " , by a margin  "
              },
              {
                "type": "inline-math",
                "latex": "\\alpha"
              },
              {
                "type": "text",
                "content": "  (set to 1.0):\nTable 2: Financial Forecasting Results (MSE and MAE Scores) for CAMEF and Baselines Across Various Financial Assets: S&P500 (SPX), Dow Industrials (INDU), Nasdaq100 (NDX) Index, US 1-Month Treasury Bond (USGG1M), and US 5-Year Treasury Bond (USGG5YR).\n<table><tr><td rowspan=\"2\">Model / Datasets</td><td rowspan=\"2\">Forecasting Length</td><td colspan=\"2\">SP500 (SPX)</td><td colspan=\"2\">Dow Industrial (INDU)</td><td colspan=\"2\">NASDAQ (NDX)</td><td colspan=\"2\">USGG1M</td><td colspan=\"2\">USGG5YR</td></tr><tr><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td></tr><tr><td rowspan=\"3\">ARIMA</td><td>35</td><td>0.0032628</td><td>0.0308016</td><td>0.0121513</td><td>0.0523810</td><td>0.0065253</td><td>0.0435694</td><td>0.0072223</td><td>0.0262512</td><td>0.0038973</td><td>0.0340227</td></tr><tr><td>70</td><td>0.0035361</td><td>0.0352004</td><td>0.0139245</td><td>0.0656002</td><td>0.0082324</td><td>0.0520933</td><td>0.0028710</td><td>0.0304132</td><td>0.0039441</td><td>0.0366630</td></tr><tr><td>140</td><td>0.0051080</td><td>0.0439935</td><td>0.0219147</td><td>0.0793471</td><td>0.0118692</td><td>0.0665155</td><td>0.0089949</td><td>0.0338275</td><td>0.0050746</td><td>0.0455617</td></tr><tr><td rowspan=\"3\">DLinear</td><td>35</td><td>0.0144331</td><td>0.0896910</td><td>0.0395136</td><td>0.1380539</td><td>0.0183989</td><td>0.0999178</td><td>0.0108576</td><td>0.0706170</td><td>0.0147211</td><td>0.0876379</td></tr><tr><td>70</td><td>0.0120578</td><td>0.0817373</td><td>0.0406573</td><td>0.1282699</td><td>0.0189431</td><td>0.0972439</td><td>0.0093591</td><td>0.0678380</td><td>0.0146430</td><td>0.0881574</td></tr><tr><td>140</td><td>0.0178138</td><td>0.0931039</td><td>0.0747210</td><td>0.1724027</td><td>0.0344153</td><td>0.1287803</td><td>0.0101465</td><td>0.0645396</td><td>0.0179185</td><td>0.0977673</td></tr><tr><td rowspan=\"3\">Autoformer</td><td>35</td><td>0.0068136</td><td>0.0540556</td><td>0.0277636</td><td>0.0975948</td><td>0.0135249</td><td>0.0796486</td><td>0.0047505</td><td>0.0388076</td><td>0.0092717</td><td>0.0622862</td></tr><tr><td>70</td><td>0.0088997</td><td>0.0628341</td><td>0.0375279</td><td>0.1185710</td><td>0.0185264</td><td>0.0933398</td><td>0.0065554</td><td>0.0471531</td><td>0.0113750</td><td>0.0727373</td></tr><tr><td>140</td><td>0.0158248</td><td>0.0829188</td><td>0.0772580</td><td>0.1640365</td><td>0.0334504</td><td>0.1262163</td><td>0.0086212</td><td>0.0533337</td><td>0.0152298</td><td>0.0875821</td></tr><tr><td rowspan=\"3\">FEDformer</td><td>35</td><td>0.0072377</td><td>0.0576221</td><td>0.0304808</td><td>0.1044447</td><td>0.0128668</td><td>0.0758742</td><td>0.0063596</td><td>0.0519141</td><td>0.0094995</td><td>0.0494306</td></tr><tr><td>70</td><td>0.0088056</td><td>0.0621386</td><td>0.0399824</td><td>0.1229772</td><td>0.0171008</td><td>0.0889995</td><td>0.0062841</td><td>0.0448822</td><td>0.0099615</td><td>0.0664197</td></tr><tr><td>140</td><td>0.0157429</td><td>0.0819469</td><td>0.0786426</td><td>0.1677705</td><td>0.0313433</td><td>0.1214097</td><td>0.0083784</td><td>0.0518365</td><td>0.0131231</td><td>0.0782861</td></tr><tr><td rowspan=\"3\">iTransformer</td><td>35</td><td>0.0064209</td><td>0.0516341</td><td>0.0270860</td><td>0.0927605</td><td>0.0125008</td><td>0.0751656</td><td>0.0011000</td><td>0.0155975</td><td>0.0056660</td><td>0.0183524</td></tr><tr><td>70</td><td>0.0069612</td><td>0.0540920</td><td>0.0304566</td><td>0.1038424</td><td>0.0151214</td><td>0.0816262</td><td>0.0021811</td><td>0.0221315</td><td>0.0011721</td><td>0.0226975</td></tr><tr><td>140</td><td>0.0128021</td><td>0.0718771</td><td>0.0680991</td><td>0.1486782</td><td>0.0254479</td><td>0.1047119</td><td>0.0052255</td><td>0.0327429</td><td>0.0017441</td><td>0.0282537</td></tr><tr><td rowspan=\"3\">PatchTST</td><td>35</td><td>0.0063304</td><td>0.0507462</td><td>0.0293131</td><td>0.0989455</td><td>0.0122679</td><td>0.0764552</td><td>0.0012060</td><td>0.0163610</td><td>0.0063078</td><td>0.0520734</td></tr><tr><td>70</td><td>0.0072471</td><td>0.0547738</td><td>0.0339444</td><td>0.1116023</td><td>0.0153753</td><td>0.0824677</td><td>0.0021643</td><td>0.0223036</td><td>0.0079617</td><td>0.0606007</td></tr><tr><td>140</td><td>0.0130219</td><td>0.0712171</td><td>0.0688582</td><td>0.1452592</td><td>0.0256001</td><td>0.1047749</td><td>0.0054544</td><td>0.0341517</td><td>0.0118553</td><td>0.0747537</td></tr><tr><td rowspan=\"3\">GPT4MTS</td><td>35</td><td>0.00795088</td><td>0.0674255</td><td>0.0026558</td><td>0.0417553</td><td>0.0011035</td><td>0.0240469</td><td>0.0017016</td><td>0.0309320</td><td>0.0028713</td><td>0.0389277</td></tr><tr><td>70</td><td>0.00171038</td><td>0.0305950</td><td>0.0027033</td><td>0.0393112</td><td>0.0016205</td><td>0.0336116</td><td>0.0019098</td><td>0.0279222</td><td>0.0023371</td><td>0.0354777</td></tr><tr><td>140</td><td>0.00212612</td><td>0.0330497</td><td>0.0045029</td><td>0.0458267</td><td>0.0025175</td><td>0.0341671</td><td>0.0013648</td><td>0.0260887</td><td>0.0037004</td><td>0.0449272</td></tr><tr><td rowspan=\"3\">TEST</td><td>35</td><td>0.00073333</td><td>0.0199733</td><td>0.0026572</td><td>0.0296887</td><td>0.0006593</td><td>0.0194091</td><td>0.0003252</td><td>0.0137511</td><td>0.0013633</td><td>0.0265036</td></tr><tr><td>70</td><td>0.00078762</td><td>0.0205412</td><td>0.0088903</td><td>0.0599179</td><td>0.0010678</td><td>0.0248594</td><td>0.0010515</td><td>0.0182706</td><td>0.0034630</td><td>0.0415002</td></tr><tr><td>140</td><td>0.00278572</td><td>0.0467150</td><td>0.0070749</td><td>0.0557744</td><td>0.0020130</td><td>0.0362325</td><td>0.0006995</td><td>0.0207850</td><td>0.0024356</td><td>0.0375164</td></tr><tr><td rowspan=\"3\">CAMEF</td><td>35</td><td>0.00048860</td><td>0.0154050</td><td>0.0025349</td><td>0.0366245</td><td>0.0005468</td><td>0.0178845</td><td>0.0002883</td><td>0.0118010</td><td>0.0013234</td><td>0.0260618</td></tr><tr><td>70</td><td>0.00064780</td><td>0.0178691</td><td>0.0025042</td><td>0.0365500</td><td>0.0005814</td><td>0.0162882</td><td>0.0004402</td><td>0.0139699</td><td>0.0020701</td><td>0.0326371</td></tr><tr><td>140</td><td>0.0010756</td><td>0.0210284</td><td>0.0039313</td><td>0.0383459</td><td>0.0010159</td><td>0.0207716</td><td>0.0004938</td><td>0.0148485</td><td>0.0022458</td><td>0.0336680</td></tr></table>"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "三元组损失：应用三元组损失强制真实事件嵌入   与时序嵌入   的距离比任何反事实事件嵌入   近一个边界值  （设为1.0）：\n表2：CAMEF与基线模型在多种金融资产上的预测结果（MSE与MAE分数）：标普500（SPX）、道琼斯工业指数（INDU）、纳斯达克100（NDX）指数、美国1个月期国债（USGG1M）和5年期国债（USGG5YR）。"
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "math-0a4fc141-b16c-4cb9-b944-d56e664f3ef3",
          "type": "math",
          "latex": "\\mathcal {L} _ {\\text {C a u s a l - T L}} = \\max  \\left(0, d \\left(\\mathbf {P} ^ {G T}, \\mathbf {T}\\right) - d \\left(\\mathbf {P} _ {i} ^ {C F}, \\mathbf {T}\\right) + \\alpha\\right), \\tag {17}"
        },
        {
          "id": "paragraph-915b7429-2fef-43a5-8880-2c6f77739b12",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where  "
              },
              {
                "type": "inline-math",
                "latex": "$d(\\cdot, \\cdot)$"
              },
              {
                "type": "text",
                "content": "  denotes the distance between two embeddings (e.g., cosine similarity or Euclidean distance). This loss function encourages the model to capture the causal relationships between events and time-series movements by penalizing counterfactual events that deviate from the causal signal of the ground-truth event.\nThe combination of diverse counterfactual sampling and causal learning ensures that CAMEF effectively learns the true causal drivers of financial market movements, improving its robustness and predictive power.\nTotal Loss: The overall training loss for CAMEF is defined as:"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中   表示两个嵌入间的距离（如余弦相似度或欧氏距离）。该损失函数通过惩罚偏离真实事件因果信号的反事实事件，促使模型捕捉事件与时序波动间的因果关系。\n多样化反事实采样与因果学习的结合确保CAMEF有效学习金融市场波动的真实因果驱动因素，提升其鲁棒性与预测能力。\n总损失：CAMEF的整体训练损失定义为："
              }
            ]
          },
          "align": "left"
        },
        {
          "id": "math-68b847a1-03db-4f9d-b09d-552bbebc97ca",
          "type": "math",
          "latex": "\\mathcal {L} _ {\\text {T o t a l}} = \\mathcal {L} _ {\\text {T i m e}} + \\mathcal {L} _ {\\text {C a u s a l - T L}}, \\tag {18}"
        },
        {
          "id": "paragraph-3e1f1c62-f225-4a71-82e1-ec81f08fcd66",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "where  "
              },
              {
                "type": "inline-math",
                "latex": "\\mathcal{L}_{\\mathrm{Time}}"
              },
              {
                "type": "text",
                "content": "  is the objective for time series forecasting, as defined in Equation 14."
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "其中   为时序预测目标（定义见公式14）。"
              }
            ]
          },
          "align": "left"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-13da957d-79f3-4f10-8d2a-d7cb690732e8",
      "title": {
        "en": "Experiments",
        "zh": "实验"
      },
      "content": [
        {
          "id": "heading-f1c958dd-6271-470a-9b08-d2a3a5bbf054",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Experiments"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "实验"
              }
            ]
          }
        },
        {
          "id": "paragraph-c2c2c290-bdb4-4b12-8786-523d014ff300",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "In this section, we evaluate CAMEF by addressing the following key questions: RQ1. Accuracy: How accurately does CAMEF forecast final market based on events? RQ2. Model Effectiveness: How do different components enhance CAMEF's predictive performance? RQ3. Event Analysis: Which types of events exhibit stronger influences to financial market?"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "本节通过以下关键问题评估CAMEF：RQ1. 准确性：CAMEF基于事件预测最终市场的准确度如何？RQ2. 模型有效性：各组件如何增强CAMEF的预测性能？RQ3. 事件分析：哪些事件类型对金融市场影响更强？"
              }
            ]
          },
          "align": "left"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-bd4c444f-d1ff-4a4b-87d9-33e9dd61cff4",
      "title": {
        "en": "Experimental Settings",
        "zh": "实验设置"
      },
      "content": [
        {
          "id": "heading-64a2b50a-19cc-46cb-bee2-5ffa44436686",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Experimental Settings"
              }
            ],
            "zh": [
              {
                "type": "text",
                "content": "实验设置"
              }
            ]
          }
        }
      ],
      "subsections": [
        {
          "id": "section-a9846cd2-8a27-496a-883f-c5a3ba9f9a9f",
          "title": {
            "en": "Datasets. We utilized the collected event scripts and time-series data as outlined in Sec. 4 and detailed in Appendix B. The dataset was divided into training, validation, and testing sets in a 6:2:2 ratio. The training set was used to train the models, while the validation set was used for convergence checking and early stopping to prevent overfitting. The final results, based on the test set, are reported in Table 2.",
            "zh": "数据集：使用第4节所述并在附录B详述的事件脚本与时序数据。数据集按6:2:2比例划分为训练集、验证集和测试集。训练集用于模型训练，验证集用于收敛检测和早停以防止过拟合。基于测试集的最终结果报告于表2。"
          },
          "content": [
            {
              "id": "heading-20544bd5-145a-462f-b686-daf6f64754b3",
              "type": "heading",
              "level": 3,
              "content": {
                "en": [
                  {
                    "type": "text",
                    "content": "Datasets. We utilized the collected event scripts and time-series data as outlined in Sec. 4 and detailed in Appendix B. The dataset was divided into training, validation, and testing sets in a 6:2:2 ratio. The training set was used to train the models, while the validation set was used for convergence checking and early stopping to prevent overfitting. The final results, based on the test set, are reported in Table 2."
                  }
                ],
                "zh": [
                  {
                    "type": "text",
                    "content": "数据集：使用第4节所述并在附录B详述的事件脚本与时序数据。数据集按6:2:2比例划分为训练集、验证集和测试集。训练集用于模型训练，验证集用于收敛检测和早停以防止过拟合。基于测试集的最终结果报告于表2。"
                  }
                ]
              }
            }
          ],
          "subsections": [
            {
              "id": "section-879a1d33-0bfb-4cb9-8f66-14959ef9f906",
              "title": {
                "en": "Baselines. To evaluate our proposed method, we compare it against both uni-modal and multi-modal time series forecasting approaches. For the uni-modal baselines, we considered the traditional yet robust ARIMA model [6], the linear neural model DLlinear [59], and several state-of-the-art transformer-based time-series models, including AutoFormer [8], FEDformer [61], and iTransformer [30]. For the multi-modal baselines, we included TEST [51] and GPT4MTS [24].",
                "zh": "基准方法。为评估我们提出的方法，我们将其与单模态和多模态时间序列预测方法进行比较。单模态基准方法包括传统而稳健的ARIMA模型[6]、线性神经网络模型DLinear[59]，以及若干基于Transformer的先进时序模型，如AutoFormer[8]、FEDformer[61]和iTransformer[30]。多模态基准方法则包含TEST[51]和GPT4MTS[24]。\n\n测试设置。我们在短期、中期和长期三个时间跨度上评估基准方法与CAMEF，以模拟真实投资行为。对于第3节定义的每个对齐事件与时序数据对，我们使用事件脚本和事件时间点前的时序片段（即）来预测未来时序片段。的值根据时间跨度调整：短期、中期和长期预测分别设为35、70和140，对应175分钟（约半个交易日）、350分钟（约一个交易日）和700分钟（约两个交易日）。\n\n表3：在35、70和140预测长度下评估CAMEF模型组件的消融研究结果（MSE）。\n（表格内容保持原样）\n\n表4：标普500指数上不同类型事件的消融研究结果。\n（表格内容保持原样）\n\n6.1.4 实现概述。对于单模态方法（ARIMA、DLinear、AutoFormer、FEDformer、iTransformer和PatchTST），我们测试了两种方式：(1) 在连续历史时序数据上训练模型，并在测试集的对齐事件时序片段上测试；(2) 直接在事件时序片段上训练模型，并在测试集的同类片段上测试。第二种方法结果更准确，本文展示的即为这些结果。具体而言，对于每个对齐事件数据对，单模态方法仅使用事件前的时序片段训练模型并预测后续片段；测试采用相同方式。各模型详细设置见附录C。\n对于多模态方法（GPT4MTS、TEST和CAMEF），事件脚本和事件前的时序片段均作为输入，训练模型以预测事件后时序片段。实现细节（包括模型配置和训练设置）在附录C中说明。\n\n事件驱动时序预测的实验结果（研究问题1）\n\n表2展示了五个数据集在短、中、长期预测跨度上的结果。CAMEF在30项设置中的24项领先，获得首位排名，其余6项位列第二。具体而言，除INDU的短期预测外，CAMEF在股票市场指数（SPX、INDU和NDX）的所有预测长度上均表现最佳，突显其在事件驱动股市预测中的有效性。对于国债，CAMEF在1个月期国债（USGG1M）的所有预测长度上取得最佳结果，在5年期国债（USGG5YR）上排名第二。USGG5YR上稍弱的性能表明长期国债可能对事件驱动因素较不敏感，更受历史趋势影响。\n与单模态模型（如DLinear、Autoformer、FEDformer、PatchTST和iTransformer）相比，CAMEF相对于最佳单模态模型iTransformer平均MSE降低。在多模态模型中，CAMEF超越次优模型TEST，平均MSE降低。\n这些结果凸显三个关键点：(1) 有效利用多模态信息带来显著性能提升，尤其对SPX、INDU、NDX和USGG1M；(2) 基于Transformer的方法持续优于ARIMA等经典模型；(3) CAMEF的优越训练和特征融合策略使其成为事件驱动金融预测任务中最有效的方法。\n\n模型组件的消融研究（研究问题2）\n\n为评估CAMEF各组件的有效性，我们对文本模态、因果学习、特征融合、GPT2解码器和后回归器进行全面消融研究。基于完整CAMEF模型，我们移除相应神经层（如文本模态的RoBERTa编码器或因果学习组件）以评估其单独贡献。消融结果见表3，表格左侧用或标明测试中是否包含特定组件。结果有三点关键发现：(1) 完整CAMEF模型在所有数据集上表现最佳，证明同时利用文本和时序模态至关重要；(2) 因果学习带来增量改进，确认其在捕捉数据因果关系中的价值；(3) 提出的特征融合层和GPT2解码器有效整合并利用多模态特征，显著增强模型解码时序数据的能力。这些发现强调了各组件在实现事件驱动金融预测任务最优性能中的必要性。\n\n不同类型事件的消融研究（研究问题3）\n\n表4显示了不同事件对标普500指数的预测性能。FOMC会议纪要取得最低MSE和MAE，证实其对市场预测的关键重要性。失业救济金申请和就业形势报告的误差也低于全事件选择，但后者在长期预测中效果减弱。相比之下，CPI和PPI报告预测能力较弱，PPI误差最高，CPI在长期预测中略有改善。这些结果强调了FOMC和失业相关事件对金融预测的重要性。\n\n(a) 反事实样本量的影响  \n(b) 后回归器深度（k）的影响\n\n参数敏感性分析\n\n我们在SPX数据集上以35预测长度检验CAMEF两个关键超参数的影响：反事实样本数和后回归器网络深度。GPT-2层数固定，因我们采用未修改的预训练模型。如图4所示，增加通过更强对比监督提升预测精度，性能增益在附近饱和。类似地，增加提升解码能力，但超过后收益递减。这些趋势表明CAMEF在多种配置下均表现稳健，受益于适度的复杂度增加而无过拟合。\n\n结论与未来工作\n\n本文提出CAMEF，一种用于事件驱动金融预测的多模态模型，整合了有效的因果学习和基于LLM的反事实事件增强策略。伴随模型，我们引入了一个新颖合成数据集，包含6类重要宏观经济事件脚本、其反事实样本及5种关键金融资产的高频时序数据，与真实投资实践对齐。大量实验证明CAMEF相较于先前深度时序和多模态方法具有优越预测性能。消融研究验证了因果学习及CAMEF其他设计组件的重要性。此外，发现FOMC和失业相关事件在测试事件类型中提供最高预测价值。\n未来工作中，我们计划利用先进LLM增强文本编码以提取更深语义信息，改进跨模态因果推理机制，并扩展数据集以包含更多事件类型，如政治事件和公司市场敏感新闻。\n\n致谢\n\n本工作部分得到国家自然科学基金（项目号：62402396和72471197）资助。感谢匿名评审的宝贵意见和建议，帮助提升了本文质量。"
              },
              "content": [
                {
                  "id": "heading-e57702f0-27b5-4114-851f-a3e3676aa097",
                  "type": "heading",
                  "level": 3,
                  "content": {
                    "en": [
                      {
                        "type": "text",
                        "content": "Baselines. To evaluate our proposed method, we compare it against both uni-modal and multi-modal time series forecasting approaches. For the uni-modal baselines, we considered the traditional yet robust ARIMA model [6], the linear neural model DLlinear [59], and several state-of-the-art transformer-based time-series models, including AutoFormer [8], FEDformer [61], and iTransformer [30]. For the multi-modal baselines, we included TEST [51] and GPT4MTS [24]."
                      }
                    ],
                    "zh": [
                      {
                        "type": "text",
                        "content": "基准方法。为评估我们提出的方法，我们将其与单模态和多模态时间序列预测方法进行比较。单模态基准方法包括传统而稳健的ARIMA模型[6]、线性神经网络模型DLinear[59]，以及若干基于Transformer的先进时序模型，如AutoFormer[8]、FEDformer[61]和iTransformer[30]。多模态基准方法则包含TEST[51]和GPT4MTS[24]。\n\n测试设置。我们在短期、中期和长期三个时间跨度上评估基准方法与CAMEF，以模拟真实投资行为。对于第3节定义的每个对齐事件与时序数据对，我们使用事件脚本和事件时间点前的时序片段（即）来预测未来时序片段。的值根据时间跨度调整：短期、中期和长期预测分别设为35、70和140，对应175分钟（约半个交易日）、350分钟（约一个交易日）和700分钟（约两个交易日）。\n\n表3：在35、70和140预测长度下评估CAMEF模型组件的消融研究结果（MSE）。\n（表格内容保持原样）\n\n表4：标普500指数上不同类型事件的消融研究结果。\n（表格内容保持原样）\n\n6.1.4 实现概述。对于单模态方法（ARIMA、DLinear、AutoFormer、FEDformer、iTransformer和PatchTST），我们测试了两种方式：(1) 在连续历史时序数据上训练模型，并在测试集的对齐事件时序片段上测试；(2) 直接在事件时序片段上训练模型，并在测试集的同类片段上测试。第二种方法结果更准确，本文展示的即为这些结果。具体而言，对于每个对齐事件数据对，单模态方法仅使用事件前的时序片段训练模型并预测后续片段；测试采用相同方式。各模型详细设置见附录C。\n对于多模态方法（GPT4MTS、TEST和CAMEF），事件脚本和事件前的时序片段均作为输入，训练模型以预测事件后时序片段。实现细节（包括模型配置和训练设置）在附录C中说明。\n\n事件驱动时序预测的实验结果（研究问题1）\n\n表2展示了五个数据集在短、中、长期预测跨度上的结果。CAMEF在30项设置中的24项领先，获得首位排名，其余6项位列第二。具体而言，除INDU的短期预测外，CAMEF在股票市场指数（SPX、INDU和NDX）的所有预测长度上均表现最佳，突显其在事件驱动股市预测中的有效性。对于国债，CAMEF在1个月期国债（USGG1M）的所有预测长度上取得最佳结果，在5年期国债（USGG5YR）上排名第二。USGG5YR上稍弱的性能表明长期国债可能对事件驱动因素较不敏感，更受历史趋势影响。\n与单模态模型（如DLinear、Autoformer、FEDformer、PatchTST和iTransformer）相比，CAMEF相对于最佳单模态模型iTransformer平均MSE降低。在多模态模型中，CAMEF超越次优模型TEST，平均MSE降低。\n这些结果凸显三个关键点：(1) 有效利用多模态信息带来显著性能提升，尤其对SPX、INDU、NDX和USGG1M；(2) 基于Transformer的方法持续优于ARIMA等经典模型；(3) CAMEF的优越训练和特征融合策略使其成为事件驱动金融预测任务中最有效的方法。\n\n模型组件的消融研究（研究问题2）\n\n为评估CAMEF各组件的有效性，我们对文本模态、因果学习、特征融合、GPT2解码器和后回归器进行全面消融研究。基于完整CAMEF模型，我们移除相应神经层（如文本模态的RoBERTa编码器或因果学习组件）以评估其单独贡献。消融结果见表3，表格左侧用或标明测试中是否包含特定组件。结果有三点关键发现：(1) 完整CAMEF模型在所有数据集上表现最佳，证明同时利用文本和时序模态至关重要；(2) 因果学习带来增量改进，确认其在捕捉数据因果关系中的价值；(3) 提出的特征融合层和GPT2解码器有效整合并利用多模态特征，显著增强模型解码时序数据的能力。这些发现强调了各组件在实现事件驱动金融预测任务最优性能中的必要性。\n\n不同类型事件的消融研究（研究问题3）\n\n表4显示了不同事件对标普500指数的预测性能。FOMC会议纪要取得最低MSE和MAE，证实其对市场预测的关键重要性。失业救济金申请和就业形势报告的误差也低于全事件选择，但后者在长期预测中效果减弱。相比之下，CPI和PPI报告预测能力较弱，PPI误差最高，CPI在长期预测中略有改善。这些结果强调了FOMC和失业相关事件对金融预测的重要性。\n\n(a) 反事实样本量的影响  \n(b) 后回归器深度（k）的影响\n\n参数敏感性分析\n\n我们在SPX数据集上以35预测长度检验CAMEF两个关键超参数的影响：反事实样本数和后回归器网络深度。GPT-2层数固定，因我们采用未修改的预训练模型。如图4所示，增加通过更强对比监督提升预测精度，性能增益在附近饱和。类似地，增加提升解码能力，但超过后收益递减。这些趋势表明CAMEF在多种配置下均表现稳健，受益于适度的复杂度增加而无过拟合。\n\n结论与未来工作\n\n本文提出CAMEF，一种用于事件驱动金融预测的多模态模型，整合了有效的因果学习和基于LLM的反事实事件增强策略。伴随模型，我们引入了一个新颖合成数据集，包含6类重要宏观经济事件脚本、其反事实样本及5种关键金融资产的高频时序数据，与真实投资实践对齐。大量实验证明CAMEF相较于先前深度时序和多模态方法具有优越预测性能。消融研究验证了因果学习及CAMEF其他设计组件的重要性。此外，发现FOMC和失业相关事件在测试事件类型中提供最高预测价值。\n未来工作中，我们计划利用先进LLM增强文本编码以提取更深语义信息，改进跨模态因果推理机制，并扩展数据集以包含更多事件类型，如政治事件和公司市场敏感新闻。\n\n致谢\n\n本工作部分得到国家自然科学基金（项目号：62402396和72471197）资助。感谢匿名评审的宝贵意见和建议，帮助提升了本文质量。"
                      }
                    ]
                  }
                }
              ],
              "subsections": []
            },
            {
              "id": "section-16283236-b6a5-4f09-be52-08ec1111cb13",
              "title": {
                "en": "Test Settings. We evaluate the baselines and CAMEF across three time horizons—short, medium, and long run, to simulate real investment behavior. For each aligned pair of event and time-series data    as defined in Sec. 3, we use the event script    and the time-series segment preceding the event time point   , i.e.,   , to forecast the future time-series segment   . The value of    is adjusted based on the time horizon: we set    to 35, 70, and 140 for short, medium, and long-term forecasts, respectively. These correspond to 175 minutes (about half a trading day), 350 minutes (about one trading day), and 700 minutes (about two trading days).",
                "zh": ""
              },
              "content": [
                {
                  "id": "heading-56b19def-7e8c-4b6f-bf5c-92ed5f00cfb2",
                  "type": "heading",
                  "level": 3,
                  "content": {
                    "en": [
                      {
                        "type": "text",
                        "content": "Test Settings. We evaluate the baselines and CAMEF across three time horizons—short, medium, and long run, to simulate real investment behavior. For each aligned pair of event and time-series data    as defined in Sec. 3, we use the event script    and the time-series segment preceding the event time point   , i.e.,   , to forecast the future time-series segment   . The value of    is adjusted based on the time horizon: we set    to 35, 70, and 140 for short, medium, and long-term forecasts, respectively. These correspond to 175 minutes (about half a trading day), 350 minutes (about one trading day), and 700 minutes (about two trading days)."
                      }
                    ],
                    "zh": []
                  }
                },
                {
                  "id": "paragraph-e721109c-c853-4831-ad4f-9215222fcf2c",
                  "type": "paragraph",
                  "content": {
                    "en": [
                      {
                        "type": "text",
                        "content": "Table 3: Ablation Study Results (MSE) Evaluating the CAMEF Model Components at Forecasting Lengths of 35, 70, and 140.\n<table><tr><td rowspan=\"2\" colspan=\"2\">Textual Causal</td><td rowspan=\"2\" colspan=\"3\">Feature GPT2 Fusion Decoder Regression</td><td colspan=\"3\">SPX</td><td colspan=\"3\">INDU</td><td colspan=\"3\">NDX</td><td colspan=\"3\">USGG1M</td><td colspan=\"3\">USGG5YR</td><td colspan=\"3\">AVERAGE</td></tr><tr><td>35</td><td>70</td><td>140</td><td>35</td><td>70</td><td>140</td><td>35</td><td>70</td><td>140</td><td>35</td><td>70</td><td>140</td><td>35</td><td>70</td><td>140</td><td>35</td><td>70</td><td>140</td></tr><tr><td>X</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>0.00074</td><td>0.00340</td><td>0.00120</td><td>0.00340</td><td>0.00330</td><td>0.01033</td><td>0.00131</td><td>0.00097</td><td>0.00197</td><td>0.00080</td><td>0.00179</td><td>0.00092</td><td>0.00222</td><td>0.00276</td><td>0.00380</td><td>0.00169</td><td>0.00199</td><td>0.00364</td></tr><tr><td>✓</td><td>X</td><td>✓</td><td>✓</td><td>✓</td><td>0.00068</td><td>0.00095</td><td>0.00106</td><td>0.02939</td><td>0.00281</td><td>0.00533</td><td>0.00064</td><td>0.00073</td><td>0.00121</td><td>0.00065</td><td>0.00083</td><td>0.00099</td><td>0.00160</td><td>0.00220</td><td>0.00308</td><td>0.00659</td><td>0.00170</td><td>0.00233</td></tr><tr><td>✓</td><td>✓</td><td>X</td><td>✓</td><td>✓</td><td>0.00080</td><td>0.00079</td><td>0.00110</td><td>0.01173</td><td>0.00391</td><td>0.00581</td><td>0.00069</td><td>0.00073</td><td>0.00168</td><td>0.00047</td><td>0.00046</td><td>0.00216</td><td>0.00251</td><td>0.00306</td><td>0.00426</td><td>0.00324</td><td>0.00212</td><td>0.00300</td></tr><tr><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>X</td><td>0.00073</td><td>0.00067</td><td>0.00114</td><td>0.26768</td><td>0.72387</td><td>0.18091</td><td>0.00062</td><td>0.00069</td><td>0.00158</td><td>0.00043</td><td>0.02110</td><td>0.75057</td><td>0.00220</td><td>0.00309</td><td>0.00566</td><td>0.05433</td><td>0.14593</td><td>0.03801</td></tr><tr><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>X</td><td>0.00662</td><td>0.03911</td><td>0.00979</td><td>0.50841</td><td>0.57007</td><td>0.22267</td><td>0.00774</td><td>0.00852</td><td>0.00950</td><td>0.28932</td><td>0.02110</td><td>0.75057</td><td>0.56705</td><td>0.06188</td><td>0.08251</td><td>0.27583</td><td>0.14014</td><td>0.21501</td></tr><tr><td colspan=\"5\">Full CAMEF Model</td><td>0.00048</td><td>0.00064</td><td>0.00107</td><td>0.00253</td><td>0.00250</td><td>0.00393</td><td>0.00054</td><td>0.00058</td><td>0.00101</td><td>0.00028</td><td>0.00044</td><td>0.00049</td><td>0.00132</td><td>0.00207</td><td>0.00224</td><td>0.00104</td><td>0.00124</td><td>0.00174</td></tr></table>\nTable 4: Ablation Study Results on Different Type of Events on S&P500 Index\n<table><tr><td rowspan=\"2\">Event Type</td><td colspan=\"2\">Forecasting Length = 35</td><td colspan=\"2\">Forecasting Length = 70</td><td colspan=\"2\">Forecasting Length = 140</td></tr><tr><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td></tr><tr><td>Unemployment Insurance</td><td>0.0004870 ↓</td><td>0.0159497 ↑</td><td>0.0005199 ↓</td><td>0.0157778 ↓</td><td>0.0006948 ↓</td><td>0.0190141 ↓</td></tr><tr><td>Employment Situation</td><td>0.0003923 ↓</td><td>0.0142684 ↓</td><td>0.0004612 ↓</td><td>0.0154431 ↓</td><td>0.0013767 ↑</td><td>0.0218677 ↑</td></tr><tr><td>GDP Advance</td><td>0.0006203 ↑</td><td>0.0175397 ↑</td><td>0.0005897 ↓</td><td>0.0175464 ↑</td><td>0.0011554 ↑</td><td>0.0217548 ↑</td></tr><tr><td>FOMC Minutes</td><td>0.0003401 ↓</td><td>0.0127694 ↓</td><td>0.0004448 ↓</td><td>0.0170094 ↓</td><td>0.0006433 ↓</td><td>0.0185657 ↓</td></tr><tr><td>CPI Report</td><td>0.0005645 ↑</td><td>0.0160723 ↑</td><td>0.0010660 ↑</td><td>0.0212536 ↑</td><td>0.0008187 ↓</td><td>0.0197824 ↓</td></tr><tr><td>PPI Report</td><td>0.0005275 ↑</td><td>0.0148434 ↓</td><td>0.0008054 ↑</td><td>0.0201844 ↑</td><td>0.0017646 ↑</td><td>0.0251856 ↑</td></tr><tr><td>Full Selection</td><td>0.0004886</td><td>0.0152405</td><td>0.0006478</td><td>0.0178691</td><td>0.0010756</td><td>0.0210284</td></tr></table>\n6.1.4 Implementation Overview. For the single-modality approaches (ARIMA, DLinear, AutoFormer, FEDformer, iTransformer, and PatchTST), we tested two methods: (1) training the models on continuous historical time-series data and testing on aligned event-based time-series segments from the test set, and (2) training the models directly on event-based time-series segments, and also test on the aligned event-based time-series segments from the test set. The second approach produced more accurate results, and these are the results presented in this paper. Specifically, for each aligned event data pair  "
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\left[\\mathcal{X}_{i-\\tau:i+\\tau} \\mapsto \\mathcal{E}_i\\right]"
                      },
                      {
                        "type": "text",
                        "content": " , single-modality approaches use only the time-series segment preceding the event,  "
                      },
                      {
                        "type": "inline-math",
                        "latex": "$\\mathcal{X}_{i-\\tau:i}$"
                      },
                      {
                        "type": "text",
                        "content": " , to train the models and forecast the subsequent segment,  "
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\mathcal{X}_{i+1:i+\\tau}"
                      },
                      {
                        "type": "text",
                        "content": " ; and testing follows the same approach. Detailed settings for each model are provided in Appendix C.\nFor the multi-modality approaches (GPT4MTS, TEST, and CAMEF), both the event script  "
                      },
                      {
                        "type": "inline-math",
                        "latex": "\\mathcal{E}_i"
                      },
                      {
                        "type": "text",
                        "content": "  and the time-series segment preceding the event,  "
                      },
                      {
                        "type": "inline-math",
                        "latex": "$X_{i - \\tau : i}$"
                      },
                      {
                        "type": "text",
                        "content": " , are used as input to train the models to forecast the post-event time-series segment,  "
                      },
                      {
                        "type": "inline-math",
                        "latex": "$X_{i + 1:i + \\tau}$"
                      },
                      {
                        "type": "text",
                        "content": " . Implementation details, including model configurations and training settings, are explained in Appendix C."
                      }
                    ],
                    "zh": []
                  },
                  "align": "left"
                }
              ],
              "subsections": []
            }
          ]
        }
      ]
    },
    {
      "id": "section-de554f87-75d6-46d4-85d5-08cde2b930a9",
      "title": {
        "en": "Experimental Results for Event-Driven Time-Series Forecasting (RQ1)",
        "zh": ""
      },
      "content": [
        {
          "id": "heading-9d30653c-2873-4adf-a828-75a4db5cd8ab",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Experimental Results for Event-Driven Time-Series Forecasting (RQ1)"
              }
            ],
            "zh": []
          }
        },
        {
          "id": "paragraph-ea95be15-4ed8-45b3-85e4-3966ec2f2aa2",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Table 2 presents the forecasting results for the five datasets across short, medium, and long forecasting horizons. CAMEF outperformed other models in 24 out of 30 settings, achieving first-place rankings, and ranked second in the remaining 6 settings. Specifically, CAMEF demonstrated the best performance across all forecasting lengths for the Stock Market Indices (SPX, INDU, and NDX), except for short-horizon forecasting on INDU, highlighting its effectiveness in event-driven stock market forecasting. For treasury bonds, CAMEF achieved the best results across all forecasting lengths for the 1-month treasury bond (USGG1M) and ranked second for the 5-year treasury bond (USGG5YR). The slightly lower performance on USGG5YR suggests that long-run treasury bonds may be less sensitive to event-driven factors and more influenced by historical trends.\nCompared to single-modality models (e.g., DLinear, Autoformer, FEDformer, PatchTST, and iTransformer), CAMEF achieved an average MSE reduction of  "
              },
              {
                "type": "inline-math",
                "latex": "$62.55\\%$"
              },
              {
                "type": "text",
                "content": "  relative to the best-performing single-modality model, iTransformer. Among multi-modality models, CAMEF surpassed TEST, the second-best performer, with an average MSE reduction of  "
              },
              {
                "type": "inline-math",
                "latex": "33.55\\%"
              },
              {
                "type": "text",
                "content": " .\nThese results highlight three key insights: (1) effectively leveraging multi-modality information provides significant performance gains, particularly for SPX, INDU, NDX, and USGG1M; (2) transformer-based methods consistently outperform classical models such as ARIMA; and (3) CAMEF's superior training and feature fusion strategies establish it as the most effective method for event-driven financial forecasting tasks."
              }
            ],
            "zh": []
          },
          "align": "left"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-8ae891a2-29cc-46dc-a193-896fc86afcef",
      "title": {
        "en": "Ablation Studies on Model Components (RQ2)",
        "zh": ""
      },
      "content": [
        {
          "id": "heading-e199b00a-b095-4532-882a-0f6576fd5556",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Ablation Studies on Model Components (RQ2)"
              }
            ],
            "zh": []
          }
        },
        {
          "id": "paragraph-9625df55-4636-44cf-a004-843e24681e4e",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "To evaluate the effectiveness of each component in CAMEF, we conduct comprehensive ablation studies on Textual Modality, Causal Learning, Feature Fusion, GPT2 Decoder, and the Post-Regressor. Based on the full CAMEF model, we remove the corresponding neural layers, such as the RoBERTa encoder for textual modality or the causal learning component, to assess their individual contributions. The ablation results are presented in Table 3, where the left part of the table uses  "
              },
              {
                "type": "inline-math",
                "latex": "\\checkmark"
              },
              {
                "type": "text",
                "content": "  or  "
              },
              {
                "type": "inline-math",
                "latex": "\\times"
              },
              {
                "type": "text",
                "content": "  to indicate whether the specific component is included or excluded in the test. From the results, three key findings are: (1) The full CAMEF model achieves the best performance across all datasets, demonstrating the critical importance of utilizing both textual and time-series modalities; (2) Causal learning provides incremental improvements, confirming its value in capturing cause-effect relationships within the data; (3) The proposed feature fusion layers and GPT2 decoder effectively integrate and leverage multi-modality features, significantly enhancing the model's ability to decode time-series data. These findings underscore the necessity of each component in achieving optimal performance for event-driven financial forecasting tasks."
              }
            ],
            "zh": []
          },
          "align": "left"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-753a5cc7-199d-4ff5-bd85-40ff5936d199",
      "title": {
        "en": "Ablation Studies on Different Type of Events (RQ3)",
        "zh": ""
      },
      "content": [
        {
          "id": "heading-1997be91-8631-4095-ace6-73bff555fc9e",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Ablation Studies on Different Type of Events (RQ3)"
              }
            ],
            "zh": []
          }
        },
        {
          "id": "paragraph-fb0403d2-cf6b-4d37-a1be-a7626f9288dc",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Table 4 shows the predictive performance of different events on the S&P500 Index. FOMC Minutes achieve the lowest MSE and MAE, confirming their critical importance for market prediction. Unemployment Insurance Claims and Unemployment Situation Reports also come with lower errors than the full selection, however the latter becomes less effective at long forecasting length. In contrast, CPI and PPI Reports show weaker predictive power, with PPI yielding the highest errors and CPI improving slightly at long forecasting length. These results emphasize the importance of FOMC and unemployment-related events for financial forecasting."
              }
            ],
            "zh": []
          },
          "align": "left"
        },
        {
          "id": "figure-b45f6344-6509-4968-b9ed-12c07aff238a",
          "type": "figure",
          "src": "/uploads/images/57bd0223-f398-4636-a9c9-b50bc4e35c79/figure-b45f6344-6509-4968-b9ed-12c07aff238a.jpg",
          "caption": {
            "en": [],
            "zh": []
          },
          "uploadedFilename": "figure-b45f6344-6509-4968-b9ed-12c07aff238a.jpg"
        },
        {
          "id": "paragraph-fe3ba019-d5ae-46a5-bbf8-a4cd3d2db9cb",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "(a) Effect of counterfactual sample size  "
              },
              {
                "type": "inline-math",
                "latex": "(\\alpha)"
              }
            ],
            "zh": []
          },
          "align": "left"
        },
        {
          "id": "figure-07853634-dc94-4020-8c36-5361b6d474a1",
          "type": "figure",
          "src": "/uploads/images/57bd0223-f398-4636-a9c9-b50bc4e35c79/figure-07853634-dc94-4020-8c36-5361b6d474a1.jpg",
          "caption": {
            "en": [
              {
                "type": "text",
                "content": "Sensitivity analysis of CAMEF on the SP500 dataset with respect to key hyperparameters."
              }
            ],
            "zh": []
          },
          "uploadedFilename": "figure-07853634-dc94-4020-8c36-5361b6d474a1.jpg"
        },
        {
          "id": "paragraph-2751cc70-fe8d-4e98-96a4-09fde8a301dd",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "(b) Effect of post-regressor depth (k)"
              }
            ],
            "zh": []
          },
          "align": "left"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-33d998c3-f6f8-4f67-87e7-cddd9a388b87",
      "title": {
        "en": "Parameter Sensitivity Analysis",
        "zh": ""
      },
      "content": [
        {
          "id": "heading-ac03bfbd-648e-4a33-8a49-ff06f0fb53d8",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Parameter Sensitivity Analysis"
              }
            ],
            "zh": []
          }
        },
        {
          "id": "paragraph-e784cc81-f733-45fb-957d-1bac22160e3b",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "We examine the impact of two key hyperparameters in CAMEF on SPX dataset with 35 predictive length: the number of counterfactual samples  "
              },
              {
                "type": "inline-math",
                "latex": "(\\alpha)"
              },
              {
                "type": "text",
                "content": "  and the depth of the post-regressor network  "
              },
              {
                "type": "inline-math",
                "latex": "$(k)$"
              },
              {
                "type": "text",
                "content": " . The number of GPT-2 layers  "
              },
              {
                "type": "inline-math",
                "latex": "$(l)$"
              },
              {
                "type": "text",
                "content": "  remains fixed, as we adopt the pre-trained model without modification. As shown in Figure 4, increasing  "
              },
              {
                "type": "inline-math",
                "latex": "\\alpha"
              },
              {
                "type": "text",
                "content": "  enhances forecasting accuracy through stronger contrastive supervision, with performance gains saturating around  "
              },
              {
                "type": "inline-math",
                "latex": "\\alpha = 10"
              },
              {
                "type": "text",
                "content": " . Similarly, increasing  "
              },
              {
                "type": "inline-math",
                "latex": "k"
              },
              {
                "type": "text",
                "content": "  improves decoding capacity, though with diminishing returns beyond  "
              },
              {
                "type": "inline-math",
                "latex": "$k = 4$"
              },
              {
                "type": "text",
                "content": " . These trends suggest that CAMEF performs robustly across a range of configurations, benefiting from moderate complexity increases without overfitting."
              }
            ],
            "zh": []
          },
          "align": "left"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-0b31a34e-18f7-4cda-a3da-70f87ecfd5bc",
      "title": {
        "en": "Conclusion and Future Work",
        "zh": ""
      },
      "content": [
        {
          "id": "heading-2a317529-64f4-45ec-9e67-6fc4f017e635",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Conclusion and Future Work"
              }
            ],
            "zh": []
          }
        },
        {
          "id": "paragraph-7763b423-f7fc-419c-97a6-1c93ecfba4e4",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "This paper proposed CAMEF, a multi-modality model for event-driven financial forecasting, which integrates effective causal learning and an LLM-based counterfactual event augmentation strategy. Alongside the model, we introduced a novel synthetic dataset comprising 6 types of salient macroeconomic event scripts, their counterfactual samples, and high-frequency time-series data for 5 key financial assets, aligned with real-world investment practices. Extensive experiments demonstrated CAMEF's superior predictive performance compared to prior deep time-series and multi-modality methods. Ablation studies testified the importance of causal learning and other designed components of CAMEF. Additionally, it is found that FOMC and unemployment-related events provided the most predictive value among the tested event types.\nFor future work, we plan to leverage advanced LLMs for enhanced textual encoding to extract deeper semantic information, refine the cross-modality causal inference mechanisms, and expand the dataset to include additional event types, such as political events and corporate market-sensitive news."
              }
            ],
            "zh": []
          },
          "align": "left"
        }
      ],
      "subsections": []
    },
    {
      "id": "section-9f35a279-c5d9-4903-bd97-dd818a3a447d",
      "title": {
        "en": "Acknowledgements",
        "zh": ""
      },
      "content": [
        {
          "id": "heading-e5e4f864-dcdd-4b61-8dad-fef2de27a16f",
          "type": "heading",
          "level": 1,
          "content": {
            "en": [
              {
                "type": "text",
                "content": "Acknowledgements"
              }
            ],
            "zh": []
          }
        },
        {
          "id": "paragraph-00fc0a63-b323-414a-ab18-747505c33084",
          "type": "paragraph",
          "content": {
            "en": [
              {
                "type": "text",
                "content": "This work was supported in part by the National Natural Science Foundation of China (NSFC) under Grant Nos. 62402396 and 72471197. We would like to thank the anonymous reviewers for their valuable comments and suggestions that helped improve the quality of this paper."
              }
            ],
            "zh": []
          },
          "align": "left"
        }
      ],
      "subsections": []
    }
  ],
  "references": [
    {
      "id": "ref-93f36d02-2fab-4387-9a27-44dcc695cf54",
      "number": 1,
      "authors": [],
      "title": "Ariyo, Adewumi O",
      "year": 2014
    },
    {
      "id": "ref-c782b6ff-bda3-4534-b403-7cb3056cea82",
      "number": 2,
      "authors": [],
      "title": "2025",
      "year": 2025
    },
    {
      "id": "ref-806300f0-c67c-4a1f-be28-7129ee639135",
      "number": 3,
      "authors": [],
      "title": "2008",
      "year": 2008
    },
    {
      "id": "ref-1c121d76-0ef6-4bcb-b3b5-a42ae9d1433f",
      "number": 4,
      "authors": [],
      "title": "Peters, and Arman Cohan",
      "year": 2020
    },
    {
      "id": "ref-21c4b0aa-3994-4dce-b90b-cfc255c23209",
      "number": 5,
      "authors": [],
      "title": "2017",
      "year": 2017
    },
    {
      "id": "ref-86f744b7-46d0-4917-80dc-8a8c09112142",
      "number": 6,
      "authors": [],
      "title": "Jenkins",
      "year": 1994
    },
    {
      "id": "ref-2da32eaf-802e-4da5-be94-20d626d824b8",
      "number": 7,
      "authors": [],
      "title": "Q",
      "year": 1992
    },
    {
      "id": "ref-9474f86a-df6a-4433-99d5-ad746533b3fd",
      "number": 8,
      "authors": [],
      "title": "2021",
      "year": 2021
    },
    {
      "id": "ref-6f471659-e9f1-49b2-850d-09045505c857",
      "number": 9,
      "authors": [],
      "title": "2023",
      "year": 2023
    },
    {
      "id": "ref-c59f4f5e-4940-4512-8377-a52df738606d",
      "number": 10,
      "authors": [],
      "title": "2019",
      "year": 2019
    },
    {
      "id": "ref-df7b14ec-d768-4185-a6bf-df1dd9f94a24",
      "number": 11,
      "authors": [],
      "title": "2019",
      "year": 2019
    },
    {
      "id": "ref-2dc8157f-23d7-4f03-a192-895b1c042972",
      "number": 12,
      "authors": [],
      "title": "2019",
      "year": 2019
    },
    {
      "id": "ref-90c5e8d3-f448-4e01-8864-5e46e58cf164",
      "number": 13,
      "authors": [],
      "title": "2021",
      "year": 2021,
      "url": "https://www.cNBC.com/2021/03/16/one-year-ago-stocks-dropped-12percent-in-a-single-day-what-investors-haslearned-since-then.html"
    },
    {
      "id": "ref-15b88061-ffee-4440-9b4d-1e5438e9b340",
      "number": 14,
      "authors": [],
      "title": "M",
      "year": 2022
    },
    {
      "id": "ref-316ababf-e83a-4f50-aeaa-05b5178752da",
      "number": 15,
      "authors": [],
      "title": "Fama",
      "year": 1965
    },
    {
      "id": "ref-6ea909e8-81b2-4991-9446-b9a872b05352",
      "number": 16,
      "authors": [],
      "title": "Fama, Lawrence Fisher, Michael C",
      "year": 1969
    },
    {
      "id": "ref-c4d8c2c7-a7b9-4d8e-b9d8-ca8107ffe6d6",
      "number": 17,
      "authors": [],
      "title": "2018",
      "year": 2018
    },
    {
      "id": "ref-7724919e-a603-495e-8aea-886fdc62a63d",
      "number": 18,
      "authors": [],
      "title": "2010",
      "year": 2010
    },
    {
      "id": "ref-ce85828a-aaa3-4ca7-874c-668d4a460c7a",
      "number": 19,
      "authors": [],
      "title": "2017",
      "year": 2017
    },
    {
      "id": "ref-49192b80-7763-461d-978d-b3172fe76cc5",
      "number": 20,
      "authors": [],
      "title": "2013",
      "year": 2013
    },
    {
      "id": "ref-2c1fd738-1390-4cb0-a285-afd9d1b5bc6e",
      "number": 21,
      "authors": [],
      "title": "2024",
      "year": 2024
    },
    {
      "id": "ref-edcae27e-11ca-48a1-b0fd-8cc11853d20d",
      "number": 22,
      "authors": [],
      "title": "Huynh, L",
      "year": 2017
    },
    {
      "id": "ref-493d0496-bd7b-4149-94b8-194ec2369e7b",
      "number": 23,
      "authors": [],
      "title": "2007",
      "year": 2007
    },
    {
      "id": "ref-4075d78d-6edc-4e07-b98d-ffef27bf9601",
      "number": 24,
      "authors": [],
      "title": "2024",
      "year": 2024
    },
    {
      "id": "ref-6bc90067-2b78-465c-aa53-8f28017932cd",
      "number": 25,
      "authors": [],
      "title": "2020",
      "year": 2020
    },
    {
      "id": "ref-c966ed22-1fad-49df-b1c5-893a6ab07ca0",
      "number": 26,
      "authors": [],
      "title": "McKenzie, and Robert W",
      "year": 2004
    },
    {
      "id": "ref-883551b0-8587-427f-8d72-bdaf6bcdc179",
      "number": 27,
      "authors": [],
      "title": "2024",
      "year": 2024
    },
    {
      "id": "ref-a2db68ed-7348-437e-b5c5-39f00d35be07",
      "number": 28,
      "authors": [],
      "title": "2014",
      "year": 2014
    },
    {
      "id": "ref-7cb4fc3e-a39c-41c3-9cca-326251ea692b",
      "number": 29,
      "authors": [],
      "title": "2018",
      "year": 2018
    },
    {
      "id": "ref-718bc59b-c4ba-4116-9763-0f3a30a93b62",
      "number": 30,
      "authors": [],
      "title": "2024",
      "year": 2024
    },
    {
      "id": "ref-c87fe2ca-fc5a-423a-9713-643c99e9eca0",
      "number": 31,
      "authors": [],
      "title": "2019",
      "year": 2019
    },
    {
      "id": "ref-36f3594c-a72b-469b-8404-205e7f5e658c",
      "number": 32,
      "authors": [],
      "title": "2024",
      "year": 2024
    },
    {
      "id": "ref-b2496cd2-bc71-450e-bf0d-6bec618cdce3",
      "number": 33,
      "authors": [],
      "title": "LUCCA and EMANUEL MOENCH",
      "year": 2015
    },
    {
      "id": "ref-b0e53dd3-9da0-4661-8302-6b4c15b992a7",
      "number": 34,
      "authors": [],
      "title": "2024",
      "year": 2024
    },
    {
      "id": "ref-f0c8d898-001d-4055-995d-f1aa76555209",
      "number": 35,
      "authors": [],
      "title": "2022",
      "year": 2022
    },
    {
      "id": "ref-d0d856f5-b07b-4478-bd4a-7de85da7dc39",
      "number": 36,
      "authors": [],
      "title": "2015",
      "year": 2015
    },
    {
      "id": "ref-2aa9dc4b-9ee2-46e3-be2c-33744264df53",
      "number": 37,
      "authors": [],
      "title": "2024",
      "year": 2024
    },
    {
      "id": "ref-fec78a1b-4b07-4277-b10f-c30c1aeab009",
      "number": 38,
      "authors": [],
      "title": "Vance Roley",
      "year": 1984
    },
    {
      "id": "ref-0b7ff745-3eb8-467a-9209-c0dfb1ce960d",
      "number": 39,
      "authors": [],
      "title": "Pui Cheong Fung, J",
      "year": 2003
    },
    {
      "id": "ref-bb556caa-c5f0-4496-ab95-372382ded6b0",
      "number": 40,
      "authors": [],
      "title": "2019",
      "year": 2019
    },
    {
      "id": "ref-b5f7842a-b97b-43c0-a5c4-ca9452cccd57",
      "number": 41,
      "authors": [],
      "title": "2019",
      "year": 2019
    },
    {
      "id": "ref-9dbcfe5d-fc6f-4d1d-a1e4-432ae81df213",
      "number": 42,
      "authors": [],
      "title": "2011",
      "year": 2011
    },
    {
      "id": "ref-f6648528-beae-424c-b542-c8153f2a4229",
      "number": 43,
      "authors": [],
      "title": "2013",
      "year": 2013
    },
    {
      "id": "ref-45e0a3c6-197b-4ae8-99cc-03f0891c6891",
      "number": 44,
      "authors": [],
      "title": "2016",
      "year": 2016
    },
    {
      "id": "ref-98bf2ec1-5293-498f-a2dd-c23d4cd17e1f",
      "number": 45,
      "authors": [],
      "title": "2022",
      "year": 2022
    },
    {
      "id": "ref-b5584c0c-6654-4c94-a1a6-d21e94b2b8d1",
      "number": 46,
      "authors": [],
      "title": "2020",
      "year": 2020
    },
    {
      "id": "ref-6b5d86a2-0a9e-4287-9500-7d8decfcb6a1",
      "number": 47,
      "authors": [],
      "title": "2020",
      "year": 2020
    },
    {
      "id": "ref-dc40e448-7f8d-443e-9740-c9492e03fd5f",
      "number": 48,
      "authors": [],
      "title": "A Gopalakrishnan, Vijay Krishna Menon, and K",
      "year": 2017
    },
    {
      "id": "ref-9477c5e8-6e4e-4b83-b5b2-30a7a556fa70",
      "number": 49,
      "authors": [],
      "title": "2023",
      "year": 2023
    },
    {
      "id": "ref-59932284-23a5-4181-920d-fb88ca72089a",
      "number": 50,
      "authors": [],
      "title": "2013",
      "year": 2013
    },
    {
      "id": "ref-b11343dd-d500-475c-a30f-a0627500b81a",
      "number": 51,
      "authors": [],
      "title": "2024",
      "year": 2024
    },
    {
      "id": "ref-8e2ddd3a-5d84-4e89-a118-ed021d5bf09d",
      "number": 52,
      "authors": [],
      "title": "2022",
      "year": 2022
    },
    {
      "id": "ref-b17f1923-fe63-4dc2-a086-dfdc6d7f4563",
      "number": 53,
      "authors": [],
      "title": "2024",
      "year": 2024
    },
    {
      "id": "ref-a92cbfe6-ce6b-457f-8890-c7c12b2f7238",
      "number": 54,
      "authors": [],
      "title": "2007",
      "year": 2007
    },
    {
      "id": "ref-4298ae14-5926-4527-bdc7-fd58990df12b",
      "number": 55,
      "authors": [],
      "title": "Smith, Daniel Khashabi, and Hannaneh Hajishirzi",
      "year": 2023
    },
    {
      "id": "ref-2f494773-d227-429e-940d-909e1883cdaf",
      "number": 56,
      "authors": [],
      "title": "2021",
      "year": 2021
    },
    {
      "id": "ref-780bc93f-3532-462f-8743-dcc14336e45f",
      "number": 57,
      "authors": [],
      "title": "Cohen",
      "year": 2018
    },
    {
      "id": "ref-af37a947-ee0d-4f1e-afdd-c89cd90496d0",
      "number": 58,
      "authors": [],
      "title": "2020",
      "year": 2020
    },
    {
      "id": "ref-9236ad62-a421-41bf-8e1c-755808484879",
      "number": 59,
      "authors": [],
      "title": "2023",
      "year": 2023
    },
    {
      "id": "ref-86650065-b114-4b2e-943a-e59925fbcd5e",
      "number": 60,
      "authors": [],
      "title": "2021",
      "year": 2021
    },
    {
      "id": "ref-adaa6a74-6838-4822-a39e-3b2fa4de53ec",
      "number": 61,
      "authors": [],
      "title": "2022",
      "year": 2022
    },
    {
      "id": "ref-facb9544-9202-4a74-8e34-51629f4a64e1",
      "number": 62,
      "authors": [],
      "title": "[n",
      "year": 2021
    },
    {
      "id": "ref-c9857e1e-fe94-4081-a029-c5d5c1e3d1d6",
      "number": 63,
      "authors": [],
      "title": "- Requests - to send HTTP requests for archive access;"
    },
    {
      "id": "ref-f8879b26-88e0-4858-80d0-1646ea02f4e4",
      "number": 64,
      "authors": [],
      "title": "- Selenium - to locate and download files via HTML headers;"
    },
    {
      "id": "ref-4ce30b4b-52da-4e49-9860-622fb6e9cbe8",
      "number": 65,
      "authors": [],
      "title": "|"
    },
    {
      "id": "ref-207b2bcf-9150-4292-9263-4f911ff02d95",
      "number": 66,
      "authors": [],
      "title": "In the first stage, the encoder was trained by selecting 10 prototype words based on GPT vocabulary clustering (as instructed in the repository) to align textual representations with time-series data"
    },
    {
      "id": "ref-c55bd4cf-8c14-49fa-bbee-170703b4b7c2",
      "number": 67,
      "authors": [],
      "title": "Instead of using BERT [12] as the textual encoder, we employed LongFormer [4], which is better suited for encoding longer contexts, as our texts tend to be relatively lengthy"
    },
    {
      "id": "ref-ab6593c0-66c2-4545-a86d-e4ffbffe8cac",
      "number": 68,
      "authors": [],
      "title": "Additionally, the token embedding layer of GPT2 in the decoder is frozen to preserve its pre-trained representations"
    },
    {
      "id": "ref-425bebde-1119-4fae-928a-525ee0f98a87",
      "number": 69,
      "authors": [],
      "title": "The hidden sizes of the different components of the CAMEF model are detailed in Sec"
    }
  ],
  "blockNotes": [],
  "checklistNotes": [],
  "attachments": []
}